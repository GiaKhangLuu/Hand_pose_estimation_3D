{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a14009-0976-41cf-8b28-896dad8c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d477fb-a335-4c4f-8dda-9a8e6bfd87b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from hand_landmarks.neural_networks.mlp import MLP_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8518cda9-3ca9-44fe-aeb7-5db5d2ccb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmarks_through_frame(landmarks, time_sleep=0.01):\n",
    "    assert landmarks.shape[1:] == (21, 3)\n",
    "    \n",
    "    x = np.array([[500, 0, 0],\n",
    "                  [0, 0, 0]])\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(x)\n",
    "\n",
    "    lines = [[0, 0]]\n",
    "    colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(x),\n",
    "        lines=o3d.utility.Vector2iVector(lines)\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.add_geometry(line_set)\n",
    "\n",
    "    for i in range(landmarks.shape[0]):\n",
    "        hand_lmks = landmarks[i]\n",
    "        pcd.points = o3d.utility.Vector3dVector(hand_lmks)\n",
    "\n",
    "        lines = [[0,1],[1,2],[2,3],[3,4], \n",
    "                 [0,5],[5,6],[6,7],[7,8],\n",
    "                 [5,9],[9,10],[10,11],[11,12],\n",
    "                 [9,13],[13,14],[14,15],[15,16],\n",
    "                 [13,17],[17,18],[18,19],[19,20],[0,17]]\n",
    "        colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "        line_set.points = o3d.utility.Vector3dVector(hand_lmks)  # Update the points\n",
    "        line_set.lines = o3d.utility.Vector2iVector(lines)  # Update the lines\n",
    "        line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        vis.update_geometry(pcd)\n",
    "        vis.update_geometry(line_set)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        \n",
    "        time.sleep(time_sleep)\n",
    "\n",
    "    vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d24564-93ff-4736-befa-ed69d3be4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_csv(file_name, data, num_cam=2):\n",
    "    num_points_each_joint = 3\n",
    "    num_joints_each_hand = 21\n",
    "    num_input_cols = num_cam * num_points_each_joint * num_joints_each_hand\n",
    "\n",
    "    input_header = input_cam1_header\n",
    "    for i in range(2, num_cam+1):\n",
    "        input_cam_i_header = input_cam1_header.replace(\"cam1\", \"cam{}\".format(i))\n",
    "        input_header += ',' + input_cam_i_header\n",
    "\n",
    "    output_header = input_cam1_header.replace(\"cam1_\", \"\").replace(\"in\", \"out\")\n",
    "    csv_header = input_header + ',' + output_header\n",
    "\n",
    "    assert len(csv_header.split(\",\")) == data.shape[1]\n",
    "\n",
    "    np.savetxt(file_name, data, delimiter=',', fmt='%f', header=csv_header, comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ed955-9430-4acd-8d71-b80135fc1dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828eb86-e456-41f1-b017-7a1e362793ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9b2be-6f65-4aaf-be82-d6a78a2359e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d89f3b67-4f80-4c3e-9511-fb851642c913",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Visualize GTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1099b869-630b-46f7-9c8c-b2e881518d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_lmks_file = np.load('/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/hand_landmarks_2024_6_14_16_12.npz')\n",
    "hand_lmks_file = np.load('/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/hand_landmarks_2024_6_14_18_1.npz')\n",
    "hand_lmks_file = np.load('/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/hand_landmarks_2024_6_14_18_3.npz')\n",
    "hand_lmks_file = np.load('/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/hand_landmarks_2024_6_14_18_6.npz')\n",
    "\n",
    "hand_lmks_gt = hand_lmks_file[\"landmarks_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b70cc6-fb51-476c-80db-8e81998dca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "visualize_landmarks_through_frame(hand_lmks_gt, time_sleep=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45058c-9636-4ee5-9490-8987c58203e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9327ef33-afd2-4978-a3d5-bc14cafba95d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Visualize raw landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b3c3f9-d337-4fd0-baac-96817c8c959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_lmks_file = np.load('/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/data/hand_landmarks_2024_6_14_16_12.npz')\n",
    "hand_lmks_input = hand_lmks_file[\"raw_xyZ_of_opposite_cam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4555a6e7-0727-40c7-94e2-852bb302a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(hand_lmks_input, time_sleep=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8b95bf-449d-418a-a5e0-6659215fc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_lmks_input = hand_lmks_file[\"raw_xyZ_of_rightside_cam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26e3966f-222c-4089-b983-fe1b98b1f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(hand_lmks_input, time_sleep=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a05f7e-d2f4-49a9-a684-db618a2ff2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d761dd-2df7-401f-8e20-83e0dd6f86ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9ec944-8ea0-47fb-944d-079754f43905",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb266333-aa98-40b7-869f-0cc35a5d4397",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualize for verifing that we save the correct landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80ec62a-629d-43a7-bc48-7d4b10f07404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/train_hand_landmarks_2024_6_14_16_12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data from a CSV file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/train_hand_landmarks_2024_6_14_16_12.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m num_output_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      5\u001b[0m X_train \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m(num_output_nodes)]\n",
      "File \u001b[0;32m~/py_venv/hand_pose_estimation/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py_venv/hand_pose_estimation/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/py_venv/hand_pose_estimation/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py_venv/hand_pose_estimation/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/py_venv/hand_pose_estimation/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/train_hand_landmarks_2024_6_14_16_12.csv'"
     ]
    }
   ],
   "source": [
    "# Load the data from a CSV file\n",
    "train_data = pd.read_csv(\"/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/train_hand_landmarks_2024_6_14_16_12.csv\")\n",
    "\n",
    "num_output_nodes = 21 * 3\n",
    "X_train = train_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_train = train_data.iloc[:, -(num_output_nodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb38a17-a3f6-4394-92db-a0ecda8bebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_landmarks_each_cam = 21 * 3\n",
    "X_train_cam_1 = X_train.values[:, :num_landmarks_each_cam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f5c6a9c-85eb-40c6-8ba9-eea8d957f84d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_cam_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m visualize_landmarks_through_frame(\u001b[43mX_train_cam_1\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m3\u001b[39m), time_sleep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_cam_1' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_landmarks_through_frame(X_train_cam_1.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74c3ac83-5711-49d7-802b-f594bfc3544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(Y_train.values.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "426823a6-d610-4509-b354-af876167a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cam_2 = X_train.values[:, num_landmarks_each_cam:]\n",
    "visualize_landmarks_through_frame(X_train_cam_2.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b7782-a716-444a-b48e-2035047352bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62dad440-9909-4f8d-99a0-9f56c4d8a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a CSV file\n",
    "test_data = pd.read_csv('/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/data/test_hand_landmarks_2024_6_14_16_12.csv')\n",
    "\n",
    "num_output_nodes = 21 * 3\n",
    "X_test = test_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_test = test_data.iloc[:, -(num_output_nodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "987e9b76-d813-4277-a67d-4dcd7ea0eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_landmarks_each_cam = 21 * 3\n",
    "X_test_cam_1 = X_test.values[:, :num_landmarks_each_cam]\n",
    "visualize_landmarks_through_frame(X_test_cam_1.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3e2d352-cd48-422c-b3fe-96a156499c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cam_2 = X_test.values[:, num_landmarks_each_cam:]\n",
    "visualize_landmarks_through_frame(X_test_cam_2.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f917bc59-542b-4d85-8e21-b64d1aa9735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(Y_test.values.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba830f7-832c-4e0c-b837-fca57760c64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc478798-bc6f-441f-a15f-36cbea8524f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec01fcde-cea7-4538-b538-8bca8ea52938",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_landmarks = 21 * 3\n",
    "landmarks_opposite_cam = X.values[:, :num_landmarks]\n",
    "landmarks_rightside_cam = X.values[:, num_landmarks:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303eaeaf-8a4b-404d-8080-64b6d3f05d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_opposite_cam = landmarks_opposite_cam.reshape(landmarks_opposite_cam.shape[0], 21, -1)\n",
    "landmarks_rightside_cam = landmarks_rightside_cam.reshape(landmarks_rightside_cam.shape[0], 21, -1)\n",
    "landmarks_gt = Y.values\n",
    "landmarks_gt = landmarks_gt.reshape(landmarks_gt.shape[0], 21, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f73cf65-6df8-485c-8e26-4e1b8f62a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(landmarks_rightside_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d227d-a274-494e-b0cb-5e22cbe47704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc55ef-d38e-469c-aefd-502a0f90bd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caccf9cb-952a-460c-963e-3dc43ea440a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/train_hand_landmarks_2024_6_14_16_12.csv\"\n",
    "test_data_path = \"/Users/giakhang/dev/research/Hand_pose_estimation_3D/hand_landmarks/data/test_hand_landmarks_2024_6_14_16_12.csv\"\n",
    "\n",
    "# Load the data from a CSV file\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "num_output_nodes = 21 * 3\n",
    "X_train = train_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_train = train_data.iloc[:, -(num_output_nodes):]\n",
    "X_test = test_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_test = test_data.iloc[:, -(num_output_nodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865497e-ed36-43ad-9a1f-3d843ed20fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928b13e-4eae-4708-880b-d251e5c19bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c91236a9-8fd8-4b75-9775-0c075e40bb5d",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7dc270-05a6-4913-8849-8155b18ba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093ae4e8-1e0d-4689-be17-cf0bf09fb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_files = glob.glob(os.path.join(data_folder, \"*/train*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1715c64f-6755-4bf3-87a1-a33158fc00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frames = []\n",
    "\n",
    "for file in train_data_files:\n",
    "    train_data_frame = pd.read_csv(file)\n",
    "    train_data_frames.append(train_data_frame)\n",
    "\n",
    "# Concatenate all data frames into a single data frame\n",
    "merged_train_data = pd.concat(train_data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2433be11-1c9b-4675-8b7a-43cc55fd2b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_files = [file.replace(\"train\", \"test\") for file in train_data_files]\n",
    "\n",
    "test_data_frames = []\n",
    "\n",
    "for file in test_data_files:\n",
    "    test_df = pd.read_csv(file)\n",
    "    test_data_frames.append(test_df)\n",
    "\n",
    "merged_test_data = pd.concat(test_data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299cacb-57e8-41d4-b9e4-d6866ce39402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf1ad07-04d1-40ff-8918-b6e630ec1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_nodes = 21 * 3\n",
    "X_train = merged_train_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_train = merged_train_data.iloc[:, -(num_output_nodes):]\n",
    "X_test = merged_test_data.iloc[:, :-(num_output_nodes)]\n",
    "Y_test = merged_test_data.iloc[:, -(num_output_nodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efd6e0-7973-48f6-955d-b4f9d5016c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff351ee-0776-4e77-8a9a-ef531753098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cam1_X00_in</th>\n",
       "      <th>cam1_Y00_in</th>\n",
       "      <th>cam1_Z00_in</th>\n",
       "      <th>cam1_X01_in</th>\n",
       "      <th>cam1_Y01_in</th>\n",
       "      <th>cam1_Z01_in</th>\n",
       "      <th>cam1_X02_in</th>\n",
       "      <th>cam1_Y02_in</th>\n",
       "      <th>cam1_Z02_in</th>\n",
       "      <th>cam1_X03_in</th>\n",
       "      <th>...</th>\n",
       "      <th>cam1_Z17_in</th>\n",
       "      <th>cam1_X18_in</th>\n",
       "      <th>cam1_Y18_in</th>\n",
       "      <th>cam1_Z18_in</th>\n",
       "      <th>cam1_X19_in</th>\n",
       "      <th>cam1_Y19_in</th>\n",
       "      <th>cam1_Z19_in</th>\n",
       "      <th>cam1_X20_in</th>\n",
       "      <th>cam1_Y20_in</th>\n",
       "      <th>cam1_Z20_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743.123345</td>\n",
       "      <td>171.452410</td>\n",
       "      <td>664.112915</td>\n",
       "      <td>806.416982</td>\n",
       "      <td>156.730690</td>\n",
       "      <td>689.641602</td>\n",
       "      <td>813.150030</td>\n",
       "      <td>136.019235</td>\n",
       "      <td>686.213379</td>\n",
       "      <td>771.749168</td>\n",
       "      <td>...</td>\n",
       "      <td>707.295715</td>\n",
       "      <td>682.808819</td>\n",
       "      <td>135.650830</td>\n",
       "      <td>703.877136</td>\n",
       "      <td>693.793886</td>\n",
       "      <td>129.494983</td>\n",
       "      <td>690.344849</td>\n",
       "      <td>696.750916</td>\n",
       "      <td>141.048865</td>\n",
       "      <td>682.862427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>632.684383</td>\n",
       "      <td>51.868599</td>\n",
       "      <td>741.745667</td>\n",
       "      <td>578.401790</td>\n",
       "      <td>20.912088</td>\n",
       "      <td>747.945801</td>\n",
       "      <td>479.663022</td>\n",
       "      <td>12.100841</td>\n",
       "      <td>701.973511</td>\n",
       "      <td>417.889550</td>\n",
       "      <td>...</td>\n",
       "      <td>715.926453</td>\n",
       "      <td>464.224760</td>\n",
       "      <td>75.380606</td>\n",
       "      <td>706.878296</td>\n",
       "      <td>424.448473</td>\n",
       "      <td>71.683153</td>\n",
       "      <td>690.033569</td>\n",
       "      <td>406.300806</td>\n",
       "      <td>72.008677</td>\n",
       "      <td>703.126099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333.535070</td>\n",
       "      <td>-155.549948</td>\n",
       "      <td>796.472168</td>\n",
       "      <td>270.331367</td>\n",
       "      <td>-150.541812</td>\n",
       "      <td>826.316528</td>\n",
       "      <td>218.788598</td>\n",
       "      <td>-158.240785</td>\n",
       "      <td>828.830078</td>\n",
       "      <td>181.561901</td>\n",
       "      <td>...</td>\n",
       "      <td>796.132996</td>\n",
       "      <td>187.065664</td>\n",
       "      <td>-164.732348</td>\n",
       "      <td>813.638794</td>\n",
       "      <td>175.810343</td>\n",
       "      <td>-146.212779</td>\n",
       "      <td>834.935913</td>\n",
       "      <td>176.400728</td>\n",
       "      <td>-136.505687</td>\n",
       "      <td>860.233032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224.871843</td>\n",
       "      <td>32.556823</td>\n",
       "      <td>781.035034</td>\n",
       "      <td>199.500594</td>\n",
       "      <td>-10.916714</td>\n",
       "      <td>806.637207</td>\n",
       "      <td>156.942292</td>\n",
       "      <td>-45.379594</td>\n",
       "      <td>824.041748</td>\n",
       "      <td>123.669363</td>\n",
       "      <td>...</td>\n",
       "      <td>775.100647</td>\n",
       "      <td>52.284971</td>\n",
       "      <td>76.905354</td>\n",
       "      <td>768.202271</td>\n",
       "      <td>22.824038</td>\n",
       "      <td>90.063794</td>\n",
       "      <td>769.679077</td>\n",
       "      <td>-2.450192</td>\n",
       "      <td>100.559907</td>\n",
       "      <td>773.636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>615.849703</td>\n",
       "      <td>38.403163</td>\n",
       "      <td>730.573730</td>\n",
       "      <td>582.035489</td>\n",
       "      <td>3.258603</td>\n",
       "      <td>713.746521</td>\n",
       "      <td>536.439438</td>\n",
       "      <td>-22.364605</td>\n",
       "      <td>697.377319</td>\n",
       "      <td>499.273383</td>\n",
       "      <td>...</td>\n",
       "      <td>703.424805</td>\n",
       "      <td>482.505275</td>\n",
       "      <td>30.173349</td>\n",
       "      <td>719.204712</td>\n",
       "      <td>496.142542</td>\n",
       "      <td>32.467161</td>\n",
       "      <td>717.115601</td>\n",
       "      <td>513.508734</td>\n",
       "      <td>32.484529</td>\n",
       "      <td>707.200928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>450.549237</td>\n",
       "      <td>107.555878</td>\n",
       "      <td>578.841797</td>\n",
       "      <td>430.854739</td>\n",
       "      <td>65.083729</td>\n",
       "      <td>593.544250</td>\n",
       "      <td>389.830267</td>\n",
       "      <td>44.015018</td>\n",
       "      <td>615.353577</td>\n",
       "      <td>335.085761</td>\n",
       "      <td>...</td>\n",
       "      <td>591.653503</td>\n",
       "      <td>297.741129</td>\n",
       "      <td>163.192664</td>\n",
       "      <td>611.219238</td>\n",
       "      <td>270.714084</td>\n",
       "      <td>155.770524</td>\n",
       "      <td>617.077454</td>\n",
       "      <td>253.347195</td>\n",
       "      <td>144.378529</td>\n",
       "      <td>619.201477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>753.124368</td>\n",
       "      <td>58.692086</td>\n",
       "      <td>817.966309</td>\n",
       "      <td>784.649226</td>\n",
       "      <td>9.614661</td>\n",
       "      <td>853.159790</td>\n",
       "      <td>793.110710</td>\n",
       "      <td>-23.452980</td>\n",
       "      <td>904.951782</td>\n",
       "      <td>737.386025</td>\n",
       "      <td>...</td>\n",
       "      <td>879.398865</td>\n",
       "      <td>659.451409</td>\n",
       "      <td>64.140597</td>\n",
       "      <td>896.927795</td>\n",
       "      <td>658.921691</td>\n",
       "      <td>53.119792</td>\n",
       "      <td>890.006897</td>\n",
       "      <td>663.070039</td>\n",
       "      <td>50.110716</td>\n",
       "      <td>879.505981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>610.340981</td>\n",
       "      <td>27.480328</td>\n",
       "      <td>643.860046</td>\n",
       "      <td>577.750896</td>\n",
       "      <td>-5.992889</td>\n",
       "      <td>649.838623</td>\n",
       "      <td>517.925825</td>\n",
       "      <td>-19.180636</td>\n",
       "      <td>646.730103</td>\n",
       "      <td>472.098329</td>\n",
       "      <td>...</td>\n",
       "      <td>633.789734</td>\n",
       "      <td>454.090510</td>\n",
       "      <td>52.647196</td>\n",
       "      <td>655.347412</td>\n",
       "      <td>456.195301</td>\n",
       "      <td>56.267694</td>\n",
       "      <td>641.569031</td>\n",
       "      <td>472.176362</td>\n",
       "      <td>55.904058</td>\n",
       "      <td>639.656799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>564.257620</td>\n",
       "      <td>78.360995</td>\n",
       "      <td>650.537781</td>\n",
       "      <td>519.177287</td>\n",
       "      <td>40.719941</td>\n",
       "      <td>633.592712</td>\n",
       "      <td>468.754716</td>\n",
       "      <td>14.673351</td>\n",
       "      <td>624.565369</td>\n",
       "      <td>421.964621</td>\n",
       "      <td>...</td>\n",
       "      <td>625.928589</td>\n",
       "      <td>393.411515</td>\n",
       "      <td>82.424300</td>\n",
       "      <td>627.251892</td>\n",
       "      <td>366.865095</td>\n",
       "      <td>78.331446</td>\n",
       "      <td>644.238770</td>\n",
       "      <td>343.081349</td>\n",
       "      <td>73.948300</td>\n",
       "      <td>647.688171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>442.378817</td>\n",
       "      <td>84.749618</td>\n",
       "      <td>560.543152</td>\n",
       "      <td>387.160214</td>\n",
       "      <td>64.220309</td>\n",
       "      <td>552.563843</td>\n",
       "      <td>329.152205</td>\n",
       "      <td>59.693876</td>\n",
       "      <td>539.836060</td>\n",
       "      <td>284.918273</td>\n",
       "      <td>...</td>\n",
       "      <td>522.445679</td>\n",
       "      <td>279.583893</td>\n",
       "      <td>124.705299</td>\n",
       "      <td>502.111938</td>\n",
       "      <td>245.445572</td>\n",
       "      <td>134.200359</td>\n",
       "      <td>494.163727</td>\n",
       "      <td>219.651387</td>\n",
       "      <td>143.386746</td>\n",
       "      <td>493.035034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10400 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cam1_X00_in  cam1_Y00_in  cam1_Z00_in  cam1_X01_in  cam1_Y01_in  \\\n",
       "0       743.123345   171.452410   664.112915   806.416982   156.730690   \n",
       "1       632.684383    51.868599   741.745667   578.401790    20.912088   \n",
       "2       333.535070  -155.549948   796.472168   270.331367  -150.541812   \n",
       "3       224.871843    32.556823   781.035034   199.500594   -10.916714   \n",
       "4       615.849703    38.403163   730.573730   582.035489     3.258603   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10395   450.549237   107.555878   578.841797   430.854739    65.083729   \n",
       "10396   753.124368    58.692086   817.966309   784.649226     9.614661   \n",
       "10397   610.340981    27.480328   643.860046   577.750896    -5.992889   \n",
       "10398   564.257620    78.360995   650.537781   519.177287    40.719941   \n",
       "10399   442.378817    84.749618   560.543152   387.160214    64.220309   \n",
       "\n",
       "       cam1_Z01_in  cam1_X02_in  cam1_Y02_in  cam1_Z02_in  cam1_X03_in  ...  \\\n",
       "0       689.641602   813.150030   136.019235   686.213379   771.749168  ...   \n",
       "1       747.945801   479.663022    12.100841   701.973511   417.889550  ...   \n",
       "2       826.316528   218.788598  -158.240785   828.830078   181.561901  ...   \n",
       "3       806.637207   156.942292   -45.379594   824.041748   123.669363  ...   \n",
       "4       713.746521   536.439438   -22.364605   697.377319   499.273383  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "10395   593.544250   389.830267    44.015018   615.353577   335.085761  ...   \n",
       "10396   853.159790   793.110710   -23.452980   904.951782   737.386025  ...   \n",
       "10397   649.838623   517.925825   -19.180636   646.730103   472.098329  ...   \n",
       "10398   633.592712   468.754716    14.673351   624.565369   421.964621  ...   \n",
       "10399   552.563843   329.152205    59.693876   539.836060   284.918273  ...   \n",
       "\n",
       "       cam1_Z17_in  cam1_X18_in  cam1_Y18_in  cam1_Z18_in  cam1_X19_in  \\\n",
       "0       707.295715   682.808819   135.650830   703.877136   693.793886   \n",
       "1       715.926453   464.224760    75.380606   706.878296   424.448473   \n",
       "2       796.132996   187.065664  -164.732348   813.638794   175.810343   \n",
       "3       775.100647    52.284971    76.905354   768.202271    22.824038   \n",
       "4       703.424805   482.505275    30.173349   719.204712   496.142542   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10395   591.653503   297.741129   163.192664   611.219238   270.714084   \n",
       "10396   879.398865   659.451409    64.140597   896.927795   658.921691   \n",
       "10397   633.789734   454.090510    52.647196   655.347412   456.195301   \n",
       "10398   625.928589   393.411515    82.424300   627.251892   366.865095   \n",
       "10399   522.445679   279.583893   124.705299   502.111938   245.445572   \n",
       "\n",
       "       cam1_Y19_in  cam1_Z19_in  cam1_X20_in  cam1_Y20_in  cam1_Z20_in  \n",
       "0       129.494983   690.344849   696.750916   141.048865   682.862427  \n",
       "1        71.683153   690.033569   406.300806    72.008677   703.126099  \n",
       "2      -146.212779   834.935913   176.400728  -136.505687   860.233032  \n",
       "3        90.063794   769.679077    -2.450192   100.559907   773.636292  \n",
       "4        32.467161   717.115601   513.508734    32.484529   707.200928  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "10395   155.770524   617.077454   253.347195   144.378529   619.201477  \n",
       "10396    53.119792   890.006897   663.070039    50.110716   879.505981  \n",
       "10397    56.267694   641.569031   472.176362    55.904058   639.656799  \n",
       "10398    78.331446   644.238770   343.081349    73.948300   647.688171  \n",
       "10399   134.200359   494.163727   219.651387   143.386746   493.035034  \n",
       "\n",
       "[10400 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_1 = X_train.iloc[..., :21 * 3]\n",
    "X_train_cam_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee55c3e-71d3-4dc6-b957-e728cac4350a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cam1_X00_in</th>\n",
       "      <th>cam1_Y00_in</th>\n",
       "      <th>cam1_Z00_in</th>\n",
       "      <th>cam1_X01_in</th>\n",
       "      <th>cam1_Y01_in</th>\n",
       "      <th>cam1_Z01_in</th>\n",
       "      <th>cam1_X02_in</th>\n",
       "      <th>cam1_Y02_in</th>\n",
       "      <th>cam1_Z02_in</th>\n",
       "      <th>cam1_X03_in</th>\n",
       "      <th>...</th>\n",
       "      <th>cam1_Z17_in</th>\n",
       "      <th>cam1_X18_in</th>\n",
       "      <th>cam1_Y18_in</th>\n",
       "      <th>cam1_Z18_in</th>\n",
       "      <th>cam1_X19_in</th>\n",
       "      <th>cam1_Y19_in</th>\n",
       "      <th>cam1_Z19_in</th>\n",
       "      <th>cam1_X20_in</th>\n",
       "      <th>cam1_Y20_in</th>\n",
       "      <th>cam1_Z20_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>527.040721</td>\n",
       "      <td>46.981908</td>\n",
       "      <td>786.940419</td>\n",
       "      <td>482.745531</td>\n",
       "      <td>25.758607</td>\n",
       "      <td>780.269398</td>\n",
       "      <td>437.626127</td>\n",
       "      <td>9.868326</td>\n",
       "      <td>772.101365</td>\n",
       "      <td>407.559232</td>\n",
       "      <td>...</td>\n",
       "      <td>772.031947</td>\n",
       "      <td>435.414491</td>\n",
       "      <td>54.328464</td>\n",
       "      <td>766.424993</td>\n",
       "      <td>433.823875</td>\n",
       "      <td>56.462562</td>\n",
       "      <td>779.082365</td>\n",
       "      <td>471.111673</td>\n",
       "      <td>59.193351</td>\n",
       "      <td>841.642392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>195.714362</td>\n",
       "      <td>66.966368</td>\n",
       "      <td>121.163930</td>\n",
       "      <td>190.955506</td>\n",
       "      <td>68.284276</td>\n",
       "      <td>106.653667</td>\n",
       "      <td>197.572310</td>\n",
       "      <td>74.254153</td>\n",
       "      <td>109.586212</td>\n",
       "      <td>224.185540</td>\n",
       "      <td>...</td>\n",
       "      <td>224.416968</td>\n",
       "      <td>238.625899</td>\n",
       "      <td>85.250834</td>\n",
       "      <td>153.658838</td>\n",
       "      <td>305.878377</td>\n",
       "      <td>91.296952</td>\n",
       "      <td>252.138544</td>\n",
       "      <td>528.750173</td>\n",
       "      <td>116.921357</td>\n",
       "      <td>524.568155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-233.129104</td>\n",
       "      <td>-221.150595</td>\n",
       "      <td>291.539154</td>\n",
       "      <td>-253.623570</td>\n",
       "      <td>-208.817049</td>\n",
       "      <td>334.791809</td>\n",
       "      <td>-279.854895</td>\n",
       "      <td>-268.933229</td>\n",
       "      <td>334.554901</td>\n",
       "      <td>-1429.941772</td>\n",
       "      <td>...</td>\n",
       "      <td>335.497559</td>\n",
       "      <td>-281.970597</td>\n",
       "      <td>-304.500552</td>\n",
       "      <td>298.436646</td>\n",
       "      <td>-260.808829</td>\n",
       "      <td>-1137.935783</td>\n",
       "      <td>295.645935</td>\n",
       "      <td>-1474.206075</td>\n",
       "      <td>-1648.794793</td>\n",
       "      <td>295.564636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>400.259024</td>\n",
       "      <td>9.588794</td>\n",
       "      <td>725.946915</td>\n",
       "      <td>349.926617</td>\n",
       "      <td>-14.563588</td>\n",
       "      <td>713.135498</td>\n",
       "      <td>302.185748</td>\n",
       "      <td>-35.780749</td>\n",
       "      <td>703.876770</td>\n",
       "      <td>267.719807</td>\n",
       "      <td>...</td>\n",
       "      <td>700.673614</td>\n",
       "      <td>296.226343</td>\n",
       "      <td>0.058609</td>\n",
       "      <td>694.102066</td>\n",
       "      <td>283.164670</td>\n",
       "      <td>0.677281</td>\n",
       "      <td>691.153534</td>\n",
       "      <td>281.240989</td>\n",
       "      <td>-1.147976</td>\n",
       "      <td>695.135727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>531.815183</td>\n",
       "      <td>49.265005</td>\n",
       "      <td>792.279266</td>\n",
       "      <td>488.281617</td>\n",
       "      <td>24.723895</td>\n",
       "      <td>780.983154</td>\n",
       "      <td>444.088588</td>\n",
       "      <td>6.021037</td>\n",
       "      <td>772.184174</td>\n",
       "      <td>408.975504</td>\n",
       "      <td>...</td>\n",
       "      <td>764.167968</td>\n",
       "      <td>413.839695</td>\n",
       "      <td>56.365481</td>\n",
       "      <td>757.976044</td>\n",
       "      <td>403.046101</td>\n",
       "      <td>56.982994</td>\n",
       "      <td>757.850708</td>\n",
       "      <td>407.080629</td>\n",
       "      <td>58.802425</td>\n",
       "      <td>772.401611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>639.017085</td>\n",
       "      <td>81.557176</td>\n",
       "      <td>855.163818</td>\n",
       "      <td>599.073294</td>\n",
       "      <td>61.284230</td>\n",
       "      <td>852.255737</td>\n",
       "      <td>553.501655</td>\n",
       "      <td>50.839302</td>\n",
       "      <td>843.450989</td>\n",
       "      <td>525.698076</td>\n",
       "      <td>...</td>\n",
       "      <td>831.483719</td>\n",
       "      <td>547.899813</td>\n",
       "      <td>104.841270</td>\n",
       "      <td>828.756409</td>\n",
       "      <td>539.244485</td>\n",
       "      <td>110.016519</td>\n",
       "      <td>834.582489</td>\n",
       "      <td>550.177143</td>\n",
       "      <td>116.908565</td>\n",
       "      <td>868.976807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6572.718144</td>\n",
       "      <td>520.388347</td>\n",
       "      <td>7537.995605</td>\n",
       "      <td>1935.463777</td>\n",
       "      <td>531.310725</td>\n",
       "      <td>3057.377441</td>\n",
       "      <td>2583.350013</td>\n",
       "      <td>566.229551</td>\n",
       "      <td>3147.678467</td>\n",
       "      <td>9882.863324</td>\n",
       "      <td>...</td>\n",
       "      <td>8255.999023</td>\n",
       "      <td>9299.359106</td>\n",
       "      <td>1048.306701</td>\n",
       "      <td>8255.999023</td>\n",
       "      <td>10111.592765</td>\n",
       "      <td>713.088042</td>\n",
       "      <td>8127.000000</td>\n",
       "      <td>10460.586370</td>\n",
       "      <td>1261.682809</td>\n",
       "      <td>10198.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cam1_X00_in   cam1_Y00_in   cam1_Z00_in   cam1_X01_in   cam1_Y01_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     527.040721     46.981908    786.940419    482.745531     25.758607   \n",
       "std      195.714362     66.966368    121.163930    190.955506     68.284276   \n",
       "min     -233.129104   -221.150595    291.539154   -253.623570   -208.817049   \n",
       "25%      400.259024      9.588794    725.946915    349.926617    -14.563588   \n",
       "50%      531.815183     49.265005    792.279266    488.281617     24.723895   \n",
       "75%      639.017085     81.557176    855.163818    599.073294     61.284230   \n",
       "max     6572.718144    520.388347   7537.995605   1935.463777    531.310725   \n",
       "\n",
       "        cam1_Z01_in   cam1_X02_in   cam1_Y02_in   cam1_Z02_in   cam1_X03_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     780.269398    437.626127      9.868326    772.101365    407.559232   \n",
       "std      106.653667    197.572310     74.254153    109.586212    224.185540   \n",
       "min      334.791809   -279.854895   -268.933229    334.554901  -1429.941772   \n",
       "25%      713.135498    302.185748    -35.780749    703.876770    267.719807   \n",
       "50%      780.983154    444.088588      6.021037    772.184174    408.975504   \n",
       "75%      852.255737    553.501655     50.839302    843.450989    525.698076   \n",
       "max     3057.377441   2583.350013    566.229551   3147.678467   9882.863324   \n",
       "\n",
       "       ...   cam1_Z17_in   cam1_X18_in   cam1_Y18_in   cam1_Z18_in  \\\n",
       "count  ...  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean   ...    772.031947    435.414491     54.328464    766.424993   \n",
       "std    ...    224.416968    238.625899     85.250834    153.658838   \n",
       "min    ...    335.497559   -281.970597   -304.500552    298.436646   \n",
       "25%    ...    700.673614    296.226343      0.058609    694.102066   \n",
       "50%    ...    764.167968    413.839695     56.365481    757.976044   \n",
       "75%    ...    831.483719    547.899813    104.841270    828.756409   \n",
       "max    ...   8255.999023   9299.359106   1048.306701   8255.999023   \n",
       "\n",
       "        cam1_X19_in   cam1_Y19_in   cam1_Z19_in   cam1_X20_in   cam1_Y20_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     433.823875     56.462562    779.082365    471.111673     59.193351   \n",
       "std      305.878377     91.296952    252.138544    528.750173    116.921357   \n",
       "min     -260.808829  -1137.935783    295.645935  -1474.206075  -1648.794793   \n",
       "25%      283.164670      0.677281    691.153534    281.240989     -1.147976   \n",
       "50%      403.046101     56.982994    757.850708    407.080629     58.802425   \n",
       "75%      539.244485    110.016519    834.582489    550.177143    116.908565   \n",
       "max    10111.592765    713.088042   8127.000000  10460.586370   1261.682809   \n",
       "\n",
       "        cam1_Z20_in  \n",
       "count  10400.000000  \n",
       "mean     841.642392  \n",
       "std      524.568155  \n",
       "min      295.564636  \n",
       "25%      695.135727  \n",
       "50%      772.401611  \n",
       "75%      868.976807  \n",
       "max    10198.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6e624-b828-40c4-b9a2-cc3bf972d3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b998463-d476-456a-8961-8ed4de1f678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7563b-53f7-4baf-b344-169b992fadf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87a35e35-677b-44f0-b567-3baad1989be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cam2_X00_in</th>\n",
       "      <th>cam2_Y00_in</th>\n",
       "      <th>cam2_Z00_in</th>\n",
       "      <th>cam2_X01_in</th>\n",
       "      <th>cam2_Y01_in</th>\n",
       "      <th>cam2_Z01_in</th>\n",
       "      <th>cam2_X02_in</th>\n",
       "      <th>cam2_Y02_in</th>\n",
       "      <th>cam2_Z02_in</th>\n",
       "      <th>cam2_X03_in</th>\n",
       "      <th>...</th>\n",
       "      <th>cam2_Z17_in</th>\n",
       "      <th>cam2_X18_in</th>\n",
       "      <th>cam2_Y18_in</th>\n",
       "      <th>cam2_Z18_in</th>\n",
       "      <th>cam2_X19_in</th>\n",
       "      <th>cam2_Y19_in</th>\n",
       "      <th>cam2_Z19_in</th>\n",
       "      <th>cam2_X20_in</th>\n",
       "      <th>cam2_Y20_in</th>\n",
       "      <th>cam2_Z20_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>476.524627</td>\n",
       "      <td>151.164865</td>\n",
       "      <td>652.950391</td>\n",
       "      <td>453.981175</td>\n",
       "      <td>127.024251</td>\n",
       "      <td>621.302899</td>\n",
       "      <td>459.160505</td>\n",
       "      <td>110.410108</td>\n",
       "      <td>588.392661</td>\n",
       "      <td>463.151778</td>\n",
       "      <td>...</td>\n",
       "      <td>605.961058</td>\n",
       "      <td>458.931184</td>\n",
       "      <td>103.124292</td>\n",
       "      <td>609.520865</td>\n",
       "      <td>460.712001</td>\n",
       "      <td>108.720953</td>\n",
       "      <td>620.577848</td>\n",
       "      <td>455.619138</td>\n",
       "      <td>120.829000</td>\n",
       "      <td>620.924727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>407.480575</td>\n",
       "      <td>64.247100</td>\n",
       "      <td>672.886557</td>\n",
       "      <td>355.788708</td>\n",
       "      <td>36.523227</td>\n",
       "      <td>672.071631</td>\n",
       "      <td>342.002142</td>\n",
       "      <td>16.105776</td>\n",
       "      <td>658.855517</td>\n",
       "      <td>329.165946</td>\n",
       "      <td>...</td>\n",
       "      <td>606.958290</td>\n",
       "      <td>322.599618</td>\n",
       "      <td>60.802133</td>\n",
       "      <td>585.555372</td>\n",
       "      <td>306.745356</td>\n",
       "      <td>60.668783</td>\n",
       "      <td>573.475558</td>\n",
       "      <td>294.235111</td>\n",
       "      <td>59.071840</td>\n",
       "      <td>561.343301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.120986</td>\n",
       "      <td>-112.832419</td>\n",
       "      <td>734.581455</td>\n",
       "      <td>156.466255</td>\n",
       "      <td>-104.876903</td>\n",
       "      <td>749.928186</td>\n",
       "      <td>185.775029</td>\n",
       "      <td>-133.125632</td>\n",
       "      <td>778.013094</td>\n",
       "      <td>148.950205</td>\n",
       "      <td>...</td>\n",
       "      <td>700.399140</td>\n",
       "      <td>173.240957</td>\n",
       "      <td>-143.524328</td>\n",
       "      <td>714.276310</td>\n",
       "      <td>161.973831</td>\n",
       "      <td>-125.610727</td>\n",
       "      <td>729.851608</td>\n",
       "      <td>154.634818</td>\n",
       "      <td>-112.544457</td>\n",
       "      <td>741.845319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.306465</td>\n",
       "      <td>32.493386</td>\n",
       "      <td>719.925148</td>\n",
       "      <td>134.205016</td>\n",
       "      <td>2.342387</td>\n",
       "      <td>733.060738</td>\n",
       "      <td>130.601136</td>\n",
       "      <td>-29.476404</td>\n",
       "      <td>737.076331</td>\n",
       "      <td>113.717047</td>\n",
       "      <td>...</td>\n",
       "      <td>694.710542</td>\n",
       "      <td>90.598574</td>\n",
       "      <td>59.981087</td>\n",
       "      <td>678.608405</td>\n",
       "      <td>76.396004</td>\n",
       "      <td>72.395661</td>\n",
       "      <td>670.620985</td>\n",
       "      <td>55.171114</td>\n",
       "      <td>80.043650</td>\n",
       "      <td>665.112023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378.441822</td>\n",
       "      <td>27.714581</td>\n",
       "      <td>663.289980</td>\n",
       "      <td>359.443206</td>\n",
       "      <td>2.441910</td>\n",
       "      <td>664.750585</td>\n",
       "      <td>345.271157</td>\n",
       "      <td>-20.703539</td>\n",
       "      <td>652.218553</td>\n",
       "      <td>317.035275</td>\n",
       "      <td>...</td>\n",
       "      <td>583.425200</td>\n",
       "      <td>344.461626</td>\n",
       "      <td>21.492119</td>\n",
       "      <td>603.339625</td>\n",
       "      <td>343.822801</td>\n",
       "      <td>21.383245</td>\n",
       "      <td>624.249550</td>\n",
       "      <td>350.128085</td>\n",
       "      <td>23.217901</td>\n",
       "      <td>635.772211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>229.763598</td>\n",
       "      <td>77.981610</td>\n",
       "      <td>517.441028</td>\n",
       "      <td>312.278181</td>\n",
       "      <td>66.922947</td>\n",
       "      <td>494.115623</td>\n",
       "      <td>307.590350</td>\n",
       "      <td>48.484657</td>\n",
       "      <td>493.690578</td>\n",
       "      <td>3999.412364</td>\n",
       "      <td>...</td>\n",
       "      <td>489.552183</td>\n",
       "      <td>267.024971</td>\n",
       "      <td>138.925063</td>\n",
       "      <td>485.505866</td>\n",
       "      <td>259.084412</td>\n",
       "      <td>139.218641</td>\n",
       "      <td>506.352200</td>\n",
       "      <td>255.282935</td>\n",
       "      <td>136.624106</td>\n",
       "      <td>525.749020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>502.170729</td>\n",
       "      <td>64.061695</td>\n",
       "      <td>716.645856</td>\n",
       "      <td>518.880649</td>\n",
       "      <td>23.976928</td>\n",
       "      <td>736.748151</td>\n",
       "      <td>484.412784</td>\n",
       "      <td>-5.901593</td>\n",
       "      <td>769.541232</td>\n",
       "      <td>494.666066</td>\n",
       "      <td>...</td>\n",
       "      <td>781.875119</td>\n",
       "      <td>459.155812</td>\n",
       "      <td>66.715449</td>\n",
       "      <td>830.913235</td>\n",
       "      <td>460.564911</td>\n",
       "      <td>59.006385</td>\n",
       "      <td>843.334936</td>\n",
       "      <td>460.775454</td>\n",
       "      <td>54.186553</td>\n",
       "      <td>843.871622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>343.240746</td>\n",
       "      <td>46.263389</td>\n",
       "      <td>579.819874</td>\n",
       "      <td>342.845078</td>\n",
       "      <td>24.398177</td>\n",
       "      <td>589.644140</td>\n",
       "      <td>377.153111</td>\n",
       "      <td>2.671945</td>\n",
       "      <td>591.321848</td>\n",
       "      <td>367.550315</td>\n",
       "      <td>...</td>\n",
       "      <td>508.460994</td>\n",
       "      <td>365.491664</td>\n",
       "      <td>42.982239</td>\n",
       "      <td>512.498106</td>\n",
       "      <td>357.384796</td>\n",
       "      <td>44.776668</td>\n",
       "      <td>523.096218</td>\n",
       "      <td>351.821857</td>\n",
       "      <td>44.132049</td>\n",
       "      <td>529.974711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>374.519657</td>\n",
       "      <td>70.044368</td>\n",
       "      <td>578.663998</td>\n",
       "      <td>366.665594</td>\n",
       "      <td>45.112380</td>\n",
       "      <td>581.332848</td>\n",
       "      <td>362.462765</td>\n",
       "      <td>20.092347</td>\n",
       "      <td>574.218053</td>\n",
       "      <td>321.962419</td>\n",
       "      <td>...</td>\n",
       "      <td>521.875182</td>\n",
       "      <td>294.831997</td>\n",
       "      <td>62.961281</td>\n",
       "      <td>502.577135</td>\n",
       "      <td>297.456713</td>\n",
       "      <td>60.480262</td>\n",
       "      <td>518.905116</td>\n",
       "      <td>297.041799</td>\n",
       "      <td>58.116418</td>\n",
       "      <td>536.090517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>298.693094</td>\n",
       "      <td>90.074505</td>\n",
       "      <td>467.339275</td>\n",
       "      <td>287.272172</td>\n",
       "      <td>79.536221</td>\n",
       "      <td>487.568279</td>\n",
       "      <td>254.038413</td>\n",
       "      <td>64.633767</td>\n",
       "      <td>495.204251</td>\n",
       "      <td>254.155065</td>\n",
       "      <td>...</td>\n",
       "      <td>378.545104</td>\n",
       "      <td>275.890157</td>\n",
       "      <td>109.039811</td>\n",
       "      <td>354.542039</td>\n",
       "      <td>256.737037</td>\n",
       "      <td>114.651695</td>\n",
       "      <td>345.003271</td>\n",
       "      <td>250.369405</td>\n",
       "      <td>122.171909</td>\n",
       "      <td>330.139932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10400 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cam2_X00_in  cam2_Y00_in  cam2_Z00_in  cam2_X01_in  cam2_Y01_in  \\\n",
       "0       476.524627   151.164865   652.950391   453.981175   127.024251   \n",
       "1       407.480575    64.247100   672.886557   355.788708    36.523227   \n",
       "2       244.120986  -112.832419   734.581455   156.466255  -104.876903   \n",
       "3       136.306465    32.493386   719.925148   134.205016     2.342387   \n",
       "4       378.441822    27.714581   663.289980   359.443206     2.441910   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10395   229.763598    77.981610   517.441028   312.278181    66.922947   \n",
       "10396   502.170729    64.061695   716.645856   518.880649    23.976928   \n",
       "10397   343.240746    46.263389   579.819874   342.845078    24.398177   \n",
       "10398   374.519657    70.044368   578.663998   366.665594    45.112380   \n",
       "10399   298.693094    90.074505   467.339275   287.272172    79.536221   \n",
       "\n",
       "       cam2_Z01_in  cam2_X02_in  cam2_Y02_in  cam2_Z02_in  cam2_X03_in  ...  \\\n",
       "0       621.302899   459.160505   110.410108   588.392661   463.151778  ...   \n",
       "1       672.071631   342.002142    16.105776   658.855517   329.165946  ...   \n",
       "2       749.928186   185.775029  -133.125632   778.013094   148.950205  ...   \n",
       "3       733.060738   130.601136   -29.476404   737.076331   113.717047  ...   \n",
       "4       664.750585   345.271157   -20.703539   652.218553   317.035275  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "10395   494.115623   307.590350    48.484657   493.690578  3999.412364  ...   \n",
       "10396   736.748151   484.412784    -5.901593   769.541232   494.666066  ...   \n",
       "10397   589.644140   377.153111     2.671945   591.321848   367.550315  ...   \n",
       "10398   581.332848   362.462765    20.092347   574.218053   321.962419  ...   \n",
       "10399   487.568279   254.038413    64.633767   495.204251   254.155065  ...   \n",
       "\n",
       "       cam2_Z17_in  cam2_X18_in  cam2_Y18_in  cam2_Z18_in  cam2_X19_in  \\\n",
       "0       605.961058   458.931184   103.124292   609.520865   460.712001   \n",
       "1       606.958290   322.599618    60.802133   585.555372   306.745356   \n",
       "2       700.399140   173.240957  -143.524328   714.276310   161.973831   \n",
       "3       694.710542    90.598574    59.981087   678.608405    76.396004   \n",
       "4       583.425200   344.461626    21.492119   603.339625   343.822801   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10395   489.552183   267.024971   138.925063   485.505866   259.084412   \n",
       "10396   781.875119   459.155812    66.715449   830.913235   460.564911   \n",
       "10397   508.460994   365.491664    42.982239   512.498106   357.384796   \n",
       "10398   521.875182   294.831997    62.961281   502.577135   297.456713   \n",
       "10399   378.545104   275.890157   109.039811   354.542039   256.737037   \n",
       "\n",
       "       cam2_Y19_in  cam2_Z19_in  cam2_X20_in  cam2_Y20_in  cam2_Z20_in  \n",
       "0       108.720953   620.577848   455.619138   120.829000   620.924727  \n",
       "1        60.668783   573.475558   294.235111    59.071840   561.343301  \n",
       "2      -125.610727   729.851608   154.634818  -112.544457   741.845319  \n",
       "3        72.395661   670.620985    55.171114    80.043650   665.112023  \n",
       "4        21.383245   624.249550   350.128085    23.217901   635.772211  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "10395   139.218641   506.352200   255.282935   136.624106   525.749020  \n",
       "10396    59.006385   843.334936   460.775454    54.186553   843.871622  \n",
       "10397    44.776668   523.096218   351.821857    44.132049   529.974711  \n",
       "10398    60.480262   518.905116   297.041799    58.116418   536.090517  \n",
       "10399   114.651695   345.003271   250.369405   122.171909   330.139932  \n",
       "\n",
       "[10400 rows x 63 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_2 = X_train.iloc[..., 21 * 3:]\n",
    "X_train_cam_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "973d32e7-baa5-4cb8-9f83-8671458aa3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cam1_Z00_in    121.163930\n",
       "cam1_Z01_in    106.653667\n",
       "cam1_Z02_in    109.586212\n",
       "cam1_Z03_in    148.632455\n",
       "cam1_Z04_in    559.415115\n",
       "cam1_Z05_in    182.967591\n",
       "cam1_Z06_in    207.494309\n",
       "cam1_Z07_in    306.467479\n",
       "cam1_Z08_in    889.801162\n",
       "cam1_Z09_in    175.114157\n",
       "cam1_Z10_in    200.242178\n",
       "cam1_Z11_in    240.783263\n",
       "cam1_Z12_in    687.534074\n",
       "cam1_Z13_in    223.930215\n",
       "cam1_Z14_in    140.993554\n",
       "cam1_Z15_in    182.512236\n",
       "cam1_Z16_in    412.906371\n",
       "cam1_Z17_in    224.416968\n",
       "cam1_Z18_in    153.658838\n",
       "cam1_Z19_in    252.138544\n",
       "cam1_Z20_in    524.568155\n",
       "Name: std, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_1.describe().iloc[2, 2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db635861-f136-467b-8ef3-e8e7b40fb29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cam1_X00_in</th>\n",
       "      <th>cam1_Y00_in</th>\n",
       "      <th>cam1_Z00_in</th>\n",
       "      <th>cam1_X01_in</th>\n",
       "      <th>cam1_Y01_in</th>\n",
       "      <th>cam1_Z01_in</th>\n",
       "      <th>cam1_X02_in</th>\n",
       "      <th>cam1_Y02_in</th>\n",
       "      <th>cam1_Z02_in</th>\n",
       "      <th>cam1_X03_in</th>\n",
       "      <th>...</th>\n",
       "      <th>cam1_Z17_in</th>\n",
       "      <th>cam1_X18_in</th>\n",
       "      <th>cam1_Y18_in</th>\n",
       "      <th>cam1_Z18_in</th>\n",
       "      <th>cam1_X19_in</th>\n",
       "      <th>cam1_Y19_in</th>\n",
       "      <th>cam1_Z19_in</th>\n",
       "      <th>cam1_X20_in</th>\n",
       "      <th>cam1_Y20_in</th>\n",
       "      <th>cam1_Z20_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "      <td>10400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>527.040721</td>\n",
       "      <td>46.981908</td>\n",
       "      <td>786.940419</td>\n",
       "      <td>482.745531</td>\n",
       "      <td>25.758607</td>\n",
       "      <td>780.269398</td>\n",
       "      <td>437.626127</td>\n",
       "      <td>9.868326</td>\n",
       "      <td>772.101365</td>\n",
       "      <td>407.559232</td>\n",
       "      <td>...</td>\n",
       "      <td>772.031947</td>\n",
       "      <td>435.414491</td>\n",
       "      <td>54.328464</td>\n",
       "      <td>766.424993</td>\n",
       "      <td>433.823875</td>\n",
       "      <td>56.462562</td>\n",
       "      <td>779.082365</td>\n",
       "      <td>471.111673</td>\n",
       "      <td>59.193351</td>\n",
       "      <td>841.642392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>195.714362</td>\n",
       "      <td>66.966368</td>\n",
       "      <td>121.163930</td>\n",
       "      <td>190.955506</td>\n",
       "      <td>68.284276</td>\n",
       "      <td>106.653667</td>\n",
       "      <td>197.572310</td>\n",
       "      <td>74.254153</td>\n",
       "      <td>109.586212</td>\n",
       "      <td>224.185540</td>\n",
       "      <td>...</td>\n",
       "      <td>224.416968</td>\n",
       "      <td>238.625899</td>\n",
       "      <td>85.250834</td>\n",
       "      <td>153.658838</td>\n",
       "      <td>305.878377</td>\n",
       "      <td>91.296952</td>\n",
       "      <td>252.138544</td>\n",
       "      <td>528.750173</td>\n",
       "      <td>116.921357</td>\n",
       "      <td>524.568155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-233.129104</td>\n",
       "      <td>-221.150595</td>\n",
       "      <td>291.539154</td>\n",
       "      <td>-253.623570</td>\n",
       "      <td>-208.817049</td>\n",
       "      <td>334.791809</td>\n",
       "      <td>-279.854895</td>\n",
       "      <td>-268.933229</td>\n",
       "      <td>334.554901</td>\n",
       "      <td>-1429.941772</td>\n",
       "      <td>...</td>\n",
       "      <td>335.497559</td>\n",
       "      <td>-281.970597</td>\n",
       "      <td>-304.500552</td>\n",
       "      <td>298.436646</td>\n",
       "      <td>-260.808829</td>\n",
       "      <td>-1137.935783</td>\n",
       "      <td>295.645935</td>\n",
       "      <td>-1474.206075</td>\n",
       "      <td>-1648.794793</td>\n",
       "      <td>295.564636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>400.259024</td>\n",
       "      <td>9.588794</td>\n",
       "      <td>725.946915</td>\n",
       "      <td>349.926617</td>\n",
       "      <td>-14.563588</td>\n",
       "      <td>713.135498</td>\n",
       "      <td>302.185748</td>\n",
       "      <td>-35.780749</td>\n",
       "      <td>703.876770</td>\n",
       "      <td>267.719807</td>\n",
       "      <td>...</td>\n",
       "      <td>700.673614</td>\n",
       "      <td>296.226343</td>\n",
       "      <td>0.058609</td>\n",
       "      <td>694.102066</td>\n",
       "      <td>283.164670</td>\n",
       "      <td>0.677281</td>\n",
       "      <td>691.153534</td>\n",
       "      <td>281.240989</td>\n",
       "      <td>-1.147976</td>\n",
       "      <td>695.135727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>531.815183</td>\n",
       "      <td>49.265005</td>\n",
       "      <td>792.279266</td>\n",
       "      <td>488.281617</td>\n",
       "      <td>24.723895</td>\n",
       "      <td>780.983154</td>\n",
       "      <td>444.088588</td>\n",
       "      <td>6.021037</td>\n",
       "      <td>772.184174</td>\n",
       "      <td>408.975504</td>\n",
       "      <td>...</td>\n",
       "      <td>764.167968</td>\n",
       "      <td>413.839695</td>\n",
       "      <td>56.365481</td>\n",
       "      <td>757.976044</td>\n",
       "      <td>403.046101</td>\n",
       "      <td>56.982994</td>\n",
       "      <td>757.850708</td>\n",
       "      <td>407.080629</td>\n",
       "      <td>58.802425</td>\n",
       "      <td>772.401611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>639.017085</td>\n",
       "      <td>81.557176</td>\n",
       "      <td>855.163818</td>\n",
       "      <td>599.073294</td>\n",
       "      <td>61.284230</td>\n",
       "      <td>852.255737</td>\n",
       "      <td>553.501655</td>\n",
       "      <td>50.839302</td>\n",
       "      <td>843.450989</td>\n",
       "      <td>525.698076</td>\n",
       "      <td>...</td>\n",
       "      <td>831.483719</td>\n",
       "      <td>547.899813</td>\n",
       "      <td>104.841270</td>\n",
       "      <td>828.756409</td>\n",
       "      <td>539.244485</td>\n",
       "      <td>110.016519</td>\n",
       "      <td>834.582489</td>\n",
       "      <td>550.177143</td>\n",
       "      <td>116.908565</td>\n",
       "      <td>868.976807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6572.718144</td>\n",
       "      <td>520.388347</td>\n",
       "      <td>7537.995605</td>\n",
       "      <td>1935.463777</td>\n",
       "      <td>531.310725</td>\n",
       "      <td>3057.377441</td>\n",
       "      <td>2583.350013</td>\n",
       "      <td>566.229551</td>\n",
       "      <td>3147.678467</td>\n",
       "      <td>9882.863324</td>\n",
       "      <td>...</td>\n",
       "      <td>8255.999023</td>\n",
       "      <td>9299.359106</td>\n",
       "      <td>1048.306701</td>\n",
       "      <td>8255.999023</td>\n",
       "      <td>10111.592765</td>\n",
       "      <td>713.088042</td>\n",
       "      <td>8127.000000</td>\n",
       "      <td>10460.586370</td>\n",
       "      <td>1261.682809</td>\n",
       "      <td>10198.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cam1_X00_in   cam1_Y00_in   cam1_Z00_in   cam1_X01_in   cam1_Y01_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     527.040721     46.981908    786.940419    482.745531     25.758607   \n",
       "std      195.714362     66.966368    121.163930    190.955506     68.284276   \n",
       "min     -233.129104   -221.150595    291.539154   -253.623570   -208.817049   \n",
       "25%      400.259024      9.588794    725.946915    349.926617    -14.563588   \n",
       "50%      531.815183     49.265005    792.279266    488.281617     24.723895   \n",
       "75%      639.017085     81.557176    855.163818    599.073294     61.284230   \n",
       "max     6572.718144    520.388347   7537.995605   1935.463777    531.310725   \n",
       "\n",
       "        cam1_Z01_in   cam1_X02_in   cam1_Y02_in   cam1_Z02_in   cam1_X03_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     780.269398    437.626127      9.868326    772.101365    407.559232   \n",
       "std      106.653667    197.572310     74.254153    109.586212    224.185540   \n",
       "min      334.791809   -279.854895   -268.933229    334.554901  -1429.941772   \n",
       "25%      713.135498    302.185748    -35.780749    703.876770    267.719807   \n",
       "50%      780.983154    444.088588      6.021037    772.184174    408.975504   \n",
       "75%      852.255737    553.501655     50.839302    843.450989    525.698076   \n",
       "max     3057.377441   2583.350013    566.229551   3147.678467   9882.863324   \n",
       "\n",
       "       ...   cam1_Z17_in   cam1_X18_in   cam1_Y18_in   cam1_Z18_in  \\\n",
       "count  ...  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean   ...    772.031947    435.414491     54.328464    766.424993   \n",
       "std    ...    224.416968    238.625899     85.250834    153.658838   \n",
       "min    ...    335.497559   -281.970597   -304.500552    298.436646   \n",
       "25%    ...    700.673614    296.226343      0.058609    694.102066   \n",
       "50%    ...    764.167968    413.839695     56.365481    757.976044   \n",
       "75%    ...    831.483719    547.899813    104.841270    828.756409   \n",
       "max    ...   8255.999023   9299.359106   1048.306701   8255.999023   \n",
       "\n",
       "        cam1_X19_in   cam1_Y19_in   cam1_Z19_in   cam1_X20_in   cam1_Y20_in  \\\n",
       "count  10400.000000  10400.000000  10400.000000  10400.000000  10400.000000   \n",
       "mean     433.823875     56.462562    779.082365    471.111673     59.193351   \n",
       "std      305.878377     91.296952    252.138544    528.750173    116.921357   \n",
       "min     -260.808829  -1137.935783    295.645935  -1474.206075  -1648.794793   \n",
       "25%      283.164670      0.677281    691.153534    281.240989     -1.147976   \n",
       "50%      403.046101     56.982994    757.850708    407.080629     58.802425   \n",
       "75%      539.244485    110.016519    834.582489    550.177143    116.908565   \n",
       "max    10111.592765    713.088042   8127.000000  10460.586370   1261.682809   \n",
       "\n",
       "        cam1_Z20_in  \n",
       "count  10400.000000  \n",
       "mean     841.642392  \n",
       "std      524.568155  \n",
       "min      295.564636  \n",
       "25%      695.135727  \n",
       "50%      772.401611  \n",
       "75%      868.976807  \n",
       "max    10198.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3aa1e3ca-9bd3-47fd-81e4-ea0b7735cbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cam1_Z00_in    129.216903\n",
       "cam1_Z01_in    139.120240\n",
       "cam1_Z02_in    139.574219\n",
       "cam1_Z03_in    148.759719\n",
       "cam1_Z04_in    198.253799\n",
       "cam1_Z05_in    148.553574\n",
       "cam1_Z06_in    144.997284\n",
       "cam1_Z07_in    150.085861\n",
       "cam1_Z08_in    233.093979\n",
       "cam1_Z09_in    135.205781\n",
       "cam1_Z10_in    140.127335\n",
       "cam1_Z11_in    143.848999\n",
       "cam1_Z12_in    171.268036\n",
       "cam1_Z13_in    132.132812\n",
       "cam1_Z14_in    136.400055\n",
       "cam1_Z15_in    140.432449\n",
       "cam1_Z16_in    154.262131\n",
       "cam1_Z17_in    130.810105\n",
       "cam1_Z18_in    134.654343\n",
       "cam1_Z19_in    143.428955\n",
       "cam1_Z20_in    173.841080\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cam_1.describe().iloc[-2, 2::3] - X_train_cam_1.describe().iloc[4, 2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9bb165-4d0d-4724-a160-02f25519f5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1163ab-9c94-4fec-b773-3cbe599b571e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86ef60-0055-4077-985c-f4174a679891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255dd2d-6a4c-4400-9dcc-f4bc6e556840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43687e-8e03-4d5d-91ea-928e680eca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to plot input data\n",
    "\n",
    "num_landmarks_each_cam = 21 * 3\n",
    "X_train_cam_1 = X_train.values[:, :num_landmarks_each_cam]\n",
    "visualize_landmarks_through_frame(X_train_cam_1.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0c34cf-347c-4106-a7d3-d61a6b647015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines to plot ground truth\n",
    "\n",
    "#visualize_landmarks_through_frame(Y_train.reshape(-1, 21, 3), time_sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7650d-39f6-4b00-bbd0-5e518d25686d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c596a9-8a9d-485a-9dbd-24e372287ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7aee469-9e57-4889-bd07-5e83ef7ee7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (10400, 126)\n",
      "Y_train shape:  (10400, 63)\n",
      "X_test shape:  (2600, 126)\n",
      "Y_test shape:  (2600, 63)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb954ab-d2c8-4af4-a2bc-64bc6c9b78ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d91044-f1ae-41af-9f95-a9f31a4cfa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fdf30-3589-48a5-9e62-0b1c201f4375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492be2df-399e-4bfd-a0e1-7f3fd594c206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9427f15a-6cdd-49be-a8c2-77a4373da606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler for scaling between 0 and 1\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c985f11c-1890-4d6f-8af5-4390c590077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on the data and transform\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_test_scaled = scaler_Y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d074bc6a-c831-44b6-9d13-3a2c8cf84834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train_scaled, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 512  # Adjust according to your needs\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6de5d6f-ef2b-44c4-ad01-72f7849ba2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER_FOLDER = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/scaler\"\n",
    "\n",
    "now = datetime.now()\n",
    "year, month, day = str(now.year), str(now.month), str(now.day)\n",
    "month = \"0{}\".format(month) if len(month) == 1 else month\n",
    "day = \"0{}\".format(day) if len(day) == 1 else day\n",
    "SCALER_FOLDER = os.path.join(SCALER_FOLDER, \"{}_{}_{}\".format(year, month, day))\n",
    "\n",
    "if not os.path.exists(SCALER_FOLDER):\n",
    "    os.makedirs(SCALER_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869bc34d-0554-4403-a203-b23637fe2ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a64c8e-04ec-4b63-b9b0-30ac92b23384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebbeabc-3c0e-4cf4-b8a4-6e56f7f8c3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/scaler/2024_06_17/scaler_X.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler_X, os.path.join(SCALER_FOLDER, \"scaler_X.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26246d9b-50bf-4820-95ad-1b9b74701f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/scaler/2024_06_17/scaler_Y.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler_Y, os.path.join(SCALER_FOLDER, \"scaler_Y.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334987b-31e8-4a28-aad8-e76cd3b6da18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e038ee58-cb01-43e8-9e52-8b8f47ae65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  torch.Size([10000, 126])\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0b86b4e-3851-4475-93f3-c41506a310c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape:  torch.Size([2500, 126])\n"
     ]
    }
   ],
   "source": [
    "print('X_test shape: ', X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569a7eb-8947-4bba-bc31-aecd260d397e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547309a-6500-4010-a516-dea228cc3a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59ee2f92-9018-419e-b2b3-7ca8638ac342",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22be5adc-1633-43f4-93b6-135a6467f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_v2()\n",
    "\n",
    "#pretrained_weight = None\n",
    "pretrained_weight = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/mlp_v2_weights/2024_06_17/best_model.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"mps\"\n",
    "model.to(device)\n",
    "\n",
    "if pretrained_weight:\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(pretrained_weight))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(pretrained_weight,\n",
    "                                         map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "# Define your criterion and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Decay the learning rate by a factor of 0.1 every 1000 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=math.sqrt(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "869ce244-1636-4daf-979e-e4cef7161493",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_FOLDER = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/mlp_v2_weights\"\n",
    "WEIGHT_FOLDER = os.path.join(WEIGHT_FOLDER, \"{}_{}_{}\".format(year, month, day))\n",
    "\n",
    "if not os.path.exists(WEIGHT_FOLDER):\n",
    "    os.makedirs(WEIGHT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57872b65-fa8b-4a12-9a11-f3acc0c76967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [9/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [10/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [11/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [12/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [13/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [14/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [15/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [16/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [17/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [18/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [19/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [20/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [21/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [22/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [23/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [24/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [25/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [26/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [27/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [28/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [29/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [30/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [31/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [32/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [33/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [34/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [35/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [36/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [37/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [38/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [39/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [40/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [41/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [42/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [43/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [44/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [45/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [46/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [47/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [48/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [49/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [50/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [51/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [52/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [53/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [54/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [55/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [56/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [57/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [58/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [59/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [60/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [61/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [62/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [63/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [64/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [65/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [66/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [67/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [68/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [69/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [70/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [71/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [72/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [73/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [74/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [75/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [76/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [77/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [78/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [79/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [80/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [81/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [82/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [83/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [84/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [85/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [86/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [87/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [88/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [89/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [90/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [91/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [92/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [93/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [94/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [95/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [96/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [97/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [98/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [99/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [101/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [102/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [103/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [105/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [106/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [108/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [109/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [111/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [112/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [113/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [114/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [115/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [116/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [117/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [118/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [119/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [120/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [121/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [122/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [123/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [124/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [125/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [126/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [130/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [131/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [132/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [133/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [134/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [136/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [137/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [138/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [139/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [140/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [141/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [142/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [143/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [144/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [145/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [146/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [147/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [148/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [149/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [150/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [151/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [152/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [155/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [156/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [157/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [158/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [159/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [161/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [163/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [164/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [165/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [166/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [168/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [169/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [171/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [172/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [173/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [174/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [175/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [176/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [177/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [180/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [181/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [182/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [183/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [184/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [185/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [187/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [188/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [189/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [191/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [192/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [193/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [195/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [196/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [197/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [199/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [201/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [202/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [203/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [205/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [206/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [207/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [208/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [209/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [210/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [211/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [212/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [214/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [215/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [217/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [218/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [221/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [222/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [223/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [224/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [225/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [226/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [227/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [228/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [230/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [231/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [233/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [234/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [235/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [236/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [238/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [240/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [241/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [242/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [243/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [244/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [245/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [247/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [248/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [249/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [251/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [252/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [253/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [255/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [256/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [257/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [258/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [261/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [262/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [265/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [266/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [267/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [269/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [270/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [273/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [275/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [276/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [277/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [278/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [279/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [280/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [281/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [282/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [283/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [284/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [285/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [287/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [288/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [289/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [290/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [291/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [292/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [293/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [294/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [295/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [298/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [299/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [301/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [302/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [304/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [305/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [306/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [307/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [309/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [310/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [311/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [312/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [313/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [314/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [315/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [316/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [320/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [321/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [322/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [323/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [324/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [325/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [326/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [328/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [329/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [330/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [333/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [335/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [337/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [338/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [339/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [340/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [342/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [346/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [348/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [349/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [350/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [355/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [358/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [361/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [363/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [364/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [365/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [366/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [367/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [368/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [369/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [370/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [372/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [374/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [375/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [376/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [378/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [379/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [380/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [381/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [382/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [383/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [385/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [386/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [387/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [388/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [389/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [390/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [391/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [392/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [393/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [396/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [399/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [401/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [402/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [403/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [406/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [408/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [410/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [411/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [412/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [413/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [414/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [415/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [416/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [417/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [418/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [419/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [420/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [421/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [422/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [423/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [424/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [425/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [426/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [428/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [429/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [431/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [432/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [433/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [434/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [435/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [436/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [437/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [438/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [439/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [440/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [441/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [442/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [443/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [444/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [445/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [447/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [448/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [449/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [450/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [451/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [454/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [456/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [457/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [459/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [460/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [461/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [462/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [463/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [464/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [465/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [466/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [467/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [468/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [469/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [470/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [471/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [472/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [473/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [474/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [475/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [477/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [478/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [479/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [480/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [481/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [486/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [488/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [489/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [490/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [491/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [493/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [494/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [495/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [498/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [500/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [502/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [503/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [506/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [507/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [509/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [510/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [511/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [512/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [513/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [514/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [516/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [517/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [521/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [524/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [525/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [527/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [528/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [529/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [530/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [531/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [532/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [533/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [534/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [536/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [537/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [539/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [541/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [544/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [545/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [547/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [548/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [549/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [550/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [551/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [552/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [553/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [554/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [557/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [558/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [559/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [560/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [562/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [563/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [564/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [565/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [566/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [567/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [568/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [571/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [573/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [574/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [575/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [576/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [577/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [580/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [581/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [582/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [583/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [585/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [586/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [587/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [589/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [590/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [591/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [595/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [598/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [599/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [600/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [602/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [603/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [604/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [605/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [606/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [607/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [609/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [612/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [613/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [614/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [618/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [619/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [620/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [621/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [622/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [623/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [624/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [625/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [626/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [627/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [628/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [630/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [631/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [632/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [635/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [636/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [639/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [640/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [641/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [642/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [644/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [646/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [647/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [651/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [653/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [654/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [655/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [658/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [659/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [660/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [668/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [672/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [673/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [674/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [675/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [676/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [678/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [679/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [680/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [681/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [682/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [684/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [685/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [686/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [687/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [689/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [690/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [691/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [692/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [693/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [694/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [696/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [697/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [698/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [699/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [701/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [704/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [705/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [706/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [707/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [709/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [710/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [713/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [714/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [716/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [717/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [719/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [724/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [725/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [726/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [727/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [728/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [729/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [730/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [731/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [732/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [733/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [734/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [735/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [737/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [738/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [740/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [741/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [742/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [744/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [745/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [748/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [752/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [753/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [754/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [756/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [758/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [759/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [760/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [764/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [765/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [767/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [768/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [769/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [772/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [774/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [777/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [779/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [780/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [781/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [786/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [787/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [788/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [791/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [793/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [794/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [797/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [799/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [800/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [802/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [804/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [805/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [810/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [811/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [812/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [813/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [814/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [816/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [818/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [819/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [821/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [822/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [824/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [825/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [827/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [828/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [829/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [830/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [831/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [834/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [835/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [838/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [840/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [845/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [848/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [849/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [850/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [851/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [852/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [853/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [855/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [857/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [858/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [859/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [860/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [861/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [862/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [863/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [864/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [865/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [866/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [867/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [869/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [870/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [873/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [874/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [875/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [876/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [878/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [881/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [883/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [884/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [885/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [886/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [887/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [891/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [893/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [894/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [899/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [901/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [905/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [907/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [908/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [909/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [911/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [912/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [913/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [914/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [915/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [916/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [918/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [919/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [923/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [924/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [925/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [926/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [927/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [929/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [932/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [933/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [935/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [938/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [941/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [942/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [944/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [945/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [946/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [947/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [948/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [949/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [951/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [952/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [955/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [961/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [962/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [964/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [965/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [969/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [973/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [976/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [977/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [978/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [982/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [984/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [985/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [986/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [990/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [992/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [993/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [994/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [998/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [999/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1004/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1005/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1007/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1008/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1011/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1013/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1014/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1015/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1017/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1020/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1025/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1026/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1028/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1029/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1030/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1035/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1036/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1048/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1050/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1051/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1052/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1054/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1057/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1060/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1061/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1067/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1069/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1070/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1072/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1073/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1080/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1085/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1086/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1088/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1094/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1095/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1100/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1101/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1102/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1103/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1105/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1108/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1109/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1111/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1112/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1116/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1119/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1120/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1121/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1125/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1129/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1131/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1137/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1138/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1139/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1141/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1142/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1143/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1144/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1145/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1150/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1151/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1153/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1156/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1157/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1158/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1159/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1160/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1165/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1171/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1172/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1175/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1176/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1178/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1179/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1181/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1183/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1184/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1194/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1195/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1198/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1199/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1200/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1205/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1207/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1213/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1214/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1217/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1220/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1221/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1222/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1223/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1227/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1229/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1234/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1236/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1237/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1241/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1244/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1245/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1251/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1252/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1257/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1262/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1263/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1264/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1265/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1269/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1272/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1274/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1275/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1276/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1279/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1281/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1282/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1284/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1286/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1287/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1288/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1289/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1290/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1291/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1294/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1295/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1304/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1307/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1308/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1309/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1312/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1316/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1318/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1322/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1324/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1325/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1326/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1327/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1328/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1330/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1334/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1337/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1340/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1341/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1342/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1348/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1350/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1357/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1361/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1362/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1363/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1364/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1366/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1368/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1370/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1371/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1379/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1382/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1385/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1386/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1387/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1391/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1392/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1393/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1394/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1407/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1412/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1414/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1417/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1422/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1426/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1427/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1431/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1436/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1438/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1441/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1449/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1450/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1456/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1460/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1462/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1463/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1465/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1467/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1468/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1471/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1473/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1478/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1483/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1488/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1489/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1490/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1491/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1495/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1501/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1502/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1506/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1508/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1509/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1511/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1512/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1522/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1525/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1526/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1539/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1540/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1544/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1547/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1552/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1553/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1557/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1560/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1565/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1568/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1573/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1575/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1578/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1580/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1581/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1586/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1588/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1592/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1594/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1595/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1599/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1600/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1606/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1610/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1611/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1613/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1614/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1620/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1625/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1631/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1632/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1633/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1634/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1636/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1639/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1645/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1648/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1653/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1660/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1662/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1664/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1668/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1672/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1677/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1678/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1680/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1686/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1687/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1695/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1696/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1703/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1707/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1709/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1714/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1716/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1719/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1723/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1724/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1726/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1727/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1730/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1731/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1736/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1737/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1741/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1744/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1746/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1748/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1751/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1752/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1755/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1757/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1760/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1761/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1765/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1766/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1769/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1772/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1773/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1774/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1775/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1776/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1778/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1785/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1787/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1790/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1794/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1797/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1803/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1805/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1808/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1813/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1816/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1817/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1820/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1822/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1823/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1824/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1825/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1827/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1830/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1834/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1835/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1839/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1840/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1842/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1850/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1851/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1853/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1855/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1861/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1862/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [1863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1866/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1867/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1868/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1879/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1882/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1883/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1887/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1891/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1892/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1897/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1902/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1917/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1922/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1924/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1926/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1927/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1941/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1948/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1950/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1957/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [1958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1969/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1974/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1979/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1982/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1985/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1993/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [1994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [1999/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2001/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2009/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2011/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2012/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2020/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2021/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2028/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2030/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2031/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2035/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2042/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2046/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2052/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2053/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [2054/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2057/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2061/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2067/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2069/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2070/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2073/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2075/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2080/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2084/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2094/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2095/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2101/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2102/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2108/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2109/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2111/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2113/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2119/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2121/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2122/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2125/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2134/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2138/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2142/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2148/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2153/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2156/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2158/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2159/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2166/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2170/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2177/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2178/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2180/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2193/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2194/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2200/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2205/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2207/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2214/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2216/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2217/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2218/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2220/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2224/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2234/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2244/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2249/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2250/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2253/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2254/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2255/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2257/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2262/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2268/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2284/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2286/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2287/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2288/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2294/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2295/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2300/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2307/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2309/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2313/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2316/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2322/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2325/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2328/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2330/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2333/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2341/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2342/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2345/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2350/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2354/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2358/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [2359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2360/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2363/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2370/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2373/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2381/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2388/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2391/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2403/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2409/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2412/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2417/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2438/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2440/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2441/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2449/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2454/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2457/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [2458/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2460/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2462/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2463/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2465/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2468/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [2469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2478/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2487/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2489/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2492/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2495/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2498/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2500/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2502/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2507/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2518/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2527/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2532/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2535/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2545/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2554/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2555/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2558/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2562/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2575/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2581/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2586/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2589/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2591/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2592/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2600/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2602/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2620/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2627/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2631/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2632/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2639/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2640/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2647/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2653/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2655/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2657/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2673/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2675/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2677/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2679/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2695/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2701/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [2702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2713/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2714/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2716/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2724/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2726/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2730/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2731/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2735/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2739/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2744/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2750/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2758/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2763/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2765/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2767/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2769/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2775/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2778/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2783/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2788/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2790/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2794/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2797/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2804/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2807/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2813/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2814/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2825/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2828/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2830/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2834/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2838/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2839/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2851/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2852/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2855/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2862/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2867/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2875/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2879/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2880/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2882/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2887/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2888/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2892/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2899/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2909/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2915/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2918/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2919/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2922/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2923/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2928/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2929/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [2930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2938/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2943/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2947/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2948/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2951/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2965/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2968/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2969/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2972/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2979/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2982/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [2983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [2999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3005/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3011/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3012/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3024/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3025/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3027/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3030/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3035/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3038/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3045/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3046/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3052/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3054/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3057/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3062/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3064/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3067/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3069/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3080/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3090/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3094/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3095/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3099/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3101/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3103/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3108/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [3109/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3111/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3114/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3116/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3119/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3121/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [3122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3126/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3130/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3131/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3132/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3135/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3159/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3160/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3168/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3172/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [3173/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3178/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3179/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3185/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3187/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3189/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3201/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3205/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3207/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3208/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3214/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3217/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3224/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3225/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3231/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3233/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3240/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3244/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3246/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3248/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3252/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3262/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3270/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3287/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3290/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3292/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3293/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3294/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3301/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3303/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3307/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3308/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3309/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3310/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3312/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3313/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3322/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3323/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3325/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3326/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3328/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3334/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3335/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3336/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3342/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3350/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3356/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3362/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3363/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3368/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3370/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3377/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3387/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3391/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3395/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3397/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3408/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3414/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3415/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3416/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3417/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3422/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3424/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3433/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3435/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3437/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3438/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3441/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3444/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3445/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3446/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3449/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3454/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3459/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3460/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3462/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3463/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3465/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3468/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3470/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3471/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3477/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3478/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3482/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3483/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3485/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3486/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3502/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3504/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3505/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3508/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3512/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3516/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3519/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3550/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3555/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3556/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3557/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3562/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3570/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3575/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3579/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3580/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3581/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3582/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3595/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3596/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3602/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3603/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3608/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3628/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3631/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3637/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3639/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3641/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3648/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3653/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3671/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3674/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3676/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3682/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3685/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3692/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3696/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3697/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3700/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3711/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3714/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3718/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3724/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3726/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3730/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3731/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3733/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3734/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3738/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3744/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3749/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3751/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3753/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3761/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3764/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3765/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3794/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3795/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3805/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3813/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3819/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3825/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3828/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [3829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3830/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3832/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3834/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3835/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3837/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3844/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3851/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3855/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3861/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3862/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3866/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3867/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3868/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3869/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3870/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3871/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3873/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3878/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3880/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3887/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3896/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3910/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3914/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3917/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3918/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3927/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3931/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3935/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3943/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3946/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3948/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3952/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3954/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3956/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3958/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3968/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3971/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3972/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3990/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3993/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3994/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [3995/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3996/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [3998/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [3999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4003/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4005/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4011/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4013/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4029/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4030/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4035/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4039/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4043/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4044/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4052/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4054/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4057/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4063/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4065/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4067/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4069/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4071/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4074/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4075/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4077/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4078/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4080/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4086/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4090/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4093/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4094/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4095/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4098/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4100/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4101/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4108/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4109/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4111/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4119/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4121/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4127/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4128/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4149/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4154/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4159/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4160/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4166/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4168/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4176/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4181/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4184/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4201/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4202/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4205/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4211/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4214/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4215/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4217/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4218/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4224/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4232/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4236/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4237/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4242/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4244/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4251/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4257/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4262/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4269/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4272/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4273/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4282/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4287/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4294/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4297/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4302/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4307/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4308/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4309/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4314/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4318/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4321/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4322/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4325/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4328/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4329/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4336/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4338/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4342/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4343/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4350/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4357/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4360/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4363/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4367/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4370/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4372/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4374/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4379/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4391/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4392/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4398/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4400/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4409/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4410/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4412/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4414/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4417/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4418/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4425/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4432/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4438/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4441/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4449/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4460/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4462/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4463/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4465/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4468/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4474/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4478/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4490/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4491/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4495/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4497/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4498/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4499/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4500/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4502/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4503/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4506/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4507/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4525/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4528/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4548/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4550/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4569/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4573/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4575/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4578/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4579/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4581/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4597/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4599/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4617/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4620/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4627/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4630/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4631/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4632/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4637/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4639/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4654/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4656/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4667/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4673/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4676/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4681/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4687/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4698/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4704/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4705/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4712/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4714/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4717/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4718/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4721/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4724/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4726/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4727/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4729/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4731/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4736/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4744/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4745/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4748/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4749/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4754/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4757/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4762/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4765/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4770/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4775/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4778/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4782/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4783/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4789/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4791/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4794/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4798/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4799/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4800/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4806/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4808/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4810/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4813/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4818/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4823/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4825/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4826/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4830/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4834/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4852/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4855/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4858/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4862/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4867/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4877/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4884/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4887/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4894/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4895/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4899/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4900/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [4901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4911/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4913/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4927/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4943/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4952/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4954/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4962/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4963/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4967/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4968/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4970/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [4971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4992/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4997/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [4998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [4999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5011/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5023/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5026/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5030/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5035/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5041/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5052/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5054/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5057/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5067/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5069/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5080/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5084/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5090/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5092/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5094/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5095/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5101/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5106/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5108/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5109/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5111/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5119/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5121/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5125/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [5126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5127/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5139/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5159/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5168/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5178/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5179/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5188/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5191/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5200/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5203/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5205/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5212/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5214/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5217/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5218/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [5219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5239/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5242/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5244/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5255/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5258/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5262/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5263/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5264/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5266/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5270/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5275/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5278/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5281/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5283/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5287/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5292/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5294/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5295/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5307/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5308/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5309/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5322/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5325/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5328/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5329/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5333/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5334/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5342/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5345/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5350/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5363/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5369/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5370/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5373/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5378/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5382/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5383/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5384/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5391/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5399/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5406/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5407/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5408/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5413/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5417/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5426/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5428/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5431/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5433/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5438/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5441/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5442/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5449/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5450/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5455/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5460/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5462/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5463/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5465/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5467/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5468/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5478/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5481/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5489/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5494/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5498/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5502/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5503/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5510/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5516/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5522/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5528/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [5529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5531/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5539/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5541/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5542/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5544/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5548/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5549/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5555/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5575/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5579/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5580/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5581/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5584/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5590/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5593/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5595/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5597/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5601/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5603/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5606/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5613/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5614/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5628/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5630/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5631/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5634/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5636/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5639/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5645/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5658/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [5659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5660/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5669/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5687/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5688/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5690/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5694/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5703/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5713/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5714/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5715/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5717/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5721/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5724/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5726/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5731/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5744/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5749/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5765/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5773/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5785/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5787/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5788/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5794/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5811/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5813/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5814/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5815/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5819/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5825/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5826/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5830/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5834/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5837/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5841/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [5842/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5855/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5862/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5865/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5867/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5868/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5871/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5878/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5880/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5881/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5884/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5887/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5893/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5895/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5899/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5909/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5911/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5914/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5924/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5925/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5931/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5933/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [5934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5950/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5975/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5985/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5988/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5989/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5991/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [5998/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [5999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6010/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6011/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6012/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6022/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6023/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6024/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [6025/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6030/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6031/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6035/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6039/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6052/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6054/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6057/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6058/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6060/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6062/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6067/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6069/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6074/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6080/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6083/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6084/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6094/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6095/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6097/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6101/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6105/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6108/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6109/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6111/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6117/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6119/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6121/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6122/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6123/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6130/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6134/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6135/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6141/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6145/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6146/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6151/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6153/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6159/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6164/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6174/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6183/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6186/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6190/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6203/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6205/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6214/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6217/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6226/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6228/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6244/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6247/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6259/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6262/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6283/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6284/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6287/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6293/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6294/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6307/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6309/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6321/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6322/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6325/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6328/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6341/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6342/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6350/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6354/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6359/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6363/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6365/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6366/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6370/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6373/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6380/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6382/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6391/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6392/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [6393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6401/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6402/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6416/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6417/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6421/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6438/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6441/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6442/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6443/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6446/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6449/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6457/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6460/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6462/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6463/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6465/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6468/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6472/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6474/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6478/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6480/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [6481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6488/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6490/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6493/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6497/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6499/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6502/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6519/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6533/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6535/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6537/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6542/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6547/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6555/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6556/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6558/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6559/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6563/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6566/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6570/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6571/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6573/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6575/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6581/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6582/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6587/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6594/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6598/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6623/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6629/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6631/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6637/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6639/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6644/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6657/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6680/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6685/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6694/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6695/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6699/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6702/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6709/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6713/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6714/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6720/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6721/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6724/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6726/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6731/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6732/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6743/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6744/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [6745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6754/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6760/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6765/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6766/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6767/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6774/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6776/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6777/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6780/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6790/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6792/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6794/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6795/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6798/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6802/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6808/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6813/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6814/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6815/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6825/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6829/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6830/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6834/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6841/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6855/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6856/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6862/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6864/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6867/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6868/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6875/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6882/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6885/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6887/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6893/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6898/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6900/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6901/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6915/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6917/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6918/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6928/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6934/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6941/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6942/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6952/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6953/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6957/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6967/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6969/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6974/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6978/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [6979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6985/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6995/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [6996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [6999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7006/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7011/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7018/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7021/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7027/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7030/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7033/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7035/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7036/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7042/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7045/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7052/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7053/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7054/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7057/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7064/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7067/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7069/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7076/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7080/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7085/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7093/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7094/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7095/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7096/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7097/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7098/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7101/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7103/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7104/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7108/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7109/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7111/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7113/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7114/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7115/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7116/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7119/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7121/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7127/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7128/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7133/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7134/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7146/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7149/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7159/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7160/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7169/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7189/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7197/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7199/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7203/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7205/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7206/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7209/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7212/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7214/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7217/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7219/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7221/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7230/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7233/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7241/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7244/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7246/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7254/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7262/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7264/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7268/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7273/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7276/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7287/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7288/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7294/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7296/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7301/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7307/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7309/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7310/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7318/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7320/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7321/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7322/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7325/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7328/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7334/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7338/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7342/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7348/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7350/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7351/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7363/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7370/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7375/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7385/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7389/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7391/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7393/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7397/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7398/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7403/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7406/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7417/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7420/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7424/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7430/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7438/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7439/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7441/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7443/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7446/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7449/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7450/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7452/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7455/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7459/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7460/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7462/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7463/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7465/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7466/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7468/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7472/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7478/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7481/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7483/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7496/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7502/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7511/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7519/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7523/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7525/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7526/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7542/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7543/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7544/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7548/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7549/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7551/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7556/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7559/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7560/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7568/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7575/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7576/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7581/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7584/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7589/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7605/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7607/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7610/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7611/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7615/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7616/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7631/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7639/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7640/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7641/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7644/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7646/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7647/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7649/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7660/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7661/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7664/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7669/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7671/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7672/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7684/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7688/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7699/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7706/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7707/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7709/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7712/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7714/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7724/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7726/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7729/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7731/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7736/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7737/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7738/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7742/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7744/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7757/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7762/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7765/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7767/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7773/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7774/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7776/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7781/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7787/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7790/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7792/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7793/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7794/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7796/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7808/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7813/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7819/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7821/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7825/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7830/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7834/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7836/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7841/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7845/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7852/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7855/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7856/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7862/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7865/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7867/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7869/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7873/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7877/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7880/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7887/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7888/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7896/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [7897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7905/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7908/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7911/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7919/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7921/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7934/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [7935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7941/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7949/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7964/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7973/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7982/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7986/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7997/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [7998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [7999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8000/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8003/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8007/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8010/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8011/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8016/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8021/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8026/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8030/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8031/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8035/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8041/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8044/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8045/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8046/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8048/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8049/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8051/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8052/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8053/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8054/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8057/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8059/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8060/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8064/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8066/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8067/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8069/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8073/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8076/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8079/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8080/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8082/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8085/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8092/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8094/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8095/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8101/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8102/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8107/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8108/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8109/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8110/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8111/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8112/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8113/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8115/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8119/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8121/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8126/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8127/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8129/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8133/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8135/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8136/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8139/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8149/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8151/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8155/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8159/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8164/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8165/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8175/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8177/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8181/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8182/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8186/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8189/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8193/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8199/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8200/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8204/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8205/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8208/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8210/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8214/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8217/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8223/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8230/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8236/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8237/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8238/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8244/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8255/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8259/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8262/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8263/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8264/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8270/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8272/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8274/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8275/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8276/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8278/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8279/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8280/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8286/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8287/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8289/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8294/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8296/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8298/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8307/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8309/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8311/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8314/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8316/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8319/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8320/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8322/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8325/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8328/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8330/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8338/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8339/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8342/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8346/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8347/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8349/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8350/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8352/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8357/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8359/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8360/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8363/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8369/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8370/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8371/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8375/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8377/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8383/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8387/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8389/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8391/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8400/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8401/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8402/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8403/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8410/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8413/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8415/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8416/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8417/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8420/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8421/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8422/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8424/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8430/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8438/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8439/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8441/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8444/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8449/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8451/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8459/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8460/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8462/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8463/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8464/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8465/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8466/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8467/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8468/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8469/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8470/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8471/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8478/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8479/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8481/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8483/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8484/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8486/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8488/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8492/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8494/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8496/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8497/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8502/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8505/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8508/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8510/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8511/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8513/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8516/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8519/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8522/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8531/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8536/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8543/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8554/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8556/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8557/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8558/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8559/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8565/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8572/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8575/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8579/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8581/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8583/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8584/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8585/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8593/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8594/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8597/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8606/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8608/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8623/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8626/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8630/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8631/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8637/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8638/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8639/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8643/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8646/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8650/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8652/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8654/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8655/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8656/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8658/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8659/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8661/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8667/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8668/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8672/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8676/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8680/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8689/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8695/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8696/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8697/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8700/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8701/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8702/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8705/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8712/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8714/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8715/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8719/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8723/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8724/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8726/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8729/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8731/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8732/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8736/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8744/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8745/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8751/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8753/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8757/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8761/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8765/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8766/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8771/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8776/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8777/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8779/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8781/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8784/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8785/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8794/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8796/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8797/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8799/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8801/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8804/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8807/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8809/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8811/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8813/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8820/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8821/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8823/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8824/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8825/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8828/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8830/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8832/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8834/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8837/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8841/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8842/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8843/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8846/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8849/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8850/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8855/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8856/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8861/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8862/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8863/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8867/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8870/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8871/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8873/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8884/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8886/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8887/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8894/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8898/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8900/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8902/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8903/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8904/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8905/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8908/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8909/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8913/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8924/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8925/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8930/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8933/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8935/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8939/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8940/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8944/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8946/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8949/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8950/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8957/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [8958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8959/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8967/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [8968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8970/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8971/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8977/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8979/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8983/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8990/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8992/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8994/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [8995/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [8999/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9000/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9001/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9002/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9003/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9004/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9005/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9006/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9007/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9008/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9009/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9010/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9011/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9012/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9013/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9014/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9015/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9016/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9017/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9018/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9019/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9020/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9021/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9022/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9023/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9024/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9025/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9026/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9027/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9028/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9029/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9030/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9031/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9032/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9033/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9034/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9035/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9036/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9037/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9038/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9039/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9040/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9041/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9042/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9043/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9044/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9045/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9046/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9047/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9048/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9049/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9050/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9051/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9052/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9053/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9054/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [9055/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9056/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9057/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9058/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9059/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9060/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9061/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9062/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9063/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9064/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9065/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9066/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9067/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9068/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9069/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9070/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9071/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9072/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9073/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9074/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9075/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9076/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9077/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9078/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9079/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9080/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9081/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9082/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9083/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9084/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9085/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9086/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9087/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9088/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9089/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9090/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9091/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9092/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9093/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9094/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9095/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9096/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9097/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9098/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9099/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9100/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9101/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9102/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9103/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9104/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9105/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9106/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9107/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9108/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9109/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9110/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9111/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9112/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9113/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9114/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9115/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9116/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9117/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9118/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9119/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9120/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9121/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9122/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9123/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9124/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9125/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9126/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9127/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9128/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9129/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9130/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9131/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9132/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9133/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9134/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9135/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9136/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9137/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9138/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9139/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9140/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9141/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9142/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9143/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9144/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9145/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9146/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9147/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9148/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9149/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9150/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9151/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9152/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9153/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9154/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9155/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9156/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9157/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9158/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9159/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9160/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9161/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9162/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9163/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9164/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9165/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9166/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9167/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9168/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9169/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9170/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9171/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9172/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9173/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9174/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9175/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9176/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9177/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9178/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9179/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9180/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9181/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9182/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9183/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9184/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9185/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9186/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9187/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9188/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9189/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9190/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9191/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9192/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9193/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9194/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9195/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9196/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9197/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9198/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9199/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9200/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9201/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9202/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9203/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9204/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9205/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9206/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9207/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9208/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9209/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9210/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9211/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9212/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9213/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9214/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9215/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9216/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9217/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9218/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9219/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9220/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9221/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9222/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9223/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9224/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9225/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9226/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9227/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9228/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9229/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9230/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9231/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9232/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9233/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9234/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9235/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9236/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9237/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9238/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9239/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9240/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9241/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9242/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9243/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9244/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9245/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9246/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9247/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9248/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9249/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9250/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9251/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9252/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9253/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9254/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9255/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9256/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9257/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9258/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9259/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9260/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9261/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9262/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9263/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9264/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9265/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9266/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9267/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9268/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9269/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9270/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9271/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9272/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9273/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9274/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9275/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9276/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9277/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9278/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9279/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9280/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9281/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9282/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9283/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9284/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9285/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9286/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9287/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9288/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9289/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9290/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9291/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9292/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9293/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9294/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9295/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9296/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9297/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9298/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9299/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9300/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9301/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9302/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9303/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9304/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9305/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9306/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9307/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9308/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9309/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9310/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9311/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9312/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9313/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9314/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9315/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9316/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9317/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9318/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9319/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9320/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9321/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9322/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9323/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9324/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9325/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9326/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9327/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9328/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9329/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9330/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9331/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9332/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9333/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9334/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9335/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9336/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9337/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9338/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9339/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9340/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9341/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9342/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9343/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9344/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9345/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9346/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9347/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9348/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9349/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9350/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9351/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9352/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9353/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9354/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9355/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9356/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9357/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9358/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9359/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9360/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9361/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9362/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9363/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9364/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9365/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9366/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9367/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9368/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9369/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9370/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9371/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9372/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9373/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9374/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9375/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9376/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9377/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9378/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9379/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9380/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9381/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9382/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9383/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9384/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9385/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9386/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9387/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9388/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9389/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9390/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9391/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9392/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9393/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9394/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9395/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9396/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9397/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9398/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9399/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9400/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9401/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9402/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9403/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9404/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9405/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9406/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9407/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9408/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9409/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9410/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9411/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9412/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9413/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9414/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9415/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9416/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9417/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9418/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9419/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9420/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9421/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9422/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9423/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9424/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9425/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9426/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9427/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9428/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9429/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9430/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9431/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9432/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9433/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9434/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9435/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9436/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9437/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9438/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9439/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9440/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9441/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9442/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9443/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9444/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9445/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9446/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9447/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9448/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9449/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9450/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9451/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9452/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9453/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9454/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9455/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9456/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9457/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9458/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9459/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9460/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9461/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9462/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9463/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9464/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9465/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9466/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9467/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9468/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9469/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9470/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [9471/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9472/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9473/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9474/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9475/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9476/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9477/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9478/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9479/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9480/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9481/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9482/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9483/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9484/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9485/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9486/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9487/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9488/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9489/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9490/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9491/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9492/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9493/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9494/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9495/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9496/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9497/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9498/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9499/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9500/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9501/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9502/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9503/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9504/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9505/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9506/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9507/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9508/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9509/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9510/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9511/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9512/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9513/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9514/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9515/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9516/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9517/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9518/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9519/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9520/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9521/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9522/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9523/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9524/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9525/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9526/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9527/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9528/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9529/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9530/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9531/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9532/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9533/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9534/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9535/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9536/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9537/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9538/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9539/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9540/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9541/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9542/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9543/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9544/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9545/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9546/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9547/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9548/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9549/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9550/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9551/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9552/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9553/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9554/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9555/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9556/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9557/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9558/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9559/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9560/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9561/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9562/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9563/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9564/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9565/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9566/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9567/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9568/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9569/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9570/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9571/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9572/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9573/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9574/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9575/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9576/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9577/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9578/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9579/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9580/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9581/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9582/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9583/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9584/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9585/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9586/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9587/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9588/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9589/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9590/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9591/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9592/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9593/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9594/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9595/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9596/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9597/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9598/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9599/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9600/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9601/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9602/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9603/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9604/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9605/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9606/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9607/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9608/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9609/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9610/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9611/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9612/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9613/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9614/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9615/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9616/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9617/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9618/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9619/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9620/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9621/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9622/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9623/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9624/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9625/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9626/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9627/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9628/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9629/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9630/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9631/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9632/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9633/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9634/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9635/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9636/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9637/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9638/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9639/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9640/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9641/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9642/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9643/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9644/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9645/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9646/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9647/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9648/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9649/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9650/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9651/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9652/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [9653/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9654/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9655/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9656/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9657/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9658/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9659/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9660/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9661/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9662/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9663/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9664/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9665/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9666/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9667/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9668/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9669/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9670/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9671/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9672/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9673/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9674/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9675/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9676/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9677/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9678/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9679/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9680/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9681/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9682/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9683/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9684/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9685/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9686/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9687/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9688/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9689/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9690/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9691/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9692/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9693/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9694/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9695/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9696/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9697/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9698/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9699/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9700/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9701/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9702/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9703/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9704/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9705/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9706/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9707/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9708/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9709/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9710/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9711/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9712/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9713/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9714/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9715/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9716/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9717/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9718/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9719/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9720/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9721/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9722/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9723/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9724/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9725/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9726/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9727/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9728/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9729/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9730/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9731/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9732/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9733/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9734/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9735/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9736/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9737/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9738/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9739/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9740/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9741/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9742/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9743/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9744/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9745/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9746/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9747/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9748/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9749/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9750/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9751/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9752/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9753/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9754/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9755/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9756/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9757/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9758/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9759/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9760/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9761/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9762/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9763/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9764/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9765/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9766/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9767/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9768/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9769/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9770/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9771/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9772/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9773/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9774/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9775/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9776/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9777/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9778/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9779/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9780/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9781/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9782/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9783/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9784/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9785/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9786/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9787/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9788/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9789/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9790/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9791/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9792/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9793/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9794/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9795/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9796/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9797/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9798/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9799/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9800/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9801/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9802/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9803/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9804/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9805/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9806/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9807/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9808/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9809/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9810/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9811/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9812/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9813/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9814/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9815/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9816/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9817/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9818/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9819/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9820/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9821/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9822/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9823/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9824/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9825/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9826/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9827/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9828/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9829/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9830/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9831/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9832/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9833/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9834/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9835/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9836/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9837/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9838/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9839/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9840/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9841/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9842/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9843/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9844/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9845/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9846/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9847/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9848/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9849/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9850/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9851/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9852/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9853/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9854/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9855/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9856/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9857/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9858/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9859/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9860/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9861/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9862/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9863/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9864/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9865/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9866/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9867/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9868/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9869/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9870/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9871/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9872/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9873/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9874/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9875/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9876/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9877/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9878/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9879/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9880/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9881/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9882/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9883/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9884/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9885/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9886/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9887/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9888/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9889/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9890/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9891/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9892/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9893/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9894/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9895/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9896/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9897/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9898/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9899/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9900/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9901/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9902/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9903/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9904/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9905/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9906/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9907/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9908/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9909/10000], Train Loss: 0.0019, Val Loss: 0.0024\n",
      "Epoch [9910/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9911/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9912/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9913/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9914/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9915/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9916/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9917/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9918/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9919/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9920/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9921/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9922/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9923/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9924/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9925/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9926/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9927/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9928/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9929/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9930/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9931/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9932/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9933/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9934/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9935/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9936/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9937/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9938/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9939/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9940/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9941/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9942/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9943/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9944/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9945/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9946/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9947/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9948/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9949/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Epoch [9950/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9951/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9952/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9953/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9954/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9955/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9956/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9957/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9958/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9959/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9960/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9961/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9962/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9963/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9964/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9965/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9966/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9967/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9968/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9969/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9970/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9971/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9972/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9973/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9974/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9975/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9976/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9977/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9978/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9979/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9980/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9981/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9982/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9983/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9984/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9985/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9986/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9987/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9988/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9989/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9990/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9991/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9992/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9993/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9994/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9995/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [9996/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9997/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9998/10000], Train Loss: 0.0018, Val Loss: 0.0023\n",
      "Epoch [9999/10000], Train Loss: 0.0019, Val Loss: 0.0023\n",
      "Epoch [10000/10000], Train Loss: 0.0018, Val Loss: 0.0024\n",
      "Best model found at epoch 30, with validation loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to track best model\n",
    "best_loss = 0.0023\n",
    "best_epoch = 0\n",
    "num_epochs = 10000\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):    \n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs_val, labels_val in test_loader:\n",
    "            inputs_val, labels_val = inputs_val.to(device), labels_val.to(device)\n",
    "\n",
    "            outputs_val = model(inputs_val)\n",
    "            loss_val = criterion(outputs_val, labels_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_val_loss = val_loss / len(test_loader)    \n",
    "    test_losses.append(avg_val_loss)\n",
    "        \n",
    "    # Save best model based on validation loss\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), os.path.join(WEIGHT_FOLDER, 'best_model.pth'))\n",
    "\n",
    "    #print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "    # Step the scheduler at the end of each epoch\n",
    "    scheduler.step()\n",
    "\n",
    "print(f'Best model found at epoch {best_epoch+1}, with validation loss: {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2949b997-dd46-4cd3-a8b3-1fccffdad967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b73c044-4d90-4eda-a3ae-78518bf1b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52912a8190>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABKhUlEQVR4nO3dfVxUVeI/8M/MADOgzICiM6AomKRrKhQqYpa18ZVa243dtkVr08xv/vqua7ZYrZqJfbfvYo/rmha5W1m7axi7Zq4Zm2Hag6SJoJKJTxgqDg8qMzg8z5zfHzcGRoaHYWaYYfi8X695Dd577rnnXoH5cO6558qEEAJEREREfZzc0w0gIiIicgWGGiIiIvIJDDVERETkExhqiIiIyCcw1BAREZFPYKghIiIin8BQQ0RERD6BoYaIiIh8gp+nG9BbLBYLysrKEBwcDJlM5unmEBERUTcIIVBTU4OIiAjI5Z33xfSbUFNWVobIyEhPN4OIiIh64Ny5cxg+fHinZfpNqAkODgYgnRS1Wu3h1hAREVF3GI1GREZGWj/HO9NvQk3LJSe1Ws1QQ0RE1Md0Z+gIBwoTERGRT2CoISIiIp/AUENEREQ+gaGGiIiIfAJDDREREfkEhhoiIiLyCQw1RERE5BMYaoiIiMgnMNQQERGRT2CoISIiIp/AUENEREQ+gaGGiIiIfEK/eaCl21SeAA6+CQSHA9Mf93RriIiI+i321DjLcA7YnwkU/dPTLSEiIurXGGqIiIjIJzDUEBERkU9gqCEiIiKfwFDjKsLTDSAiIurfGGqcJZN5ugVEREQEhhoiIiLyEQw1RERE5BMYaoiIiMgn9CjUbNiwAVFRUVCpVEhISMCBAwc6LZ+dnY2xY8dCpVJhwoQJ2Llzp836rVu3YubMmRg8eDBkMhkKCws7rEsIgbvuugsymQzbtm3rSfPdhCOFiYiIPMnhULNlyxakpaUhPT0dhw4dQmxsLJKTk1FRUWG3/L59+zBnzhwsWLAABQUFSElJQUpKCoqKiqxlTCYTpk+fjueff77L/a9duxYyrxqc601tISIi6r9kQgiHuhgSEhIwefJkrF+/HgBgsVgQGRmJxYsXY9myZe3Kp6amwmQyYceOHdZlU6dORVxcHDIzM23Knj17FtHR0SgoKEBcXFy7ugoLC3H33Xfj4MGDCA8PxwcffICUlJRutdtoNEKj0cBgMECtVnf/gLty+jPgbymAdjzwP1+5rl4iIiJy6PPboZ6axsZG5OfnIykpqbUCuRxJSUnIy8uzu01eXp5NeQBITk7usHxHamtrcf/992PDhg3Q6XQObUtERES+z6GndFdVVcFsNkOr1dos12q1OH78uN1t9Hq93fJ6vd6hhv7ud7/DtGnTcM8993SrfENDAxoaGqz/NhqNDu2PiIiI+haHQo2nbN++Hbt370ZBQUG3t8nIyMCzzz7rxlZdw7GreERERORiDl1+CgsLg0KhQHl5uc3y8vLyDi8J6XQ6h8rbs3v3bpw+fRohISHw8/ODn5+Uxe69917cdtttdrdZvnw5DAaD9XXu3Llu788hXjVomYiIqP9yKNQEBAQgPj4eubm51mUWiwW5ublITEy0u01iYqJNeQDYtWtXh+XtWbZsGY4cOYLCwkLrCwD+9Kc/4e2337a7jVKphFqttnkRERGR73L48lNaWhrmzZuHSZMmYcqUKVi7di1MJhPmz58PAJg7dy6GDRuGjIwMAMCSJUswY8YMvPzyy5g1axaysrJw8OBBbNy40Vrn5cuXUVpairKyMgBAcXExAKmXp+3rWiNGjEB0dLTjR01EREQ+x+FQk5qaisrKSqxatQp6vR5xcXHIycmxDgYuLS2FXN7aATRt2jRs3rwZK1euxIoVKxATE4Nt27Zh/Pjx1jLbt2+3hiIAmD17NgAgPT0dq1ev7umxERERUT/i8Dw1fZXb5qk5swd49x5g6DjgN47dpk5ERESdc9s8NWQPBwoTERF5A4YaIiIi8gkMNUREROQTGGqIiIjIJzDUEBERkU9gqHGV/nETGRERkddiqHEWH5NARETkFRhqiIiIyCcw1BAREZFPYKghIiIin8BQ4zIcKExERORJDDVO40BhIiIib8BQQ0RERD6BoYaIiIh8AkMNERER+QSGGlfhjMJEREQexVDjLM4oTERE5BUYaoiIiMgnMNQQERGRT2CoISIiIp/AUOMyHChMRETkSQw1TuNAYSIiIm/AUENEREQ+gaGGiIiIfAJDDREREfkEhhpX4YzCREREHsVQ4yzOKExEROQVGGqIiIjIJzDUEBERkU9gqCEiIiKfwFDjMhwoTERE5EkMNU7jQGEiIiJvwFBDREREPoGhhoiIiHwCQw0RERH5BIYaV+GMwkRERB7FUOMszihMRETkFRhqiIiIyCcw1BAREZFPYKghIiIin8BQ4zIcKExERORJDDVO40BhIiIib9CjULNhwwZERUVBpVIhISEBBw4c6LR8dnY2xo4dC5VKhQkTJmDnzp0267du3YqZM2di8ODBkMlkKCwstFl/+fJlLF68GGPGjEFgYCBGjBiBxx57DAaDoSfNJyIiIh/kcKjZsmUL0tLSkJ6ejkOHDiE2NhbJycmoqKiwW37fvn2YM2cOFixYgIKCAqSkpCAlJQVFRUXWMiaTCdOnT8fzzz9vt46ysjKUlZXhpZdeQlFRETZt2oScnBwsWLDA0eYTERGRj5IJ4discQkJCZg8eTLWr18PALBYLIiMjMTixYuxbNmyduVTU1NhMpmwY8cO67KpU6ciLi4OmZmZNmXPnj2L6OhoFBQUIC4urtN2ZGdn49e//jVMJhP8/Py6bLfRaIRGo4HBYIBare7GkXZT6X7grZnAoFHAYwWuq5eIiIgc+vx2qKemsbER+fn5SEpKaq1ALkdSUhLy8vLsbpOXl2dTHgCSk5M7LN9dLQfXUaBpaGiA0Wi0eREREZHvcijUVFVVwWw2Q6vV2izXarXQ6/V2t9Hr9Q6V7247/vCHP2DhwoUdlsnIyIBGo7G+IiMje7y/buFjEoiIiDyqz939ZDQaMWvWLIwbNw6rV6/usNzy5cthMBisr3PnzrmnQXxMAhERkVfoejBKG2FhYVAoFCgvL7dZXl5eDp1OZ3cbnU7nUPnO1NTU4M4770RwcDA++OAD+Pv7d1hWqVRCqVQ6vA8iIiLqmxzqqQkICEB8fDxyc3OtyywWC3Jzc5GYmGh3m8TERJvyALBr164Oy3fEaDRi5syZCAgIwPbt26FSqRzanoiIiHybQz01AJCWloZ58+Zh0qRJmDJlCtauXQuTyYT58+cDAObOnYthw4YhIyMDALBkyRLMmDEDL7/8MmbNmoWsrCwcPHgQGzdutNZ5+fJllJaWoqysDABQXFwMQOrl0el01kBTW1uLv//97zYDf4cMGQKFQuHcWSAiIqI+z+FQk5qaisrKSqxatQp6vR5xcXHIycmxDgYuLS2FXN7aATRt2jRs3rwZK1euxIoVKxATE4Nt27Zh/Pjx1jLbt2+3hiIAmD17NgAgPT0dq1evxqFDh7B//34AwOjRo23aU1JSgqioKEcPww04UJiIiMiTHJ6npq9y2zw1574B3kwCQqOAJYddVy8RERG5b54aIiIiIm/FUENEREQ+gaGGiIiIfAJDjav0j6FJREREXouhxlmcUZiIiMgrMNQQERGRT2CoISIiIp/AUENEREQ+gaHGZThQmIiIyJMYapzGgcJERETegKGGiIiIfAJDDREREfkEhhoiIiLyCQw1rsJxwkRERB7FUOMsjhMmIiLyCgw1RERE5BMYaoiIiMgnMNQQERGRT2CocRmOFCYiIvIkhhqncaQwERGRN2CoISIiIp/AUENEREQ+gaGGiIiIfAJDjasIDhQmIiLyJIYaZ8k4UJiIiMgbMNQQERGRT2CoISIiIp/AUENEREQ+gaHGZThQmIiIyJMYapzGgcJERETegKGGiIiIfAJDDREREfkEhhoiIiLyCQw1RERE5BMYalyFj0kgIiLyKIYaZ/ExCURERF6BoYaIiIh8AkMNERER+QSGGiIiIvIJDDUuw4HCREREnsRQ4zQOFCYiIvIGDDVERETkE3oUajZs2ICoqCioVCokJCTgwIEDnZbPzs7G2LFjoVKpMGHCBOzcudNm/datWzFz5kwMHjwYMpkMhYWF7eqor6/HokWLMHjwYAwcOBD33nsvysvLe9J8IiIi8kEOh5otW7YgLS0N6enpOHToEGJjY5GcnIyKigq75fft24c5c+ZgwYIFKCgoQEpKClJSUlBUVGQtYzKZMH36dDz//PMd7vd3v/sd/v3vfyM7Oxt79+5FWVkZfvGLXzjafCIiIvJRMiEcmwo3ISEBkydPxvr16wEAFosFkZGRWLx4MZYtW9aufGpqKkwmE3bs2GFdNnXqVMTFxSEzM9Om7NmzZxEdHY2CggLExcVZlxsMBgwZMgSbN2/GL3/5SwDA8ePH8aMf/Qh5eXmYOnVql+02Go3QaDQwGAxQq9WOHHLnLh4B3rgFGKgDnih2Xb1ERETk0Oe3Qz01jY2NyM/PR1JSUmsFcjmSkpKQl5dnd5u8vDyb8gCQnJzcYXl78vPz0dTUZFPP2LFjMWLEiA7raWhogNFotHm5BWcUJiIi8goOhZqqqiqYzWZotVqb5VqtFnq93u42er3eofId1REQEICQkJBu15ORkQGNRmN9RUZGdnt/RERE1Pf47N1Py5cvh8FgsL7OnTvn6SYRERGRG/k5UjgsLAwKhaLdXUfl5eXQ6XR2t9HpdA6V76iOxsZGVFdX2/TWdFaPUqmEUqns9j6IiIiob3OopyYgIADx8fHIzc21LrNYLMjNzUViYqLdbRITE23KA8CuXbs6LG9PfHw8/P39beopLi5GaWmpQ/W4F2cUJiIi8iSHemoAIC0tDfPmzcOkSZMwZcoUrF27FiaTCfPnzwcAzJ07F8OGDUNGRgYAYMmSJZgxYwZefvllzJo1C1lZWTh48CA2btxorfPy5csoLS1FWVkZACmwAFIPjU6ng0ajwYIFC5CWloZBgwZBrVZj8eLFSExM7NadT+7FgcJERETewOFQk5qaisrKSqxatQp6vR5xcXHIycmxDgYuLS2FXN7aATRt2jRs3rwZK1euxIoVKxATE4Nt27Zh/Pjx1jLbt2+3hiIAmD17NgAgPT0dq1evBgD86U9/glwux7333ouGhgYkJyfjtdde69FBExERke9xeJ6avspt89Toi4DMm4GBWuCJE66rl4iIiNw3Tw0RERGRt2KocZX+0eFFRETktRhqnMUZhYmIiLwCQw0RERH5BIYaIiIi8gkMNUREROQTGGpchgOFiYiIPImhxmkcKExEROQNGGqIiIjIJzDUEBERkU9gqCEiIiKfwFDjKpxRmIiIyKMYapzFGYWJiIi8AkMNERER+QSGGiIiIvIJDDVERETkExhqXIYDhYmIiDyJocZpHChMRETkDRhqiIiIyCcw1BAREZFPYKghIiIin8BQQ0RERD6BocZV+JgEIiIij2KocVKTRQozjDRERESexVDjpMJz1QAAY32zZxtCRETUzzHUEBERkU9gqCEiIiKfwFDjIjKOqiEiIvIohhqn8TEJRERE3oChxkkyZhoiIiKvwFBDREREPoGhxkkyXn4iIiLyCgw1LsKBwkRERJ7FUOMkGQfVEBEReQWGGiIiIvIJDDUuwotPREREnsVQQ0RERD6BocZFZIJ9NURERJ7EUOMsOQcKExEReQOGGiIiIvIJDDVOYj8NERGRd2CoISIiIp/Qo1CzYcMGREVFQaVSISEhAQcOHOi0fHZ2NsaOHQuVSoUJEyZg586dNuuFEFi1ahXCw8MRGBiIpKQknDx50qbMiRMncM899yAsLAxqtRrTp0/HZ5991pPmu1TL3HvssSEiIvIsh0PNli1bkJaWhvT0dBw6dAixsbFITk5GRUWF3fL79u3DnDlzsGDBAhQUFCAlJQUpKSkoKiqylnnhhRewbt06ZGZmYv/+/RgwYACSk5NRX19vLXP33XejubkZu3fvRn5+PmJjY3H33XdDr9f34LBdiXGGiIjIG8iEcOxe5ISEBEyePBnr168HAFgsFkRGRmLx4sVYtmxZu/KpqakwmUzYsWOHddnUqVMRFxeHzMxMCCEQERGBpUuX4oknngAAGAwGaLVabNq0CbNnz0ZVVRWGDBmCzz//HLfccgsAoKamBmq1Grt27UJSUlKX7TYajdBoNDAYDFCr1Y4ccqcKCw8ibtsduIoBGLi6zGX1EhERkWOf3w711DQ2NiI/P98mRMjlciQlJSEvL8/uNnl5ee1CR3JysrV8SUkJ9Hq9TRmNRoOEhARrmcGDB2PMmDF49913YTKZ0NzcjDfeeANDhw5FfHy83f02NDTAaDTavIiIiMh3ORRqqqqqYDabodVqbZZrtdoOLwPp9fpOy7e8d1ZGJpPh008/RUFBAYKDg6FSqfDKK68gJycHoaGhdvebkZEBjUZjfUVGRjpyqERERNTH9Im7n4QQWLRoEYYOHYovvvgCBw4cQEpKCn7605/i4sWLdrdZvnw5DAaD9XXu3Dm3tK31Kd2cUZiIiMiTHAo1YWFhUCgUKC8vt1leXl4OnU5ndxudTtdp+Zb3zsrs3r0bO3bsQFZWFm6++WbcdNNNeO211xAYGIh33nnH7n6VSiXUarXNyz04UJiIiMgbOBRqAgICEB8fj9zcXOsyi8WC3NxcJCYm2t0mMTHRpjwA7Nq1y1o+OjoaOp3OpozRaMT+/futZWpra6XGym2bK5fLYbFYHDkEl5Mx0xAREXkFP0c3SEtLw7x58zBp0iRMmTIFa9euhclkwvz58wEAc+fOxbBhw5CRkQEAWLJkCWbMmIGXX34Zs2bNQlZWFg4ePIiNGzcCkC7fPP7443juuecQExOD6OhoPPPMM4iIiEBKSgoAKRiFhoZi3rx5WLVqFQIDA/GXv/wFJSUlmDVrlotOBREREfVlDoea1NRUVFZWYtWqVdDr9YiLi0NOTo51oG9paalNj8q0adOwefNmrFy5EitWrEBMTAy2bduG8ePHW8s89dRTMJlMWLhwIaqrqzF9+nTk5ORApVIBkC575eTk4Omnn8aPf/xjNDU14YYbbsCHH36I2NhYZ8+BU9hRQ0RE5B0cnqemr3LXPDVHjxzChK23w4RADFjt6YkAiYiIfIvb5qkhe9hXQ0RE5A0YapzFTENEROQVGGqIiIjIJzDUOI1dNURERN6AocZFZJxRmIiIyKMYapwk4+x7REREXoGhhoiIiHwCQ42T2E9DRETkHRhqiIiIyCcw1BAREZFPYKhxEgcKExEReQeGGmcx0xAREXkFhhonMdMQERF5B4YaIiIi8gkMNc5iVw0REZFXYKhxET4mgYiIyLMYapwk4ykkIiLyCvxEJiIiIp/AUENEREQ+gaHGSZx7j4iIyDsw1LgIBwoTERF5FkON09hVQ0RE5A0YaoiIiMgnMNQ4iWNqiIiIvANDDREREfkEhhonyTimhoiIyCsw1DhJ8PoTERGRV2CoISIiIp/AUOMk9tMQERF5B4YaIiIi8gkMNU5qGVLDGYWJiIg8i6HGWRwo7H4Wi6dbQEREfQBDjZN4S7ebnfwUyBgGFP3L0y0hIiIvx1BD3u0f9wJNtcA/H/Z0S4iIyMsx1DiJV5+IiIi8A0ONi3CgMBERkWcx1PiieiMgGLKIiKh/Yahxktddfao4DqyJBDanerolREREvYqhxtccfFN6P/kfz7aDiIiolzHUOMvrumqIiIj6J4YaF/GegcJMWURE1D8x1DiNp5CIiMgb9OgTecOGDYiKioJKpUJCQgIOHDjQafns7GyMHTsWKpUKEyZMwM6dO23WCyGwatUqhIeHIzAwEElJSTh58mS7ej766CMkJCQgMDAQoaGhSElJ6UnzqYUQwL+XAJ/90dMtISIicprDoWbLli1IS0tDeno6Dh06hNjYWCQnJ6OiosJu+X379mHOnDlYsGABCgoKkJKSgpSUFBQVFVnLvPDCC1i3bh0yMzOxf/9+DBgwAMnJyaivr7eW+de//oUHH3wQ8+fPx+HDh/HVV1/h/vvv78Ehu1afnnyv8jiQvwnY+7ynW0JEROQ0mRCOTWiSkJCAyZMnY/369QAAi8WCyMhILF68GMuWLWtXPjU1FSaTCTt27LAumzp1KuLi4pCZmQkhBCIiIrB06VI88cQTAACDwQCtVotNmzZh9uzZaG5uRlRUFJ599lksWLCgRwdqNBqh0WhgMBigVqt7VIc9Z0tOIuqdSWiCAv6rL7us3h77+PfA/kzp69WGzsuWFQAbb+teWU9ZrWnztZe2kYiI3MaRz2+HemoaGxuRn5+PpKSk1grkciQlJSEvL8/uNnl5eTblASA5OdlavqSkBHq93qaMRqNBQkKCtcyhQ4dw4cIFyOVy3HjjjQgPD8ddd91l09tzrYaGBhiNRpsXERER+S6HQk1VVRXMZjO0Wq3Ncq1WC71eb3cbvV7fafmW987KnDlzBgCwevVqrFy5Ejt27EBoaChuu+02XL5sv3ckIyMDGo3G+oqMjHTkULtN1pevP3HWYSIi8iF94tYdi8UCAHj66adx7733Ij4+Hm+//TZkMhmys7PtbrN8+XIYDAbr69y5c73ZZCIiIuplDoWasLAwKBQKlJeX2ywvLy+HTqezu41Op+u0fMt7Z2XCw8MBAOPGjbOuVyqVGDVqFEpLS+3uV6lUQq1W27zcQdaX54Xpy71MRERE13Ao1AQEBCA+Ph65ubnWZRaLBbm5uUhMTLS7TWJiok15ANi1a5e1fHR0NHQ6nU0Zo9GI/fv3W8vEx8dDqVSiuLjYWqapqQlnz57FyJEjHTkE9/GaKzkMKkRE1D/5ObpBWloa5s2bh0mTJmHKlClYu3YtTCYT5s+fDwCYO3cuhg0bhoyMDADAkiVLMGPGDLz88suYNWsWsrKycPDgQWzcuBGANCbl8ccfx3PPPYeYmBhER0fjmWeeQUREhHUeGrVajUcffRTp6emIjIzEyJEj8eKLLwIA7rvvPlechx7r0xGCY2qIiMiHOBxqUlNTUVlZiVWrVkGv1yMuLg45OTnWgb6lpaWQy1s7gKZNm4bNmzdj5cqVWLFiBWJiYrBt2zaMHz/eWuapp56CyWTCwoULUV1djenTpyMnJwcqlcpa5sUXX4Sfnx8efPBB1NXVISEhAbt370ZoaKgzx+8y3vOYBCIiov7J4Xlq+ip3zVNzvvQMhr91I5qFHH7PXnFZvT328TJg/+vS15ynhoiI+ji3zVNDfQAH/xIRUT/FUENEREQ+gaHGaewZISIi8gYMNS7CgcJERESexVDjpJbHJHhPf433tISIiKg3MdQ4iwNziYiIvAJDjYvIZbz85BQhgM2zgR2/83RLiIioj2KocVo/66k59C5Q+rXr69UfAU58DBx8y/V1ExFRv+DwjMJky+uuPjnSIEfmXRQC+H4fsH2x9G9XT4RnaXZtfURE1O8w1LiSEF6Ycrqps7abqoC/3A40N7ixAX30vBERkddgqHFW2yDQ10JNd9u671WgutS9bSEiInISx9Q4SSbrB6dQmD3dAiIioi71g0/k3tTH7oDq9pgaB3ufLGbgqz8D577p/jZ9qYeLiIi8Ei8/Oevay099lSsvnR1+D9i1SvqaT9YmIqJewlDjtD7cw9DdEONo2Kk87nhbrlV7Gfjsj87XQ0RE/QZDjZNsP+/7cE+Nx13T4/Xx74Gj73uuOURE1Ocw1DjNSy4/mZuB+mr3zVPT2yq/83QLiIioj+FAYSfZ3v3kwZDw9l3Ai9cB5cd6WEFnbbcTlHY+BXy1rvvlHWqKYKcXERE5jD01TvOSMTXnD0jvp3O7v40zY2oOvCG93/xY9/fX7X0w0RARkePYU+NK3nw5xx5vba8QXpMViYio72CocZJMbqeHwWIGPloKHP2nR9rULfVGYNPdnm4FERGRyzDUOM1Ol8LRfwLf/BX414L26/RHgRq9+5vVlbwNQJOp9d+d9tr0dreJl/YgERGRV+OYGifZ3tH9w4exqcJ+4apTQOZ06WtPT0rXeNV9dfdoEr9r7iJjriEiIgexp8ZJwpF5ai4cdGdT3IePMCAioj6AocZJcnnrKRQtPTXeOgC3z+BAYSIichxDjZMUbXoxLF2GGS/6pG7XVlcGsR4cZ9veoIYa4NJp1zWHiIj6BYYaJykUraew2WyWvuiLl2vqjcAnzwAXj9hZ2RvH02Yfr4wDmmp7YZ9ERORLGGqcpGhz+cli8WBDnPXJSmDfOuCNWzzdEsDc4OkWEBFRH8RQ4yRFm3lqzKIPpxr90Y7X9cWeJyIi6ncYapwkb/PsJ7O5i4HCrg4HVaeAwvdc1EXk4cHNDE5EROQkhhon+bUZUyMv2dO7O18fD2x7FDiypeuyR7KBj56QZjvuTfYCl+E88OlqoK66d9tCREQ+jaHGSfK2PQx1V6R3V/c6dHVXVcvDLDuz9b+Bb/4CHPuwBw1w8HjaHv/GW9uv/9MNwJd/Ap4f2YO2EBER2cdQ46w2H+DCHbd0N1wF/hwLfLjI8W3tqb3k+DbOhLTOxuoAgPEicGZvz+snIiL6AUON09oMFHbHrc/fbgWqvwcK/u7iiq8JYJ6aMPCVscC7PwNOfeqZ/RMRkc9gqHEhay5wZUDok7MT9yDcnf7M9c0gIqJ+haHGWQ7NKExERETuwlDjQuaWp1t2NAalz9623Avt7rPnhoiIvAVDjbPazFPTOHCYBxvirE56mRg4iIioD2CocZZMBj3CAABmmZ+HG+MlGIKIiMgD+CnsAnVQAgAsLRPNuXtszeUS4NA7bRYwRBARETHUuICQyQEBWMwunq236iTQaGq/fF2ca/fTJSdDkxCu6b1prAX8A9kTREREdjHUuID44UNfdPUIAkc+jM8fBP56hxOtclBnvUu98aDO7vRu/TEcGDMLmLPZ/e0hIqI+p0djajZs2ICoqCioVCokJCTgwIHOp+nPzs7G2LFjoVKpMGHCBOzcudNmvRACq1atQnh4OAIDA5GUlISTJ0/arauhoQFxcXGQyWQoLCzsSfNdTvwwWNjSEmo6Ci8lX3SvwtrL9gONWy9rdVD38Y+AvWu6X035MeCLl6+pWkivnOXA15n2t+tu4Cv+qPttISKifsXhULNlyxakpaUhPT0dhw4dQmxsLJKTk1FRUWG3/L59+zBnzhwsWLAABQUFSElJQUpKCoqKiqxlXnjhBaxbtw6ZmZnYv38/BgwYgOTkZNTX17er76mnnkJERISjzXYrgZZQ00mPhukSkP929yr8aKn95d9+4GDL7DA32l9eebz16/JvgbNfSl9n3e9Y/dkP2VkogAuHgK9fA3J+71h9RERE3eRwqHnllVfwyCOPYP78+Rg3bhwyMzMRFBSEt956y275P//5z7jzzjvx5JNP4kc/+hH+8Ic/4KabbsL69esBSL00a9euxcqVK3HPPfdg4sSJePfdd1FWVoZt27bZ1PXxxx/jk08+wUsvveT4kbpRS0+NMDcB574BLp1uX8hkP/TZdf4b+8uPvG9/eXfDEgD8Z0XXZV6fBmyaBVSf6369LRqM9pc31nS+HScuJCIiJzkUahobG5Gfn4+kpKTWCuRyJCUlIS8vz+42eXl5NuUBIDk52Vq+pKQEer3epoxGo0FCQoJNneXl5XjkkUfwt7/9DUFBQV22taGhAUaj0eblLi1jaoYfWQe8mdRByHBkcGsHZS3NHTTATWNeqr/vuswnzwBN7XvUbHQnsJzhYxKIiMg5DoWaqqoqmM1maLVam+VarRZ6vd7uNnq9vtPyLe+dlRFC4KGHHsKjjz6KSZMmdautGRkZ0Gg01ldkZGS3tuuJMWZp/I/6clEXJbupo/zTUahxVKOpmz0j3Qhi+9YBea86tg0REZEb9InJ91599VXU1NRg+fLl3d5m+fLlMBgM1te5cz24lOJKX7/mfB3CRbeMvzi6e+Xsjo+xw+Zym72wJHh5iYiI3M6hUBMWFgaFQoHy8nKb5eXl5dDpdHa30el0nZZvee+szO7du5GXlwelUgk/Pz+MHi19KE+aNAnz5s2zu1+lUgm1Wm3z8iibyfJ6qKtbxjty5ZrLSE213duu2+OAuuidYaAhIqJe4FCoCQgIQHx8PHJzc63LLBYLcnNzkZiYaHebxMREm/IAsGvXLmv56Oho6HQ6mzJGoxH79++3llm3bh0OHz6MwsJCFBYWWm8J37JlC/7v//7PkUPwHlv/H1D6NbBvPdBw9ZqVHYSEnoaDyuKebdddNrdj22l7cz3Q3ODeNhARUb/n8OR7aWlpmDdvHiZNmoQpU6Zg7dq1MJlMmD9/PgBg7ty5GDZsGDIyMgAAS5YswYwZM/Dyyy9j1qxZyMrKwsGDB7Fx40YAgEwmw+OPP47nnnsOMTExiI6OxjPPPIOIiAikpKQAAEaMGGHThoEDBwIArrvuOgwfPrzHB98rLGZArmi//EiW9AKAy2eAu1+Rvt77QvcG6DrC0zPwrnHfeCYiIqIWDoea1NRUVFZWYtWqVdDr9YiLi0NOTo51oG9paSnk8tYOoGnTpmHz5s1YuXIlVqxYgZiYGGzbtg3jx4+3lnnqqadgMpmwcOFCVFdXY/r06cjJyYFKpXLBIXrY/w4CVhs6L1PyufR+Zi/wWRc9TxXfOd6Ggw7c8t0TZ78EXh4L3P0n9+6HiIioEzIh+seAB6PRCI1GA4PB4PLxNVV/HIewxgsdF1htAFZrOl4/eDSwOF/qpeks1AyLBy7kd79hqw1AvQFYM6L9uoT/Afa/3v26uis4Aqgpc329bXUVEomIyGc48vndJ+5+8nYnNDd3XqD8WOfrW3JlV/nS3sMtu9LRWJbeeJ4TERFRL+IDLV1AZm/MTFuv2x9E3aqbnWWOdqqd+wYIGGB/3YE3HKuLiIjIyzHUuIBM7uRpdFevyZtJQNBg99TdEVfNpUNEROQgXn5yAbmii56arnS3B6aqB7dm115yfBtnXC3vugwREZEbMNS4gNOhpruXn4iIiKhDDDUucN2lvc5VwExDRETkNIYaFwi9esq5CngnEhERkdMYaryB8bynW0BERNTnMdS4wMXEdE83gYiIqN9jqHEB+XW3uaaiEzmuqYeIiKgfYqhxAbXK3/lKmuqBskPO10NERNRPMdS4gErhgoG+BX9zvg4iIqJ+jKHGBWTa8V0X6srOJ5yvg4iIqB9jqHGFrp79RERERG7HUENEREQ+gaGGiIiIfAJDDREREfkEhhqi3pa/CcicDhgverolREQ+haGG+rf9G4H35wHmJtvl5mbgq3VAWYHr9/nvJYD+KLBrlevr7o7mRs/sl4jIzRhqXKRWE+PpJlBPfPwkcGwbULTVdvmhTcCuZ4CNt7lv341X3Vd3R4r+BTw3BDi8pXXZpdPAe3OA8wd7vz1ERC7EUOMifgEqTzeBnNFgtP23vsj9+/TE09n/+bD0/sFC6d1iBrIeAIp3An+9o/fbQ0TkQgw1LqK47UlPN6H/qDoJlHzu6VY4z2L27P71RUBGJFD5nWfbQUTkIgw1LqK44R7UQenpZvQP6ycB7/wUKD/m6ZZ0rrmh8/WO9tQcyQY+f7Hn7bnWzieAJpPr6iMi8jCGGhf6e8CvPN2E/qXChaFGCOn909XAprttBw5n3gKc3t29eiwWoLJYClzPDQV2PtXJPh0MNVv/G9j9nOsGL3u6p4iIyMUYalzo6PD7Pd0EckT5t+2Xffkn4OwX0hiTFvojwN9+3r06P34S2DAFeD1R+veBNzouK3oYKjbPtt92ANi3Htj7gu2y07uBM3uAY9tds38iIi/l5+kG+JJfJV4PnPF0K/qh0v3AwbeAmX8ABg61X0YIoL4aCAwFSr4Aai4C+9a1LWBb/tpbvFtcrQSqioGRNwMymbTMdEm6HDZ8EnDonc7b2lRn26a2inOk47ghBZjwK0Dxw4/nqU+BK9+3aYMeeH0a8PhRIGQE0FgLfLUWiEkGPnlaKnPjg4A6HKg3dhzILM2dt5WIqI9hqHGhSVGheLrpYfyf/1uebkr/8tZM6b3xKjD7H/bLbF0IHH0fGHU7cOazblQq7C9eFyftZ84WYMydUjDZ/lug4lvpZc/Vitaw9cnK1uXXXv55L1V6P/kfwFQFRN8KhI4E/n6v/XozpwPLSoEvXgK+eBnY+3zrurz1Ug/NT9fZ3xYALh5uv6ypHvDnnXxE1Dfx8pMLqfwVKNT+AjMaXvF0U/qn4zvs34pdd0UKNEDHgebaXpPmevvlWuaWOfkf6X1/pu2lKnsK/tba83Pk/dblpfuA2sv2t9n1DLBxBrDupo7rrTcAf/uFFGiulbdeGnP078c6b9u1sngJlYj6LoYaF/uvcVp8L3Sebkb/UPC39ssybwY2JEg9HS3WTuy6rpzf2/7b3qWZhjaT5VnM0iWhnGVd1537v8AfwqRekGvnw8mcLvXkdKSug9DT4nRu5+sdHUx9Olc6d9eGPCKiPoChxsWW3MGZhXssOLz9svC4jsuf2QOs1rRfXnkc+OyPQF21dAv0tUGipzKGtX4tzMCfuxGW2vo/bftlxgvdH4TcW168Dngt0dOtICJyGEONi8laBo+S45JW21mW3rO6Dr4JPD9SugXaHQr+7rq6youAzzJcV58rcEI+IuqDGGrcoPi5O/Fa888AAB+ap3Ve+P5sIOLGXmjVNaan9XzbhXu7LvP/vnC83oFaYNEBIHpG6zJNpHSHT29wVwDqjr1rPLfvjlg88BgHIiIn8O4nN1D6KfBS86/wH/MkfCuioNFF47bKDu7K8QsABse452nQnUlKB4aMlS7N7Hyi6/IyeetkcYNGdV52aTEQ3INxRaNuk26Tnrdduk37ajkQFgM8sgd49x6g/KjjdTrClbP1+oL6aiBokKdb0TMV3wHqCEClAb77N1C4GbhnQ+fHU28EPn8BiJ0j/WzIFUB1KXDob4CpArj+LmD0HdLPgSJAmtPoqz8D4bHA9cnS/jSR0q39gDQuyV7PbcV3gH8QoBku/Vyxd5fIZRhq3KRg1Z2I/d9PAABvXIjCbQHXFBioA+R+wPAp0vvR99tX0lOrDdLljK7++o/94RbitqFmRZk0UPTQu9Ktwi2eqZJuRw4ajHa3Oz/8iTTpnCIASP0HEGxn7Ehbvz8LvDQGMP/wGIEHPwCibrH95T4iofXrAYOlW7UdHcNCzukq1LR8aH/xijRh4d1/AkKjbMtcLpHuzpq2GBgyRlpmMQOncoGmWiBquvQcr9O7gTtWARcOSSFBHd5atjRPCgAhI6W7xf56BzDxV9Lt+brxgLFMmvBwzE+A+IeA7IekugFg6LjWwdJZ9wMP50iPr/j+K+DAXwGFP/DzN4CqE8Abt0jl9r1q/3jzN9lfXrJXenVk0gLpcmhHVhvsL6/RA5ABA8Kk8NPcIN2VV14kBa34h4AjW4ArJcCsV4ATOYB/oDQ2bdTt0s/X8Z3AsQ+BoWOB2PulPxIA6cnsgSFA4CDA3CgtszRJv4v8A6UwFxgKBAyU1jVeBUq/BkKjpZ/HhhrpDzFjGTD+XikQntoljWO7UiK1a/rvAGUw4D9A+iPn+31A5BTpLkXjRWlKhDN7gLteAILCpHFqhZul426sAe5cI+2/7JD0/RKZINVTXiT1IkbdLAVJiwX4zwrpOA6+CUx+BPiv/5XuABx9B6CLBWovAYc3SzOGA8DQG6TvoYFDgRt+DhzNBoIjpO/Hhhrg0knpXJ/8VCovk0nfS3I/6ftVHQHc9KB0N2NYjHQ+h08GwicC2xdL53x0EjBymhSQv3lTOhcTfimdQ/9A6VXyhXQH5X2bpLsZt/xaCryWZqkNYWOAhIWAdoI0kWfQYCB+vjRXVvZDUnt0E6TzN3IaYDgPJC6Sfm62PCCNSfRTSsu+/wpQD5PKlh+VeqaTVkvtBaQ/AEKjgB/9TPq5Lfy79DM5cjrw3XbpfALA7PeAw+9JPzu3LJW+T754BfjmL9LvgLF3dzxfWC+QCdE/bnMwGo3QaDQwGAxQq9W9ss85G79G3plLAIDp8qP49awfY0ZzHgLNNcDtT0vfeC0TrG39f8CRLNsKblna/nbdR7+U7pgBpG+muivS10NvaJ0nZbVBmpDtj20G3v7ybeCf86Wv/zu39a9JwHawbdtfsPqjwOEsYMpCab6UFg01QMbw1n+vuiz9VXutf9wHnJSCHW74BfDt1tZ9HN8JZM0Bpj0mTZrXlUungVc7ub2Z3GPMLKD4I+kX8ZUST7eGiPqCjoJ6Dzny+c2eGjf6x38nYNQKaQ6TLy0T8OW/KwGMxqdpMzBaJmsNNADwizeAmc8BL42W/q2dANz6pJTuFUrgP8t/+EtrTOs2T5yU/jo7sFH6a7P2EjBgiLQuIMi2MeN/8UO3ub9toOmMboL0upYyGIj7tfTX8C822g80ADBjmRRqdBOlv8b8lMBN86R1Y38iTRynsnP3kj3qYV2X6S+mPdY6G/JtK4A9f7RfLiYZCIkEvvlrz/dV/JH0zkBDRN3R9jPKA9hT42aGuibEPvtJu+X/b8Yo/Oa20dAE+tuuKPkCOPslcOsTUgBpYbokXQqQyVonbOtqvMOWB6Vuw3EpwK86mb6/padm6iLgzg4+IHvKcB4YMFQaO+Qse7dv91WzXpG62i8clIJd3APA16/ZllGFSF3X5UXApIel7vLSr6Xu57aBWAipx05/VJpV2E8p/XvOFulSoP6o1LunHg4Yz7du99BO4Pw3Uk/c1XLg3AHp++X4jl45BX3W8ClA9ffSJQh7Y+EGXQdcPt377SLfNmKaNGGnt1tyuP1laCc58vnNUNNLEv74KcqNDe2Wjx+mxge/uRn+CjfciFZXDZz4DzB2FqAc2HE540XpeviE+6TrvN6qt0JNxE3SdfxrhYyQxhoAwNITQJMJKCtsvaz35BlpvAEgXV67qpcCSHO9dF6vnAX8Am3HHNkbTFpTLgWR626XesEsFkDuou8P0yXg8hkgcnLHZU58Amy+zzX7G/9LAEK6jl92SHp6eZNJWpf0rBTWrlZIvYx7MqQxE8Yy+2NUpj0mBYl6gzS2oGUsWPxDUih887+kO+hGTJXu7hsyRhr/EH2r1Nv53YfApVPAsHjp/CY8KgVAQJrxufGqdEnXHotF+n+qu+LY4GlzE1D0L+lnMGCgNK7k8HvSJdeWfdVVA0o1sPURoOif0qMtdOOlcSpNdT/sTyaNM2v7/dLRQGRzM3CxUArEyoHSv2svSZNVJjwq3RygjpDKXvleeqp8c700JmNAWMf1dsVibu0NFkJ6EOyQH0l1n9kj9RAHh0vjRcxN0hgeez215iapB3rYJOn7wV5bLBappzhggPQzGTLCtlxL0FcESPsfENa63HBOCvjX/kxZzO17nYWQxjL5q2zPi+GCNIZnUHRr2bpq6T0wxIGT1gXDeemcddQb3radLW3THwVO7pLG0bR8f1+rRi/9rACd/18LIb1c9funhxhq7PB0qBFC4LaX9uD7S7V2129bdDPyv7+CmeO0iBwUZLdMv2eqAr79QBr89979QPQt0lid4zukMUpfviL9AN78mPRB+eZ/SbfLJ/wPMOR66c6Utr8cqk5JHzAT7pM+AC+dln5Rhk+U6jFVSeOUIm6SQoncTxrUNyxeGvDoywwXpA9TP5X0S8/eB11zg/SLPFgrfXAaz0sfFgpe1e6xngYKIh/GUGOHp0NNC72hHlMzOp/a/uGbo/Gb269DubEeo4cOhNKvi5RO9rmyh4OIiDyCocYObwk1LXK/K8eCdw52q+zh9JnWsTdCCM5aTERE/QZDjR3eFmpa7CmuwENvf+PQNtmPJuJ6bXD7QcZEREQ+xpHP7x71zW/YsAFRUVFQqVRISEjAgQMHOi2fnZ2NsWPHQqVSYcKECdi5c6fNeiEEVq1ahfDwcAQGBiIpKQknT560rj979iwWLFiA6OhoBAYG4rrrrkN6ejoaGxt70nyvctuYoTi7ZhZ2PnYL7k/o3uMA7svMQ+yznyBq2UfW1/VPf4xnthWhpEoahHn+Si2yD56D2SJQWdOAhmazOw+DiIjI4xzuqdmyZQvmzp2LzMxMJCQkYO3atcjOzkZxcTGGDm0/i+C+fftw6623IiMjA3fffTc2b96M559/HocOHcL48eMBAM8//zwyMjLwzjvvIDo6Gs888wyOHj2KY8eOQaVSIScnB1u2bMGcOXMwevRoFBUV4ZFHHsGDDz6Il156qd0+7fHWnpqOfH3mEmZv/Nqlde5eOgMhQQEYNEC6vZqXsoiIyNu59fJTQkICJk+ejPXrpSmTLRYLIiMjsXjxYixbtqxd+dTUVJhMJuzY0Tr3xdSpUxEXF4fMzEwIIRAREYGlS5fiiSekWzQNBgO0Wi02bdqE2bNn223Hiy++iNdffx1nzpzpVrv7Wqhp68X/HMfHRXqcqTT1yv7CBioRFxmCr05VYUr0IPwsNgIzb9Ci6IIR4RoVlP5yBAX4QS4DglUc60NERO7jthmFGxsbkZ+fj+XLl1uXyeVyJCUlIS8vz+42eXl5SEuzfSJ0cnIytm3bBgAoKSmBXq9HUlKSdb1Go0FCQgLy8vI6DDUGgwGDBnU8X0RDQwMaGlrnhTEajV0en7d6Mnksnkwea/23EAJCAI1mC767aMTpShOeyD7ssv1VXW3Ap9+VAwD2nqjE3hOVQLZjdcyZEokhwSrMuH4IhocGQqtWYe+JSoRrVLheGwyLRaDRbMFHRy5iSvQg3sZOREROcyjUVFVVwWw2Q6u1fWChVqvF8ePH7W6j1+vtltfr9db1Lcs6KnOtU6dO4dVXX+300lNGRgaeffbZzg+oj5LJZJDJAJVcgRtHhOLGEaH4Zfxw1DY248KVOjSaLXj5kxNoMlvwxckqj7TxvQPnAADrck92UbL7NIH++ObpJAT48TZtIiJqr8/NknXhwgXceeeduO+++/DII490WG758uU2PURGoxGRkZG90USPCQrwQ4w2GADw1kO2M8bWN5nR0GSBJsgfQgg0NFtwoboOHxZcwANTR8JPLsPS7MPYU1zpiaZ3i6GuCdev/BgAMOP6IQj0VyDnW9vgK5cB9940HAKAWuWPT78rh0wGXDZJg8pV/grcMjoMD0+PhibQH2qVPx5+5xvMnhyJYJU/BigV2Hf6EiJCAjE+Qg2dRoWcIj1uiRmCUWEDYKxvwj/2l+LHY4dijDYYtU1mnK0yYUiwElq1CrWNzfjm7BUkRA+Cyr91fiGzRUAukwJpbWMzvjxZBT+FDEo/BW4eHWb9P/FXyKE31mNYSCCEEPjm7BVoAv0xasgA+MllvMRHRNQJh0JNWFgYFAoFysvLbZaXl5dDp9PZ3Uan03VavuW9vLwc4eHhNmXi4uJstisrK8Ptt9+OadOmYePGjZ22ValUQqnsYIrofkjlr7B+yMpkMqj8FbhuyECkzWx9+Nim+baz5AohYGo0Y6BS+japazTj2zIDtGoV3vyyBLWNzTiur4GxrglnO5gp2V32nrAfviwCyM4/b3cdANTUN2NrwQVsLbhgszz/+ysO7f/F/xQ7VL6vuXtiOKquNuCnsRG4NWYIGs0WFOtrsO90FWZcPxQjBgXh6zOX0GwRqG1oxs0xYTh/pQ4fH72I2MgQzLh+CGobm3Hv63lYdtdYzEuMQlGZASGB/qi62ggBgcfeK8Q9cRGYOmowrhsyAHuKKzE9JgwjBgXBIgSaLQI5RXpEhw0AAFy4UocL1XXQqlVoMltwoOQyvj5zCZsfmYrosAF4N+8ssg6cwxPJ1+O7izWobWzGL24ajiumRqj8FRgarIS/Qo5glR9kMhkqaupxxdQEmQz49Fg5YiNDYBYCQf4K+CnkiB8ZivNXarHlm3MI1wTizvE6HNcbccXUhJ9M0OFMlQkqfwX8FTIUlFZjWEggwjUqhAQFQCGX4T/f6rH205P4WWwE5t8cBZW/Ao3NFggIKGQyKOQymC0C35YZUddkxo90amiCbKdpaAnD9U0WXK6VgrnFIhDgJ4dMBjQ0Wdpduq0w1kPpr4Am0B9nq0yQyYCIkEDknb6E67XB+P6SCX4KGeIiQ6GQy1BT34STFVdxY2TIDzPiy6yXuL+/XItvywyYNSHcJlALIVDXZEZ1bRMGBPhBE+QPQ20TgpQKfH+pFtFhA6whvq3LpkZsK7iAO340FCMHD7DWJZPJcO5yLQIDFAgbqITFIrC/5DIMdU24fewQnL9SB1NDMyYOD4HFIiCXy/DN2csoN9bj7okR1vpr6psgl8kQFKCAsa4ZfgoZistrcL02GAOVfii6YMCIwUFQXzMWsKXOSz9cep8cNQijhgyEobYJV2ob4aeQYUiwEsfKjPBXyHFDhNruHxhCCBzX10Auk2GMLrhbYw2FEDhRfhXXDRkAP4Ucjc0WXKlthEUIhGsCcfS8AUPVSoQGBeD8lVqMHDwACrnt/0WzReB05VXEDA22rrNYBE5U1GDwAKX15pC227X18dGLqDI14sGpI23qlclkaGy2oKTKhMqaBtw0MgRBAbax4UR5DcIGKqWfKwB+7njkjwN6NFB4ypQpePXVVwFIA4VHjBiB3/72tx0OFK6trcW///1v67Jp06Zh4sSJNgOFn3jiCSxduhSA1KsydOhQm4HCFy5cwO233474+Hj8/e9/h0Lh2Cy7fXmgcF9y7Q/x1YZmHD1vwOSoUAhIv6Q/LLwATWAAxg9TI1wTiK9OVSE6bABq6pshk0kTE47RqXG1oQm/2+K6sUJEROReS+6Iwe/+63qX1unWu5+2bNmCefPm4Y033sCUKVOwdu1avP/++zh+/Di0Wi3mzp2LYcOGISMjA4B0S/eMGTOwZs0azJo1C1lZWfjjH//Y7pbuNWvW2NzSfeTIEest3RcuXMBtt92GkSNH4p133rEJNB31EDlzUsi7NZktyDt9CXPfOoAHEkYgwE+OhOhB+N2Ww6hrsp2PRy6Tem9a3omIyL1KMn7i0kvlbrv7CZB6XiorK7Fq1Sro9XrExcUhJyfHOtC3tLQU8jbP25k2bRo2b96MlStXYsWKFYiJicG2bdusgQYAnnrqKZhMJixcuBDV1dWYPn06cnJyoFKpAAC7du3CqVOncOrUKQwfPtymPf1kQmRqw18hx63XD8HZNbNslt85Ptxtt5Z3VW+T2dLuSettt2k2W3Cq8ipMDWbEjwy1rj920YgxP4yD+u5iDcZFqFHb2Iw3vyxB0o+0GD9MeopxY7MFAX5y6+WIj45exLCQQEwYpkF5TQMKS6sxKSoUHxRcgCbQH2N0wRijDYZZCDQ2W/D7fx5BmaEe98UPx1tfleCxH8dg6qjBWP7BEahV/lh59zhkHzyHcI0Kr+853euXE4nINzyeFOPRsX98TAIRdUhvqMdAlR9UfnK3XytvMltgEaLTB7jaC5fNZotDbRNCwGwRNtuYLcI63uDafegN9RgarLSONenOL+yWkNsyALxlPJsQ0hia0UMH2gwkt7dt2/aeqTKhurYRN40IhbG+GbWNzQjXBAIADLVNkMtb54y6VmOzBY1mi3VsXMt4mYZmCy6ZGnC60oRbY8Jsjqu6thGaQH/r2KPSS7UYF6FGoL8CdU1myH8YlwcAtY3NAKQbFU5XXoVWrcKRc9WormvC7WOGQuknx5mqqxg5eAD8FXLU1DdhoNIPxvpmKOQya7vaamg2o+iCEePC1ZDLgXJDA4rKDJgUFYqhwSqcu1wLhVyGsIFK692QR88bIJPB+ofAtefUIgRkkCHAT476JjOaLQJKPzlkkMaaWETrGKaa+maoA/2hkMvQZLag2Sx9f1RebYA2WInSy7UIVvkjJMgfMgCmRjMsFoHQAQE4XXkVapU/DHWNyDtzGbHDNbja0Aw/uRxTogfBUNsEhUKGC1fqoJDLcN2QAdZzb6htgoA0C3x1XRMmR0nTlpy/UouvTlVhctQgDAsNRH2jBXI5EOAnh1wmQ22DGUFKhfX7xmIRyDtzCaOGDIBOrYJMJsN3F434/lItEkcNto7dahlL1PJ9cdnUiGCVPwL8pO/d7y/VYsSgINQ1mTFA6YeGZjMMtU0YqPJDUICftVNBJmsdhyXvYNyOM/jsJzsYaoiIiPoetz/7iYiIiMjbMNQQERGRT2CoISIiIp/AUENEREQ+gaGGiIiIfAJDDREREfkEhhoiIiLyCQw1RERE5BMYaoiIiMgnMNQQERGRT2CoISIiIp/AUENEREQ+gaGGiIiIfEL7Z777qJaHkRuNRg+3hIiIiLqr5XO75XO8M/0m1NTU1AAAIiMjPdwSIiIiclRNTQ00Gk2nZWSiO9HHB1gsFpSVlSE4OBgymcyldRuNRkRGRuLcuXNQq9UurZta8Tz3Dp7n3sHz3Ht4rnuHu86zEAI1NTWIiIiAXN75qJl+01Mjl8sxfPhwt+5DrVbzB6YX8Dz3Dp7n3sHz3Ht4rnuHO85zVz00LThQmIiIiHwCQw0RERH5BIYaF1AqlUhPT4dSqfR0U3waz3Pv4HnuHTzPvYfnund4w3nuNwOFiYiIyLexp4aIiIh8AkMNERER+QSGGiIiIvIJDDVERETkExhqnLRhwwZERUVBpVIhISEBBw4c8HSTvNrnn3+On/70p4iIiIBMJsO2bdts1gshsGrVKoSHhyMwMBBJSUk4efKkTZnLly/jgQcegFqtRkhICBYsWICrV6/alDly5AhuueUWqFQqREZG4oUXXnD3oXmVjIwMTJ48GcHBwRg6dChSUlJQXFxsU6a+vh6LFi3C4MGDMXDgQNx7770oLy+3KVNaWopZs2YhKCgIQ4cOxZNPPonm5mabMnv27MFNN90EpVKJ0aNHY9OmTe4+PK/x+uuvY+LEidbJxhITE/Hxxx9b1/Mcu8eaNWsgk8nw+OOPW5fxXDtv9erVkMlkNq+xY8da1/eJcyyox7KyskRAQIB46623xLfffiseeeQRERISIsrLyz3dNK+1c+dO8fTTT4utW7cKAOKDDz6wWb9mzRqh0WjEtm3bxOHDh8XPfvYzER0dLerq6qxl7rzzThEbGyu+/vpr8cUXX4jRo0eLOXPmWNcbDAah1WrFAw88IIqKisR7770nAgMDxRtvvNFbh+lxycnJ4u233xZFRUWisLBQ/OQnPxEjRowQV69etZZ59NFHRWRkpMjNzRUHDx4UU6dOFdOmTbOub25uFuPHjxdJSUmioKBA7Ny5U4SFhYnly5dby5w5c0YEBQWJtLQ0cezYMfHqq68KhUIhcnJyevV4PWX79u3io48+EidOnBDFxcVixYoVwt/fXxQVFQkheI7d4cCBAyIqKkpMnDhRLFmyxLqc59p56enp4oYbbhAXL160viorK63r+8I5ZqhxwpQpU8SiRYus/zabzSIiIkJkZGR4sFV9x7WhxmKxCJ1OJ1588UXrsurqaqFUKsV7770nhBDi2LFjAoD45ptvrGU+/vhjIZPJxIULF4QQQrz22msiNDRUNDQ0WMv8/ve/F2PGjHHzEXmviooKAUDs3btXCCGdV39/f5GdnW0t89133wkAIi8vTwghBVC5XC70er21zOuvvy7UarX13D711FPihhtusNlXamqqSE5Odvchea3Q0FDx17/+lefYDWpqakRMTIzYtWuXmDFjhjXU8Fy7Rnp6uoiNjbW7rq+cY15+6qHGxkbk5+cjKSnJukwulyMpKQl5eXkebFnfVVJSAr1eb3NONRoNEhISrOc0Ly8PISEhmDRpkrVMUlIS5HI59u/fby1z6623IiAgwFomOTkZxcXFuHLlSi8djXcxGAwAgEGDBgEA8vPz0dTUZHOux44dixEjRtic6wkTJkCr1VrLJCcnw2g04ttvv7WWaVtHS5n++DNgNpuRlZUFk8mExMREnmM3WLRoEWbNmtXufPBcu87JkycRERGBUaNG4YEHHkBpaSmAvnOOGWp6qKqqCmaz2eY/DwC0Wi30er2HWtW3tZy3zs6pXq/H0KFDbdb7+flh0KBBNmXs1dF2H/2JxWLB448/jptvvhnjx48HIJ2HgIAAhISE2JS99lx3dR47KmM0GlFXV+eOw/E6R48excCBA6FUKvHoo4/igw8+wLhx43iOXSwrKwuHDh1CRkZGu3U8166RkJCATZs2IScnB6+//jpKSkpwyy23oKamps+c437zlG6i/mrRokUoKirCl19+6emm+KQxY8agsLAQBoMB//znPzFv3jzs3bvX083yKefOncOSJUuwa9cuqFQqTzfHZ911113WrydOnIiEhASMHDkS77//PgIDAz3Ysu5jT00PhYWFQaFQtBv5XV5eDp1O56FW9W0t562zc6rT6VBRUWGzvrm5GZcvX7YpY6+OtvvoL377299ix44d+OyzzzB8+HDrcp1Oh8bGRlRXV9uUv/Zcd3UeOyqjVqv7zC9BZwUEBGD06NGIj49HRkYGYmNj8ec//5nn2IXy8/NRUVGBm266CX5+fvDz88PevXuxbt06+Pn5QavV8ly7QUhICK6//nqcOnWqz3w/M9T0UEBAAOLj45Gbm2tdZrFYkJubi8TERA+2rO+Kjo6GTqezOadGoxH79++3ntPExERUV1cjPz/fWmb37t2wWCxISEiwlvn888/R1NRkLbNr1y6MGTMGoaGhvXQ0niWEwG9/+1t88MEH2L17N6Kjo23Wx8fHw9/f3+ZcFxcXo7S01OZcHz161CZE7tq1C2q1GuPGjbOWaVtHS5n+/DNgsVjQ0NDAc+xCd9xxB44ePYrCwkLra9KkSXjggQesX/Ncu97Vq1dx+vRphIeH953vZ5cMN+6nsrKyhFKpFJs2bRLHjh0TCxcuFCEhITYjv8lWTU2NKCgoEAUFBQKAeOWVV0RBQYH4/vvvhRDSLd0hISHiww8/FEeOHBH33HOP3Vu6b7zxRrF//37x5ZdfipiYGJtbuqurq4VWqxUPPvigKCoqEllZWSIoKKhf3dL9P//zP0Kj0Yg9e/bY3J5ZW1trLfPoo4+KESNGiN27d4uDBw+KxMREkZiYaF3fcnvmzJkzRWFhocjJyRFDhgyxe3vmk08+Kb777juxYcOGfnUL7LJly8TevXtFSUmJOHLkiFi2bJmQyWTik08+EULwHLtT27ufhOC5doWlS5eKPXv2iJKSEvHVV1+JpKQkERYWJioqKoQQfeMcM9Q46dVXXxUjRowQAQEBYsqUKeLrr7/2dJO82meffSYAtHvNmzdPCCHd1v3MM88IrVYrlEqluOOOO0RxcbFNHZcuXRJz5swRAwcOFGq1WsyfP1/U1NTYlDl8+LCYPn26UCqVYtiwYWLNmjW9dYhewd45BiDefvtta5m6ujrxm9/8RoSGhoqgoCDx85//XFy8eNGmnrNnz4q77rpLBAYGirCwMLF06VLR1NRkU+azzz4TcXFxIiAgQIwaNcpmH77u4YcfFiNHjhQBAQFiyJAh4o477rAGGiF4jt3p2lDDc+281NRUER4eLgICAsSwYcNEamqqOHXqlHV9XzjHMiGEcE2fDxEREZHncEwNERER+QSGGiIiIvIJDDVERETkExhqiIiIyCcw1BAREZFPYKghIiIin8BQQ0RERD6BoYaIiIh8AkMNERER+QSGGiIiIvIJDDVERETkExhqiIiIyCf8fxD5zHIWuoLlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95abc35-5c1e-4d2f-b397-57eec54d7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeed1d-153d-415f-8687-2cbd3358ced6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a371a420-58c7-4fba-9bba-8ab9c4c66e8d",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a0537d-f695-430e-8b9b-2ad9bf558e39",
   "metadata": {},
   "source": [
    "Evaluate with raw predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7b94ab-fca8-4969-8e08-9798f707c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from mlp_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_weight = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/mlp_v2_weights/2024_06_17/best_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"mps\"\n",
    "\n",
    "# Load the model state dictionary\n",
    "model = MLP_v2()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(model_weight))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_weight,\n",
    "                                     map_location=torch.device(device)))\n",
    "    \n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)\n",
    "print('Model loaded from mlp_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea6a74a-fc26-4f14-a429-7d133a9a4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_input_path = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/scaler/2024_06_17/scaler_X.pkl\"\n",
    "scaler_output_path = \"/home/giakhang/dev/Hand_pose_estimation_3D/hand_landmarks/neural_networks/scaler/2024_06_17/scaler_Y.pkl\"\n",
    "\n",
    "scaler_input = joblib.load(scaler_input_path)\n",
    "scaler_output = joblib.load(scaler_output_path)\n",
    "\n",
    "# Fit the scaler on the data and transform\n",
    "X_test_scaled = scaler_input.transform(X_test)\n",
    "\n",
    "Y_test_scaled = scaler_output.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4e3a972-ffe4-4b94-a53e-7b7cfdd6c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create datasets\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 512  # Adjust according to your needs\n",
    "\n",
    "# Create DataLoader objects\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44df06d5-6857-4192-8f42-784f699e9181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss of the model on the test set: 0.0023\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f'Average Loss of the model on the test set: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0add39-2edf-4f75-b7d8-fc7e4276c036",
   "metadata": {},
   "source": [
    "Evaluate with scaled predictions (error unit: mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ed8ee9-6d8b-4952-9d13-f9e1348694dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = X_test_tensor.to(device)\n",
    "predictions = model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2701053b-19d3-4bd6-8cdf-8ef5901f3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.detach().to(\"cpu\").numpy()\n",
    "predictions_in_mm = scaler_output.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13262655-cd58-4f26-9c41-24b1abfb8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_tensor = scaler_output.inverse_transform(Y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c63c78-4c9b-4a8c-a9bd-8583419090e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.2786998701596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Y_test_tensor, predictions_in_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86ccff-adba-41df-a075-983a576866f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485a32eb-4bcc-4182-851f-44ddcc1118dd",
   "metadata": {},
   "source": [
    "# Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8db5eb2-dca9-443f-9802-bfafc03d6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_in_mm = predictions_in_mm.reshape(predictions_in_mm.shape[0], 21, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "757bc96b-a55a-4f51-a564-ffa9c11d6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_landmarks_through_frame(predictions_in_mm, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a6f3b-70d4-443d-81b4-d0ff21c312af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5aad8-9cf4-47d0-998e-606f15beb65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237da95-4baf-4b08-b280-536688086f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebafbe-5181-4886-9878-e508351f7b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
