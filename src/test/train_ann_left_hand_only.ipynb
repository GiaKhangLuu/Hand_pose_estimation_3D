{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/giakhang/dev/pose_sandbox\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(os.curdir),\n",
    "                \"Hand_pose_estimation_3D/arm_and_hand\"))\n",
    "sys.path.append(os.path.join(os.path.abspath(os.curdir),\n",
    "                \"Hand_pose_estimation_3D\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from ann import ANN\n",
    "from dataloader_hand_only_ann import HandLandmarksDataset_ANN\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from csv_writer import columns_to_normalize, fusion_csv_columns_name\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from landmarks_scaler import LandmarksScaler\n",
    "from train_ann_no_intrinsics import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hand_lmks = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = (num_hand_lmks * 3 * 2) + (5 * 3)  # use thumb as anchor\n",
    "OUTPUT_DIM = num_hand_lmks * 3\n",
    "HIDDEN_DIM_CONTAINER = [num_hand_lmks * 3 * 2, 100, 100, 100, 70, 70]\n",
    "NUM_HIDDEN_LAYERS = 5\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "model = ANN(input_dim=INPUT_DIM,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            hidden_dim_container=HIDDEN_DIM_CONTAINER,\n",
    "            num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
    "            dropout_rate=DROPOUT_RATE)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ann_left_hand\"\n",
    "DATETIME = \"{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "DATE = \"{}\".format(datetime.now().strftime(\"%Y%m%d\"))\n",
    "BASE_DIR = \"Hand_pose_estimation_3D/arm_and_hand/runs/{}\".format(MODEL_NAME)\n",
    "SAVE_DIR = os.path.join(BASE_DIR, DATE, DATETIME)\n",
    "DATA_DIR = \"data\"  \n",
    "writer = SummaryWriter(log_dir=SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_hand_fused_names = [\"left shoulder\", \"left elbow\", \"left hip\", \"right shoulder\",\n",
    "    \"right hip\", \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \n",
    "    \"THUMB_TIP\", \"INDEX_FINGER_MCP\", \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\",\n",
    "    \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_MCP\", \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\",\n",
    "    \"MIDDLE_FINGER_TIP\", \"RING_FINGER_MCP\", \"RING_FINGER_PIP\", \"RING_FINGER_DIP\",\n",
    "    \"RING_FINGER_TIP\", \"PINKY_MCP\", \"PINKY_PIP\", \"PINKY_DIP\", \"PINKY_TIP\", \"right elbow\",\n",
    "    \"RIGHT_WRIST\", \"RIGHT_THUMB_CMC\", \"RIGHT_THUMB_MCP\", \"RIGHT_THUMB_IP\", \"RIGHT_THUMB_TIP\",\n",
    "    \"RIGHT_INDEX_FINGER_MCP\", \"RIGHT_INDEX_FINGER_PIP\", \"RIGHT_INDEX_FINGER_DIP\",\n",
    "    \"RIGHT_INDEX_FINGER_TIP\", \"RIGHT_MIDDLE_FINGER_MCP\", \"RIGHT_MIDDLE_FINGER_PIP\",\n",
    "    \"RIGHT_MIDDLE_FINGER_DIP\", \"RIGHT_MIDDLE_FINGER_TIP\", \"RIGHT_RING_FINGER_MCP\",\n",
    "    \"RIGHT_RING_FINGER_PIP\", \"RIGHT_RING_FINGER_DIP\", \"RIGHT_RING_FINGER_TIP\",\n",
    "    \"RIGHT_PINKY_MCP\", \"RIGHT_PINKY_PIP\", \"RIGHT_PINKY_DIP\", \"RIGHT_PINKY_TIP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"  \n",
    "SELECTED_DATE = \"2024-*\"  # Keep '*' when using glob.glob\n",
    "\n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"train\")))\n",
    "val_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"val\")))\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "train_body_distance_thres = 550\n",
    "train_leftarm_distance_thres = 550\n",
    "train_lefthand_distance_thres = 200\n",
    "val_body_distance_thres = 450\n",
    "val_leftarm_distance_thres = 450\n",
    "val_lefthand_distance_thres = 150\n",
    "\n",
    "input_scaler = MinMaxScaler()\n",
    "output_scaler = MinMaxScaler()\n",
    "\n",
    "train_dataset = HandLandmarksDataset_ANN(train_paths, \n",
    "    arm_hand_fused_names,\n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    train_body_distance_thres, \n",
    "    train_leftarm_distance_thres, \n",
    "    train_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_thumb_as_anchor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hand_pose_estimation_3D/arm_and_hand/runs/ann_left_hand/20241106/20241106-1755/output_scaler.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_scaler.fit_transform(train_dataset._inputs)\n",
    "output_scaler.fit_transform(train_dataset._outputs)\n",
    "\n",
    "input_scaler_save_path = os.path.join(SAVE_DIR, \"input_scaler.pkl\")\n",
    "output_scaler_save_path = os.path.join(SAVE_DIR, \"output_scaler.pkl\")\n",
    "\n",
    "joblib.dump(input_scaler, input_scaler_save_path)\n",
    "joblib.dump(output_scaler, output_scaler_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = LandmarksScaler(scaler_path=input_scaler_save_path)\n",
    "output_scaler = LandmarksScaler(scaler_path=output_scaler_save_path)\n",
    "\n",
    "train_dataset = HandLandmarksDataset_ANN(train_paths, \n",
    "    arm_hand_fused_names,\n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    train_body_distance_thres, \n",
    "    train_leftarm_distance_thres, \n",
    "    train_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_thumb_as_anchor=True,\n",
    "    input_scaler=input_scaler,\n",
    "    output_scaler=output_scaler)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = HandLandmarksDataset_ANN(val_paths,\n",
    "    arm_hand_fused_names,\n",
    "    body_lines,\n",
    "    lefthand_lines,\n",
    "    val_body_distance_thres,\n",
    "    val_leftarm_distance_thres,\n",
    "    val_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_thumb_as_anchor=True,\n",
    "    input_scaler=input_scaler,\n",
    "    output_scaler=output_scaler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1000, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 10000\n",
    "current_time = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "save_path = os.path.join(SAVE_DIR, \"{}_{}_layers_best.pth\".format(MODEL_NAME, NUM_HIDDEN_LAYERS))\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', \n",
    "    factor=math.sqrt(0.1), patience=500, verbose=True, min_lr=1e-9)\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with Validation Loss: 2.2295\n",
      "Model saved with Validation Loss: 1.6609\n",
      "Model saved with Validation Loss: 1.3064\n",
      "Model saved with Validation Loss: 1.1265\n",
      "Model saved with Validation Loss: 1.0381\n",
      "Model saved with Validation Loss: 0.9746\n",
      "Model saved with Validation Loss: 0.9271\n",
      "Model saved with Validation Loss: 0.8935\n",
      "Model saved with Validation Loss: 0.8598\n",
      "Model saved with Validation Loss: 0.8363\n",
      "Model saved with Validation Loss: 0.8187\n",
      "Model saved with Validation Loss: 0.8001\n",
      "Model saved with Validation Loss: 0.7866\n",
      "Model saved with Validation Loss: 0.7691\n",
      "Model saved with Validation Loss: 0.7559\n",
      "Model saved with Validation Loss: 0.7479\n",
      "Model saved with Validation Loss: 0.7478\n",
      "Model saved with Validation Loss: 0.7357\n",
      "Model saved with Validation Loss: 0.7119\n",
      "Model saved with Validation Loss: 0.7009\n",
      "Model saved with Validation Loss: 0.6850\n",
      "Model saved with Validation Loss: 0.6764\n",
      "Model saved with Validation Loss: 0.6692\n",
      "Model saved with Validation Loss: 0.6462\n",
      "Model saved with Validation Loss: 0.6303\n",
      "Model saved with Validation Loss: 0.6052\n",
      "Model saved with Validation Loss: 0.5805\n",
      "Model saved with Validation Loss: 0.5549\n",
      "Model saved with Validation Loss: 0.5221\n",
      "Model saved with Validation Loss: 0.5060\n",
      "Model saved with Validation Loss: 0.4978\n",
      "Model saved with Validation Loss: 0.4773\n",
      "Model saved with Validation Loss: 0.4095\n",
      "Model saved with Validation Loss: 0.3734\n",
      "Epoch 50/10000, Training Loss: 0.3555\n",
      "Epoch 50/10000, Validation Loss: 0.4050\n",
      "Model saved with Validation Loss: 0.3370\n",
      "Model saved with Validation Loss: 0.3240\n",
      "Model saved with Validation Loss: 0.3198\n",
      "Model saved with Validation Loss: 0.3108\n",
      "Model saved with Validation Loss: 0.2944\n",
      "Model saved with Validation Loss: 0.2853\n",
      "Model saved with Validation Loss: 0.2366\n",
      "Model saved with Validation Loss: 0.2193\n",
      "Model saved with Validation Loss: 0.2065\n",
      "Model saved with Validation Loss: 0.2045\n",
      "Model saved with Validation Loss: 0.1973\n",
      "Epoch 100/10000, Training Loss: 0.2658\n",
      "Epoch 100/10000, Validation Loss: 0.2107\n",
      "Model saved with Validation Loss: 0.1967\n",
      "Model saved with Validation Loss: 0.1771\n",
      "Model saved with Validation Loss: 0.1676\n",
      "Model saved with Validation Loss: 0.1552\n",
      "Epoch 150/10000, Training Loss: 0.2252\n",
      "Epoch 150/10000, Validation Loss: 0.2400\n",
      "Model saved with Validation Loss: 0.1490\n",
      "Model saved with Validation Loss: 0.1473\n",
      "Model saved with Validation Loss: 0.1468\n",
      "Model saved with Validation Loss: 0.1460\n",
      "Epoch 200/10000, Training Loss: 0.2053\n",
      "Epoch 200/10000, Validation Loss: 0.2037\n",
      "Model saved with Validation Loss: 0.1453\n",
      "Model saved with Validation Loss: 0.1413\n",
      "Model saved with Validation Loss: 0.1389\n",
      "Model saved with Validation Loss: 0.1389\n",
      "Model saved with Validation Loss: 0.1382\n",
      "Model saved with Validation Loss: 0.1339\n",
      "Epoch 250/10000, Training Loss: 0.1864\n",
      "Epoch 250/10000, Validation Loss: 0.1600\n",
      "Model saved with Validation Loss: 0.1321\n",
      "Epoch 300/10000, Training Loss: 0.1846\n",
      "Epoch 300/10000, Validation Loss: 0.1527\n",
      "Model saved with Validation Loss: 0.1284\n",
      "Epoch 350/10000, Training Loss: 0.1868\n",
      "Epoch 350/10000, Validation Loss: 0.1426\n",
      "Model saved with Validation Loss: 0.1275\n",
      "Model saved with Validation Loss: 0.1269\n",
      "Model saved with Validation Loss: 0.1266\n",
      "Model saved with Validation Loss: 0.1216\n",
      "Epoch 400/10000, Training Loss: 0.1717\n",
      "Epoch 400/10000, Validation Loss: 0.1314\n",
      "Model saved with Validation Loss: 0.1200\n",
      "Model saved with Validation Loss: 0.1198\n",
      "Epoch 450/10000, Training Loss: 0.1660\n",
      "Epoch 450/10000, Validation Loss: 0.1294\n",
      "Model saved with Validation Loss: 0.1194\n",
      "Model saved with Validation Loss: 0.1178\n",
      "Epoch 500/10000, Training Loss: 0.1734\n",
      "Epoch 500/10000, Validation Loss: 0.1453\n",
      "Model saved with Validation Loss: 0.1113\n",
      "Epoch 550/10000, Training Loss: 0.1555\n",
      "Epoch 550/10000, Validation Loss: 0.1188\n",
      "Epoch 600/10000, Training Loss: 0.1572\n",
      "Epoch 600/10000, Validation Loss: 0.1653\n",
      "Model saved with Validation Loss: 0.1110\n",
      "Model saved with Validation Loss: 0.1089\n",
      "Epoch 650/10000, Training Loss: 0.1528\n",
      "Epoch 650/10000, Validation Loss: 0.1347\n",
      "Model saved with Validation Loss: 0.1086\n",
      "Model saved with Validation Loss: 0.1078\n",
      "Model saved with Validation Loss: 0.1076\n",
      "Model saved with Validation Loss: 0.1068\n",
      "Epoch 700/10000, Training Loss: 0.1496\n",
      "Epoch 700/10000, Validation Loss: 0.1376\n",
      "Model saved with Validation Loss: 0.1058\n",
      "Epoch 750/10000, Training Loss: 0.1533\n",
      "Epoch 750/10000, Validation Loss: 0.1245\n",
      "Epoch 800/10000, Training Loss: 0.1489\n",
      "Epoch 800/10000, Validation Loss: 0.1321\n",
      "Model saved with Validation Loss: 0.1058\n",
      "Model saved with Validation Loss: 0.1053\n",
      "Model saved with Validation Loss: 0.0995\n",
      "Epoch 850/10000, Training Loss: 0.1455\n",
      "Epoch 850/10000, Validation Loss: 0.1102\n",
      "Model saved with Validation Loss: 0.0955\n",
      "Epoch 900/10000, Training Loss: 0.1448\n",
      "Epoch 900/10000, Validation Loss: 0.1020\n",
      "Epoch 950/10000, Training Loss: 0.1497\n",
      "Epoch 950/10000, Validation Loss: 0.1486\n",
      "Epoch 1000/10000, Training Loss: 0.1471\n",
      "Epoch 1000/10000, Validation Loss: 0.1177\n",
      "Epoch 1050/10000, Training Loss: 0.1415\n",
      "Epoch 1050/10000, Validation Loss: 0.1206\n",
      "Epoch 1100/10000, Training Loss: 0.1381\n",
      "Epoch 1100/10000, Validation Loss: 0.1119\n",
      "Epoch 1150/10000, Training Loss: 0.1372\n",
      "Epoch 1150/10000, Validation Loss: 0.0998\n",
      "Epoch 1200/10000, Training Loss: 0.1402\n",
      "Epoch 1200/10000, Validation Loss: 0.1326\n",
      "Epoch 1250/10000, Training Loss: 0.1430\n",
      "Epoch 1250/10000, Validation Loss: 0.1419\n",
      "Model saved with Validation Loss: 0.0864\n",
      "Epoch 1300/10000, Training Loss: 0.1349\n",
      "Epoch 1300/10000, Validation Loss: 0.1017\n",
      "Epoch 1350/10000, Training Loss: 0.1373\n",
      "Epoch 1350/10000, Validation Loss: 0.1188\n",
      "Epoch 1400/10000, Training Loss: 0.1363\n",
      "Epoch 1400/10000, Validation Loss: 0.1126\n",
      "Epoch 1450/10000, Training Loss: 0.1315\n",
      "Epoch 1450/10000, Validation Loss: 0.1423\n",
      "Epoch 1500/10000, Training Loss: 0.1350\n",
      "Epoch 1500/10000, Validation Loss: 0.1248\n",
      "Epoch 1550/10000, Training Loss: 0.1307\n",
      "Epoch 1550/10000, Validation Loss: 0.1143\n",
      "Epoch 1600/10000, Training Loss: 0.1317\n",
      "Epoch 1600/10000, Validation Loss: 0.0980\n",
      "Epoch 1650/10000, Training Loss: 0.1414\n",
      "Epoch 1650/10000, Validation Loss: 0.1253\n",
      "Epoch 1700/10000, Training Loss: 0.1419\n",
      "Epoch 1700/10000, Validation Loss: 0.2335\n",
      "Epoch 1750/10000, Training Loss: 0.1306\n",
      "Epoch 1750/10000, Validation Loss: 0.1344\n",
      "Epoch 01788: reducing learning rate of group 0 to 3.1623e-04.\n",
      "Epoch 1800/10000, Training Loss: 0.1301\n",
      "Epoch 1800/10000, Validation Loss: 0.0925\n",
      "Model saved with Validation Loss: 0.0859\n",
      "Model saved with Validation Loss: 0.0854\n",
      "Model saved with Validation Loss: 0.0843\n",
      "Epoch 1850/10000, Training Loss: 0.1300\n",
      "Epoch 1850/10000, Validation Loss: 0.0882\n",
      "Model saved with Validation Loss: 0.0822\n",
      "Epoch 1900/10000, Training Loss: 0.1294\n",
      "Epoch 1900/10000, Validation Loss: 0.0920\n",
      "Epoch 1950/10000, Training Loss: 0.1278\n",
      "Epoch 1950/10000, Validation Loss: 0.0943\n",
      "Model saved with Validation Loss: 0.0809\n",
      "Epoch 2000/10000, Training Loss: 0.1305\n",
      "Epoch 2000/10000, Validation Loss: 0.0879\n",
      "Epoch 2050/10000, Training Loss: 0.1322\n",
      "Epoch 2050/10000, Validation Loss: 0.1013\n",
      "Epoch 2100/10000, Training Loss: 0.1281\n",
      "Epoch 2100/10000, Validation Loss: 0.0923\n",
      "Epoch 2150/10000, Training Loss: 0.1302\n",
      "Epoch 2150/10000, Validation Loss: 0.1037\n",
      "Epoch 2200/10000, Training Loss: 0.1270\n",
      "Epoch 2200/10000, Validation Loss: 0.0861\n",
      "Epoch 2250/10000, Training Loss: 0.1265\n",
      "Epoch 2250/10000, Validation Loss: 0.0867\n",
      "Epoch 2300/10000, Training Loss: 0.1279\n",
      "Epoch 2300/10000, Validation Loss: 0.0868\n",
      "Epoch 2350/10000, Training Loss: 0.1273\n",
      "Epoch 2350/10000, Validation Loss: 0.0933\n",
      "Epoch 2400/10000, Training Loss: 0.1279\n",
      "Epoch 2400/10000, Validation Loss: 0.0887\n",
      "Model saved with Validation Loss: 0.0804\n",
      "Epoch 2450/10000, Training Loss: 0.1272\n",
      "Epoch 2450/10000, Validation Loss: 0.0932\n",
      "Epoch 2500/10000, Training Loss: 0.1255\n",
      "Epoch 2500/10000, Validation Loss: 0.0869\n",
      "Epoch 2550/10000, Training Loss: 0.1250\n",
      "Epoch 2550/10000, Validation Loss: 0.0848\n",
      "Epoch 2600/10000, Training Loss: 0.1310\n",
      "Epoch 2600/10000, Validation Loss: 0.0898\n",
      "Epoch 2650/10000, Training Loss: 0.1258\n",
      "Epoch 2650/10000, Validation Loss: 0.0982\n",
      "Epoch 2700/10000, Training Loss: 0.1252\n",
      "Epoch 2700/10000, Validation Loss: 0.0884\n",
      "Epoch 2750/10000, Training Loss: 0.1255\n",
      "Epoch 2750/10000, Validation Loss: 0.0912\n",
      "Epoch 2800/10000, Training Loss: 0.1249\n",
      "Epoch 2800/10000, Validation Loss: 0.0908\n",
      "Epoch 2850/10000, Training Loss: 0.1279\n",
      "Epoch 2850/10000, Validation Loss: 0.0966\n",
      "Epoch 2900/10000, Training Loss: 0.1244\n",
      "Epoch 2900/10000, Validation Loss: 0.0854\n",
      "Epoch 02948: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 2950/10000, Training Loss: 0.1313\n",
      "Epoch 2950/10000, Validation Loss: 0.1064\n",
      "Epoch 3000/10000, Training Loss: 0.1293\n",
      "Epoch 3000/10000, Validation Loss: 0.0880\n",
      "Epoch 3050/10000, Training Loss: 0.1283\n",
      "Epoch 3050/10000, Validation Loss: 0.0878\n",
      "Epoch 3100/10000, Training Loss: 0.1266\n",
      "Epoch 3100/10000, Validation Loss: 0.0866\n",
      "Epoch 3150/10000, Training Loss: 0.1271\n",
      "Epoch 3150/10000, Validation Loss: 0.0878\n",
      "Model saved with Validation Loss: 0.0804\n",
      "Model saved with Validation Loss: 0.0801\n",
      "Epoch 3200/10000, Training Loss: 0.1298\n",
      "Epoch 3200/10000, Validation Loss: 0.0813\n",
      "Model saved with Validation Loss: 0.0798\n",
      "Model saved with Validation Loss: 0.0797\n",
      "Epoch 3250/10000, Training Loss: 0.1265\n",
      "Epoch 3250/10000, Validation Loss: 0.0817\n",
      "Model saved with Validation Loss: 0.0793\n",
      "Epoch 3300/10000, Training Loss: 0.1257\n",
      "Epoch 3300/10000, Validation Loss: 0.0818\n",
      "Model saved with Validation Loss: 0.0784\n",
      "Epoch 3350/10000, Training Loss: 0.1249\n",
      "Epoch 3350/10000, Validation Loss: 0.0802\n",
      "Epoch 3400/10000, Training Loss: 0.1248\n",
      "Epoch 3400/10000, Validation Loss: 0.0830\n",
      "Model saved with Validation Loss: 0.0779\n",
      "Epoch 3450/10000, Training Loss: 0.1245\n",
      "Epoch 3450/10000, Validation Loss: 0.0824\n",
      "Epoch 3500/10000, Training Loss: 0.1258\n",
      "Epoch 3500/10000, Validation Loss: 0.0823\n",
      "Epoch 3550/10000, Training Loss: 0.1237\n",
      "Epoch 3550/10000, Validation Loss: 0.0828\n",
      "Epoch 3600/10000, Training Loss: 0.1269\n",
      "Epoch 3600/10000, Validation Loss: 0.0813\n",
      "Model saved with Validation Loss: 0.0778\n",
      "Epoch 3650/10000, Training Loss: 0.1234\n",
      "Epoch 3650/10000, Validation Loss: 0.0818\n",
      "Epoch 3700/10000, Training Loss: 0.1568\n",
      "Epoch 3700/10000, Validation Loss: 0.0848\n",
      "Epoch 3750/10000, Training Loss: 0.1259\n",
      "Epoch 3750/10000, Validation Loss: 0.0838\n",
      "Model saved with Validation Loss: 0.0757\n",
      "Epoch 3800/10000, Training Loss: 0.1237\n",
      "Epoch 3800/10000, Validation Loss: 0.0802\n",
      "Epoch 3850/10000, Training Loss: 0.1235\n",
      "Epoch 3850/10000, Validation Loss: 0.0814\n",
      "Epoch 3900/10000, Training Loss: 0.1247\n",
      "Epoch 3900/10000, Validation Loss: 0.0876\n",
      "Epoch 3950/10000, Training Loss: 0.1231\n",
      "Epoch 3950/10000, Validation Loss: 0.0787\n",
      "Epoch 4000/10000, Training Loss: 0.1232\n",
      "Epoch 4000/10000, Validation Loss: 0.0778\n",
      "Epoch 4050/10000, Training Loss: 0.1240\n",
      "Epoch 4050/10000, Validation Loss: 0.0831\n",
      "Epoch 4100/10000, Training Loss: 0.1226\n",
      "Epoch 4100/10000, Validation Loss: 0.0811\n",
      "Epoch 4150/10000, Training Loss: 0.1246\n",
      "Epoch 4150/10000, Validation Loss: 0.0822\n",
      "Epoch 4200/10000, Training Loss: 0.1242\n",
      "Epoch 4200/10000, Validation Loss: 0.0846\n",
      "Epoch 4250/10000, Training Loss: 0.1220\n",
      "Epoch 4250/10000, Validation Loss: 0.0816\n",
      "Epoch 04267: reducing learning rate of group 0 to 3.1623e-05.\n",
      "Epoch 4300/10000, Training Loss: 0.1220\n",
      "Epoch 4300/10000, Validation Loss: 0.0789\n",
      "Model saved with Validation Loss: 0.0756\n",
      "Epoch 4350/10000, Training Loss: 0.1212\n",
      "Epoch 4350/10000, Validation Loss: 0.0792\n",
      "Epoch 4400/10000, Training Loss: 0.1220\n",
      "Epoch 4400/10000, Validation Loss: 0.0791\n",
      "Epoch 4450/10000, Training Loss: 0.1241\n",
      "Epoch 4450/10000, Validation Loss: 0.0776\n",
      "Epoch 4500/10000, Training Loss: 0.1210\n",
      "Epoch 4500/10000, Validation Loss: 0.0796\n",
      "Epoch 4550/10000, Training Loss: 0.1221\n",
      "Epoch 4550/10000, Validation Loss: 0.0783\n",
      "Epoch 4600/10000, Training Loss: 0.1234\n",
      "Epoch 4600/10000, Validation Loss: 0.0782\n",
      "Epoch 4650/10000, Training Loss: 0.1257\n",
      "Epoch 4650/10000, Validation Loss: 0.0776\n",
      "Model saved with Validation Loss: 0.0750\n",
      "Epoch 4700/10000, Training Loss: 0.1226\n",
      "Epoch 4700/10000, Validation Loss: 0.0811\n",
      "Epoch 4750/10000, Training Loss: 0.1230\n",
      "Epoch 4750/10000, Validation Loss: 0.0784\n",
      "Epoch 4800/10000, Training Loss: 0.1220\n",
      "Epoch 4800/10000, Validation Loss: 0.0822\n",
      "Epoch 4850/10000, Training Loss: 0.1224\n",
      "Epoch 4850/10000, Validation Loss: 0.0786\n",
      "Epoch 4900/10000, Training Loss: 0.1236\n",
      "Epoch 4900/10000, Validation Loss: 0.0785\n",
      "Epoch 4950/10000, Training Loss: 0.1214\n",
      "Epoch 4950/10000, Validation Loss: 0.0820\n",
      "Model saved with Validation Loss: 0.0750\n",
      "Epoch 5000/10000, Training Loss: 0.1219\n",
      "Epoch 5000/10000, Validation Loss: 0.0818\n",
      "Epoch 5050/10000, Training Loss: 0.1225\n",
      "Epoch 5050/10000, Validation Loss: 0.0772\n",
      "Epoch 5100/10000, Training Loss: 0.1224\n",
      "Epoch 5100/10000, Validation Loss: 0.0814\n",
      "Epoch 5150/10000, Training Loss: 0.1228\n",
      "Epoch 5150/10000, Validation Loss: 0.0793\n",
      "Epoch 5200/10000, Training Loss: 0.1228\n",
      "Epoch 5200/10000, Validation Loss: 0.0796\n",
      "Epoch 5250/10000, Training Loss: 0.1225\n",
      "Epoch 5250/10000, Validation Loss: 0.0794\n",
      "Epoch 5300/10000, Training Loss: 0.1208\n",
      "Epoch 5300/10000, Validation Loss: 0.0808\n",
      "Epoch 5350/10000, Training Loss: 0.1221\n",
      "Epoch 5350/10000, Validation Loss: 0.0812\n",
      "Epoch 5400/10000, Training Loss: 0.1227\n",
      "Epoch 5400/10000, Validation Loss: 0.0786\n",
      "Epoch 5450/10000, Training Loss: 0.1225\n",
      "Epoch 5450/10000, Validation Loss: 0.0808\n",
      "Epoch 05485: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 5500/10000, Training Loss: 0.1216\n",
      "Epoch 5500/10000, Validation Loss: 0.0801\n",
      "Epoch 5550/10000, Training Loss: 0.1215\n",
      "Epoch 5550/10000, Validation Loss: 0.0771\n",
      "Epoch 5600/10000, Training Loss: 0.1223\n",
      "Epoch 5600/10000, Validation Loss: 0.0801\n",
      "Epoch 5650/10000, Training Loss: 0.1243\n",
      "Epoch 5650/10000, Validation Loss: 0.0812\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_seq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand/train_ann_no_intrinsics.py:295\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, num_epochs, save_path, early_stopping, scheduler, writer, log_seq)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_inputs, val_targets \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[0;32m--> 295\u001b[0m         val_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m         val_targets \u001b[38;5;241m=\u001b[39m val_targets\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    297\u001b[0m         val_outputs \u001b[38;5;241m=\u001b[39m model(val_inputs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    optimizer, \n",
    "    num_epochs=num_epochs, \n",
    "    save_path=save_path,\n",
    "    early_stopping=early_stopping,\n",
    "    scheduler=scheduler,\n",
    "    writer=writer,\n",
    "    log_seq=50)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_sandbox",
   "language": "python",
   "name": "pose_sandbox"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
