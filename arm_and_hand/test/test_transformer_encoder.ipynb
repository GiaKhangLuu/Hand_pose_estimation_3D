{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand\")\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utilities import fuse_landmarks_from_two_cameras\n",
    "from functools import partial\n",
    "\n",
    "import open3d as o3d\n",
    "from utilities import convert_to_shoulder_coord\n",
    "import time\n",
    "\n",
    "from dataloader_transformer_encoder import HandArmLandmarksDataset_Transformer_Encoder\n",
    "from transformer_encoder import TransformerEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giakhang/.local/lib/python3.8/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "input_dim = 322\n",
    "output_dim = 48 * 3  # 144\n",
    "num_encoder_heads = 7\n",
    "num_encoder_layers = 2\n",
    "dim_feedforward = 164\n",
    "dropout = 0.2\n",
    "model = TransformerEncoder(input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_heads=num_encoder_heads,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/giakhang/dev/pose_sandbox/data\"  \n",
    "SELECTED_DATE = \"*\"\n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"train\")))\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "\n",
    "sequence_length = 5\n",
    "train_body_distance_thres = 550\n",
    "train_leftarm_distance_thres = 550\n",
    "train_lefthand_distance_thres = 200\n",
    "\n",
    "train_dataset = HandArmLandmarksDataset_Transformer_Encoder(train_paths, \n",
    "    sequence_length,\n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    train_body_distance_thres, \n",
    "    train_leftarm_distance_thres, \n",
    "    train_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 144])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_dataloader:\n",
    "    inputs = inputs.permute(1, 0, 2)  # shape: [seq_length, B, input_dim]\n",
    "    outputs = model(inputs)\n",
    "    print(outputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embedding = model._generate_positional_encoding(5, 322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 322])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = positional_embedding.repeat(512, 1, 1)\n",
    "pos = pos.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 322])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((pos[:, 0, :] - pos[:, 1, :]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=322, out_features=322, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=322, out_features=164, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=164, out_features=322, bias=True)\n",
       "    (norm1): LayerNorm((322,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((322,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=322, out_features=322, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=322, out_features=164, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=164, out_features=322, bias=True)\n",
       "        (norm1): LayerNorm((322,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((322,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=322, out_features=144, bias=True)\n",
       "  (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "  (dropout_fc): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
