{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/giakhang/dev/pose_sandbox\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(os.curdir),\n",
    "                \"Hand_pose_estimation_3D/arm_and_hand\"))\n",
    "sys.path.append(os.path.join(os.path.abspath(os.curdir),\n",
    "                \"Hand_pose_estimation_3D\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from transformer_encoder import TransformerEncoder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from ann import ANN\n",
    "from dataloader_hand_only_ann import HandLandmarksDataset_ANN\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from csv_writer import columns_to_normalize, fusion_csv_columns_name\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from landmarks_scaler import LandmarksScaler\n",
    "from train_ann_no_intrinsics import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumb_landmarks = [\"left shoulder\", \"left hip\", \"right shoulder\", \"right hip\", \n",
    "    \"left elbow\", \"WRIST\", \n",
    "    \"THUMB_CMC\", \"INDEX_FINGER_MCP\", \"MIDDLE_FINGER_MCP\", \"RING_FINGER_MCP\", \"PINKY_MCP\",\n",
    "    \"THUMB_TIP\", \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_TIP\", \"RING_FINGER_TIP\", \"PINKY_TIP\"]\n",
    "num_hand_lmks = 21\n",
    "left_wrist_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = num_hand_lmks * 3 * 2 + (len(thumb_landmarks[left_wrist_idx:]) * 3)\n",
    "OUTPUT_DIM = num_hand_lmks * 3\n",
    "HIDDEN_DIM = num_hand_lmks * 3 \n",
    "NUM_HIDDEN_LAYERS = 4\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "model = ANN(input_dim=INPUT_DIM,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
    "            dropout_rate=DROPOUT_RATE)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ann\"\n",
    "DATETIME = \"{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "DATE = \"{}\".format(datetime.now().strftime(\"%Y%m%d\"))\n",
    "BASE_DIR = \"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand/runs/{}\".format(MODEL_NAME)\n",
    "SAVE_DIR = os.path.join(BASE_DIR, DATE, DATETIME)\n",
    "DATA_DIR = \"/home/giakhang/dev/pose_sandbox/data\"  \n",
    "writer = SummaryWriter(log_dir=SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_DATE = \"2024-*\"\n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"train\")))\n",
    "val_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"val\")))\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], \n",
    "                  [5, 10], [5, 22], [10, 14], \n",
    "                  [14, 18], [18, 22], [6, 7], \n",
    "                  [7, 8], [8, 9], [10, 11], \n",
    "                  [11, 12], [12, 13], [14, 15], \n",
    "                  [15, 16], [16, 17], [18, 19], \n",
    "                  [19, 20], [20, 21], [22, 23], \n",
    "                  [23, 24], [24, 25]]\n",
    "train_body_distance_thres = 550\n",
    "train_leftarm_distance_thres = 550\n",
    "train_lefthand_distance_thres = 200\n",
    "val_body_distance_thres=450\n",
    "val_leftarm_distance_thres=450\n",
    "val_lefthand_distance_thres=150\n",
    "\n",
    "arm_hand_fused_names = [\"left shoulder\", \"left elbow\", \"left hip\", \"right shoulder\",\n",
    "    \"right hip\", \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \n",
    "    \"THUMB_TIP\", \"INDEX_FINGER_MCP\", \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\",\n",
    "    \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_MCP\", \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\",\n",
    "    \"MIDDLE_FINGER_TIP\", \"RING_FINGER_MCP\", \"RING_FINGER_PIP\", \"RING_FINGER_DIP\",\n",
    "    \"RING_FINGER_TIP\", \"PINKY_MCP\", \"PINKY_PIP\", \"PINKY_DIP\", \"PINKY_TIP\", \"right elbow\",\n",
    "    \"RIGHT_WRIST\", \"RIGHT_THUMB_CMC\", \"RIGHT_THUMB_MCP\", \"RIGHT_THUMB_IP\", \"RIGHT_THUMB_TIP\",\n",
    "    \"RIGHT_INDEX_FINGER_MCP\", \"RIGHT_INDEX_FINGER_PIP\", \"RIGHT_INDEX_FINGER_DIP\",\n",
    "    \"RIGHT_INDEX_FINGER_TIP\", \"RIGHT_MIDDLE_FINGER_MCP\", \"RIGHT_MIDDLE_FINGER_PIP\",\n",
    "    \"RIGHT_MIDDLE_FINGER_DIP\", \"RIGHT_MIDDLE_FINGER_TIP\", \"RIGHT_RING_FINGER_MCP\",\n",
    "    \"RIGHT_RING_FINGER_PIP\", \"RIGHT_RING_FINGER_DIP\", \"RIGHT_RING_FINGER_TIP\",\n",
    "    \"RIGHT_PINKY_MCP\", \"RIGHT_PINKY_PIP\", \"RIGHT_PINKY_DIP\", \"RIGHT_PINKY_TIP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand/runs/ann/20241021/20241021-1547/input_scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the true dataset to get the scaler then pass the scaler to the true and fake dataset\n",
    "minmax_scaler = MinMaxScaler()\n",
    "train_dataset = HandLandmarksDataset_ANN(train_paths, \n",
    "    arm_hand_fused_names,\n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    train_body_distance_thres, \n",
    "    train_leftarm_distance_thres, \n",
    "    train_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_fused_thumb_as_input=True)\n",
    "minmax_scaler.fit_transform(train_dataset._inputs)\n",
    "scaler_save_path = os.path.join(SAVE_DIR, \"input_scaler.pkl\")\n",
    "joblib.dump(minmax_scaler, scaler_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = LandmarksScaler(scaler_path=scaler_save_path)\n",
    "train_dataset = HandLandmarksDataset_ANN(train_paths, \n",
    "    arm_hand_fused_names,\n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    train_body_distance_thres, \n",
    "    train_leftarm_distance_thres, \n",
    "    train_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    scaler=scaler,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_fused_thumb_as_input=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataset = HandLandmarksDataset_ANN(val_paths,\n",
    "    arm_hand_fused_names,\n",
    "    body_lines,\n",
    "    lefthand_lines,\n",
    "    val_body_distance_thres,\n",
    "    val_leftarm_distance_thres,\n",
    "    val_lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True,\n",
    "    scaler=scaler,\n",
    "    cvt_normalized_xy_to_XY=True,\n",
    "    use_fused_thumb_as_input=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13400, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giakhang/py_venv/mmpose/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 50000\n",
    "current_time = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "save_path = os.path.join(SAVE_DIR, \"{}_{}_layers_best.pth\".format(MODEL_NAME, NUM_HIDDEN_LAYERS))\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', \n",
    "    factor=math.sqrt(0.1), patience=1000, verbose=True, min_lr=1e-8)\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with Validation Loss: 1121165.1375\n",
      "Model saved with Validation Loss: 1120622.6875\n",
      "Model saved with Validation Loss: 1119718.2375\n",
      "Model saved with Validation Loss: 1116112.8250\n",
      "Model saved with Validation Loss: 1113795.2625\n",
      "Model saved with Validation Loss: 1113129.2312\n",
      "Model saved with Validation Loss: 1110685.5500\n",
      "Model saved with Validation Loss: 1109473.6250\n",
      "Model saved with Validation Loss: 1106840.2312\n",
      "Model saved with Validation Loss: 1101765.1875\n",
      "Model saved with Validation Loss: 1099762.5625\n",
      "Model saved with Validation Loss: 1095659.6500\n",
      "Model saved with Validation Loss: 1094380.3250\n",
      "Model saved with Validation Loss: 1081043.8687\n",
      "Model saved with Validation Loss: 1079421.0250\n",
      "Model saved with Validation Loss: 1078852.1625\n",
      "Epoch 50/50000, Training Loss: 1077826.6804\n",
      "Epoch 50/50000, Validation Loss: 1073377.1625\n",
      "Model saved with Validation Loss: 1073377.1625\n",
      "Model saved with Validation Loss: 1069076.1187\n",
      "Model saved with Validation Loss: 1067384.0625\n",
      "Model saved with Validation Loss: 1066499.9688\n",
      "Model saved with Validation Loss: 1061723.1625\n",
      "Model saved with Validation Loss: 1060526.0000\n",
      "Model saved with Validation Loss: 1051995.6875\n",
      "Model saved with Validation Loss: 1051258.8562\n",
      "Model saved with Validation Loss: 1047044.6500\n",
      "Model saved with Validation Loss: 1046311.4000\n",
      "Model saved with Validation Loss: 1044406.6188\n",
      "Model saved with Validation Loss: 1043402.9500\n",
      "Model saved with Validation Loss: 1039663.3562\n",
      "Model saved with Validation Loss: 1038078.1500\n",
      "Model saved with Validation Loss: 1037394.4313\n",
      "Model saved with Validation Loss: 1027309.8063\n",
      "Model saved with Validation Loss: 1026618.5250\n",
      "Model saved with Validation Loss: 1018303.5437\n",
      "Epoch 100/50000, Training Loss: 1015035.2394\n",
      "Epoch 100/50000, Validation Loss: 1026946.4563\n",
      "Model saved with Validation Loss: 1013998.1000\n",
      "Model saved with Validation Loss: 1013604.8500\n",
      "Model saved with Validation Loss: 1013408.5312\n",
      "Model saved with Validation Loss: 1009093.5375\n",
      "Model saved with Validation Loss: 1004930.6937\n",
      "Model saved with Validation Loss: 1004181.7625\n",
      "Model saved with Validation Loss: 1004014.6500\n",
      "Model saved with Validation Loss: 1002991.6687\n",
      "Model saved with Validation Loss: 996095.6625\n",
      "Model saved with Validation Loss: 989907.8562\n",
      "Model saved with Validation Loss: 987670.7500\n",
      "Model saved with Validation Loss: 982062.0813\n",
      "Model saved with Validation Loss: 979413.1250\n",
      "Model saved with Validation Loss: 977882.1062\n",
      "Model saved with Validation Loss: 973921.1250\n",
      "Epoch 150/50000, Training Loss: 958373.8361\n",
      "Epoch 150/50000, Validation Loss: 983917.4313\n",
      "Model saved with Validation Loss: 971732.3562\n",
      "Model saved with Validation Loss: 966306.4000\n",
      "Model saved with Validation Loss: 965522.6062\n",
      "Model saved with Validation Loss: 963495.9187\n",
      "Model saved with Validation Loss: 957171.3063\n",
      "Model saved with Validation Loss: 954120.2562\n",
      "Model saved with Validation Loss: 950401.3500\n",
      "Model saved with Validation Loss: 941464.8187\n",
      "Model saved with Validation Loss: 935840.2625\n",
      "Model saved with Validation Loss: 929743.9500\n",
      "Model saved with Validation Loss: 923988.8125\n",
      "Model saved with Validation Loss: 919458.2562\n",
      "Epoch 200/50000, Training Loss: 908484.8255\n",
      "Epoch 200/50000, Validation Loss: 925971.3438\n",
      "Model saved with Validation Loss: 910643.3000\n",
      "Model saved with Validation Loss: 910344.3125\n",
      "Model saved with Validation Loss: 900892.6750\n",
      "Model saved with Validation Loss: 896472.9938\n",
      "Model saved with Validation Loss: 890069.0125\n",
      "Model saved with Validation Loss: 886998.1875\n",
      "Model saved with Validation Loss: 876491.5312\n",
      "Model saved with Validation Loss: 875423.3438\n",
      "Model saved with Validation Loss: 862635.6875\n",
      "Model saved with Validation Loss: 860633.4625\n",
      "Epoch 250/50000, Training Loss: 862576.3620\n",
      "Epoch 250/50000, Validation Loss: 881339.0437\n",
      "Model saved with Validation Loss: 854177.9250\n",
      "Model saved with Validation Loss: 845609.4187\n",
      "Model saved with Validation Loss: 839944.3187\n",
      "Model saved with Validation Loss: 837411.9500\n",
      "Model saved with Validation Loss: 831919.8750\n",
      "Model saved with Validation Loss: 830603.3187\n",
      "Model saved with Validation Loss: 825299.2500\n",
      "Model saved with Validation Loss: 817421.2250\n",
      "Model saved with Validation Loss: 805482.8562\n",
      "Epoch 300/50000, Training Loss: 819242.5601\n",
      "Epoch 300/50000, Validation Loss: 822231.6750\n",
      "Model saved with Validation Loss: 796742.7562\n",
      "Model saved with Validation Loss: 791068.2312\n",
      "Model saved with Validation Loss: 789457.2250\n",
      "Model saved with Validation Loss: 785467.7375\n",
      "Model saved with Validation Loss: 779655.9000\n",
      "Model saved with Validation Loss: 777990.5938\n",
      "Model saved with Validation Loss: 774428.3500\n",
      "Model saved with Validation Loss: 771628.1438\n",
      "Model saved with Validation Loss: 761746.8063\n",
      "Epoch 350/50000, Training Loss: 777780.0979\n",
      "Epoch 350/50000, Validation Loss: 768100.2063\n",
      "Model saved with Validation Loss: 754146.7375\n",
      "Model saved with Validation Loss: 751115.2875\n",
      "Model saved with Validation Loss: 747919.0563\n",
      "Model saved with Validation Loss: 742310.0500\n",
      "Model saved with Validation Loss: 734780.2937\n",
      "Model saved with Validation Loss: 732593.9437\n",
      "Model saved with Validation Loss: 727347.3000\n",
      "Epoch 400/50000, Training Loss: 737186.5318\n",
      "Epoch 400/50000, Validation Loss: 723188.2063\n",
      "Model saved with Validation Loss: 723188.2063\n",
      "Model saved with Validation Loss: 719104.5563\n",
      "Model saved with Validation Loss: 711363.2438\n",
      "Model saved with Validation Loss: 710460.6625\n",
      "Model saved with Validation Loss: 704283.8375\n",
      "Model saved with Validation Loss: 704038.5312\n",
      "Model saved with Validation Loss: 695079.4500\n",
      "Model saved with Validation Loss: 691208.7125\n",
      "Model saved with Validation Loss: 690274.9625\n",
      "Model saved with Validation Loss: 681064.6438\n",
      "Model saved with Validation Loss: 680842.5375\n",
      "Model saved with Validation Loss: 679995.6312\n",
      "Epoch 450/50000, Training Loss: 696768.4493\n",
      "Epoch 450/50000, Validation Loss: 696877.8938\n",
      "Model saved with Validation Loss: 669699.5437\n",
      "Model saved with Validation Loss: 666060.4125\n",
      "Model saved with Validation Loss: 657062.0500\n",
      "Model saved with Validation Loss: 656756.7750\n",
      "Model saved with Validation Loss: 654777.9750\n",
      "Model saved with Validation Loss: 653037.6438\n",
      "Epoch 500/50000, Training Loss: 659008.2170\n",
      "Epoch 500/50000, Validation Loss: 657565.3875\n",
      "Model saved with Validation Loss: 632327.9875\n",
      "Model saved with Validation Loss: 627868.8000\n",
      "Model saved with Validation Loss: 623498.9563\n",
      "Model saved with Validation Loss: 623334.6062\n",
      "Model saved with Validation Loss: 615778.8875\n",
      "Model saved with Validation Loss: 613899.9625\n",
      "Model saved with Validation Loss: 611768.9500\n",
      "Epoch 550/50000, Training Loss: 621657.9552\n",
      "Epoch 550/50000, Validation Loss: 638989.4062\n",
      "Model saved with Validation Loss: 607628.9563\n",
      "Model saved with Validation Loss: 597333.5188\n",
      "Model saved with Validation Loss: 596044.0938\n",
      "Model saved with Validation Loss: 591919.2562\n",
      "Model saved with Validation Loss: 585774.9375\n",
      "Model saved with Validation Loss: 583415.6062\n",
      "Model saved with Validation Loss: 583092.1375\n",
      "Model saved with Validation Loss: 582323.7063\n",
      "Model saved with Validation Loss: 581037.3875\n",
      "Epoch 600/50000, Training Loss: 584303.8479\n",
      "Epoch 600/50000, Validation Loss: 584177.6438\n",
      "Model saved with Validation Loss: 573045.0312\n",
      "Model saved with Validation Loss: 570505.5312\n",
      "Model saved with Validation Loss: 569170.9000\n",
      "Model saved with Validation Loss: 566528.2750\n",
      "Model saved with Validation Loss: 563448.2438\n",
      "Model saved with Validation Loss: 561765.3063\n",
      "Model saved with Validation Loss: 552876.7562\n",
      "Model saved with Validation Loss: 542789.3688\n",
      "Model saved with Validation Loss: 539854.2937\n",
      "Epoch 650/50000, Training Loss: 548861.0295\n",
      "Epoch 650/50000, Validation Loss: 552310.6438\n",
      "Model saved with Validation Loss: 539300.8438\n",
      "Model saved with Validation Loss: 538397.5938\n",
      "Model saved with Validation Loss: 532397.7375\n",
      "Model saved with Validation Loss: 529009.0188\n",
      "Model saved with Validation Loss: 522140.3688\n",
      "Model saved with Validation Loss: 516850.8312\n",
      "Model saved with Validation Loss: 510382.0812\n",
      "Model saved with Validation Loss: 509243.5281\n",
      "Model saved with Validation Loss: 506644.6094\n",
      "Model saved with Validation Loss: 505811.8875\n",
      "Epoch 700/50000, Training Loss: 515516.8945\n",
      "Epoch 700/50000, Validation Loss: 502385.5281\n",
      "Model saved with Validation Loss: 502385.5281\n",
      "Model saved with Validation Loss: 491696.6781\n",
      "Model saved with Validation Loss: 491533.4062\n",
      "Model saved with Validation Loss: 489554.4844\n",
      "Model saved with Validation Loss: 485941.8625\n",
      "Model saved with Validation Loss: 483124.7969\n",
      "Epoch 750/50000, Training Loss: 480837.2972\n",
      "Epoch 750/50000, Validation Loss: 469537.0687\n",
      "Model saved with Validation Loss: 469537.0687\n",
      "Model saved with Validation Loss: 466669.6406\n",
      "Model saved with Validation Loss: 463581.5187\n",
      "Model saved with Validation Loss: 463087.8875\n",
      "Model saved with Validation Loss: 459709.4000\n",
      "Model saved with Validation Loss: 451063.2781\n",
      "Model saved with Validation Loss: 447907.2750\n",
      "Model saved with Validation Loss: 446098.4750\n",
      "Model saved with Validation Loss: 438233.8063\n",
      "Epoch 800/50000, Training Loss: 449335.1969\n",
      "Epoch 800/50000, Validation Loss: 450083.3781\n",
      "Model saved with Validation Loss: 423997.6063\n",
      "Model saved with Validation Loss: 417643.8750\n",
      "Model saved with Validation Loss: 408489.8719\n",
      "Model saved with Validation Loss: 407613.4688\n",
      "Epoch 850/50000, Training Loss: 419454.1268\n",
      "Epoch 850/50000, Validation Loss: 427524.5281\n",
      "Model saved with Validation Loss: 397278.7375\n",
      "Model saved with Validation Loss: 393611.2719\n",
      "Model saved with Validation Loss: 392969.3469\n",
      "Model saved with Validation Loss: 390813.3656\n",
      "Model saved with Validation Loss: 382558.1562\n",
      "Model saved with Validation Loss: 378458.6594\n",
      "Epoch 900/50000, Training Loss: 388324.8827\n",
      "Epoch 900/50000, Validation Loss: 391615.3063\n",
      "Model saved with Validation Loss: 372808.8812\n",
      "Model saved with Validation Loss: 371056.6781\n",
      "Model saved with Validation Loss: 367751.4594\n",
      "Model saved with Validation Loss: 364596.0969\n",
      "Model saved with Validation Loss: 363699.0750\n",
      "Model saved with Validation Loss: 359127.5812\n",
      "Model saved with Validation Loss: 354729.9906\n",
      "Model saved with Validation Loss: 341076.2781\n",
      "Epoch 950/50000, Training Loss: 359270.8302\n",
      "Epoch 950/50000, Validation Loss: 354210.8812\n",
      "Model saved with Validation Loss: 339049.3875\n",
      "Model saved with Validation Loss: 338819.2625\n",
      "Model saved with Validation Loss: 338512.3719\n",
      "Model saved with Validation Loss: 335106.5938\n",
      "Model saved with Validation Loss: 332855.2281\n",
      "Model saved with Validation Loss: 327606.7812\n",
      "Model saved with Validation Loss: 326866.7156\n",
      "Model saved with Validation Loss: 325512.6094\n",
      "Epoch 1000/50000, Training Loss: 333114.2488\n",
      "Epoch 1000/50000, Validation Loss: 327615.4594\n",
      "Model saved with Validation Loss: 323117.0531\n",
      "Model saved with Validation Loss: 317829.2906\n",
      "Model saved with Validation Loss: 313793.4906\n",
      "Model saved with Validation Loss: 309587.5375\n",
      "Model saved with Validation Loss: 309132.8219\n",
      "Model saved with Validation Loss: 307880.9062\n",
      "Model saved with Validation Loss: 298092.4875\n",
      "Model saved with Validation Loss: 296945.9156\n",
      "Epoch 1050/50000, Training Loss: 308516.0330\n",
      "Epoch 1050/50000, Validation Loss: 302708.0281\n",
      "Model saved with Validation Loss: 286153.3281\n",
      "Model saved with Validation Loss: 277672.1594\n",
      "Model saved with Validation Loss: 273159.8438\n",
      "Epoch 1100/50000, Training Loss: 281958.8479\n",
      "Epoch 1100/50000, Validation Loss: 294971.7375\n",
      "Model saved with Validation Loss: 261094.2875\n",
      "Model saved with Validation Loss: 258467.1484\n",
      "Model saved with Validation Loss: 256442.9078\n",
      "Model saved with Validation Loss: 256091.6641\n",
      "Model saved with Validation Loss: 254522.1344\n",
      "Model saved with Validation Loss: 248876.7875\n",
      "Epoch 1150/50000, Training Loss: 258138.1683\n",
      "Epoch 1150/50000, Validation Loss: 248377.6500\n",
      "Model saved with Validation Loss: 248377.6500\n",
      "Model saved with Validation Loss: 247300.7703\n",
      "Model saved with Validation Loss: 238323.4656\n",
      "Model saved with Validation Loss: 236531.3141\n",
      "Model saved with Validation Loss: 232901.6016\n",
      "Model saved with Validation Loss: 230947.8859\n",
      "Model saved with Validation Loss: 229091.0547\n",
      "Epoch 1200/50000, Training Loss: 235606.2880\n",
      "Epoch 1200/50000, Validation Loss: 228930.0734\n",
      "Model saved with Validation Loss: 228930.0734\n",
      "Model saved with Validation Loss: 218110.5250\n",
      "Model saved with Validation Loss: 212721.2172\n",
      "Model saved with Validation Loss: 205364.0203\n",
      "Epoch 1250/50000, Training Loss: 215226.9136\n",
      "Epoch 1250/50000, Validation Loss: 207500.3828\n",
      "Model saved with Validation Loss: 202950.9531\n",
      "Model saved with Validation Loss: 201117.4750\n",
      "Model saved with Validation Loss: 198485.0859\n",
      "Model saved with Validation Loss: 194451.2984\n",
      "Model saved with Validation Loss: 191375.4078\n",
      "Model saved with Validation Loss: 185017.7578\n",
      "Epoch 1300/50000, Training Loss: 194577.3325\n",
      "Epoch 1300/50000, Validation Loss: 195003.6281\n",
      "Model saved with Validation Loss: 178883.1891\n",
      "Model saved with Validation Loss: 169210.2891\n",
      "Model saved with Validation Loss: 168186.3250\n",
      "Model saved with Validation Loss: 167704.1359\n",
      "Epoch 1350/50000, Training Loss: 176249.8361\n",
      "Epoch 1350/50000, Validation Loss: 164828.9703\n",
      "Model saved with Validation Loss: 164828.9703\n",
      "Model saved with Validation Loss: 163145.5750\n",
      "Model saved with Validation Loss: 157320.4062\n",
      "Model saved with Validation Loss: 157027.9219\n",
      "Model saved with Validation Loss: 155192.3156\n",
      "Model saved with Validation Loss: 152501.9828\n",
      "Model saved with Validation Loss: 143407.1719\n",
      "Epoch 1400/50000, Training Loss: 158006.3395\n",
      "Epoch 1400/50000, Validation Loss: 157276.1719\n",
      "Model saved with Validation Loss: 141591.9875\n",
      "Model saved with Validation Loss: 141429.0609\n",
      "Model saved with Validation Loss: 141312.5562\n",
      "Model saved with Validation Loss: 140424.3438\n",
      "Model saved with Validation Loss: 136542.1547\n",
      "Model saved with Validation Loss: 135250.2969\n",
      "Model saved with Validation Loss: 133387.7359\n",
      "Model saved with Validation Loss: 130661.6164\n",
      "Epoch 1450/50000, Training Loss: 140919.5740\n",
      "Epoch 1450/50000, Validation Loss: 126346.8133\n",
      "Model saved with Validation Loss: 126346.8133\n",
      "Model saved with Validation Loss: 123962.4461\n",
      "Model saved with Validation Loss: 121512.0305\n",
      "Model saved with Validation Loss: 121189.7320\n",
      "Model saved with Validation Loss: 119720.3727\n",
      "Model saved with Validation Loss: 115925.5797\n",
      "Model saved with Validation Loss: 110873.9398\n",
      "Epoch 1500/50000, Training Loss: 124371.9665\n",
      "Epoch 1500/50000, Validation Loss: 126707.4875\n",
      "Model saved with Validation Loss: 110529.6438\n",
      "Model saved with Validation Loss: 108914.6828\n",
      "Model saved with Validation Loss: 105383.6148\n",
      "Model saved with Validation Loss: 104411.4742\n",
      "Model saved with Validation Loss: 104101.6047\n",
      "Model saved with Validation Loss: 103678.8781\n",
      "Model saved with Validation Loss: 100425.9312\n",
      "Epoch 1550/50000, Training Loss: 110734.2792\n",
      "Epoch 1550/50000, Validation Loss: 105855.4203\n",
      "Model saved with Validation Loss: 99623.7102\n",
      "Model saved with Validation Loss: 92193.3953\n",
      "Model saved with Validation Loss: 92068.8016\n",
      "Model saved with Validation Loss: 91738.4109\n",
      "Model saved with Validation Loss: 90479.8062\n",
      "Model saved with Validation Loss: 88487.2680\n",
      "Model saved with Validation Loss: 85116.6961\n",
      "Model saved with Validation Loss: 84932.6211\n",
      "Epoch 1600/50000, Training Loss: 96507.9758\n",
      "Epoch 1600/50000, Validation Loss: 92396.7805\n",
      "Model saved with Validation Loss: 84636.4531\n",
      "Model saved with Validation Loss: 83357.0883\n",
      "Model saved with Validation Loss: 80577.3773\n",
      "Model saved with Validation Loss: 79424.9797\n",
      "Model saved with Validation Loss: 78220.9734\n",
      "Model saved with Validation Loss: 78085.2188\n",
      "Model saved with Validation Loss: 72922.6922\n",
      "Epoch 1650/50000, Training Loss: 84096.6035\n",
      "Epoch 1650/50000, Validation Loss: 81855.1672\n",
      "Model saved with Validation Loss: 72727.9070\n",
      "Model saved with Validation Loss: 70359.3945\n",
      "Model saved with Validation Loss: 69582.2336\n",
      "Model saved with Validation Loss: 67788.0531\n",
      "Model saved with Validation Loss: 66862.1359\n",
      "Model saved with Validation Loss: 64294.0109\n",
      "Model saved with Validation Loss: 63764.1289\n",
      "Model saved with Validation Loss: 63107.8098\n",
      "Epoch 1700/50000, Training Loss: 71407.9632\n",
      "Epoch 1700/50000, Validation Loss: 71407.4547\n",
      "Model saved with Validation Loss: 60626.5590\n",
      "Model saved with Validation Loss: 60387.5625\n",
      "Model saved with Validation Loss: 59853.1078\n",
      "Model saved with Validation Loss: 55371.6496\n",
      "Model saved with Validation Loss: 52903.4293\n",
      "Epoch 1750/50000, Training Loss: 61356.6946\n",
      "Epoch 1750/50000, Validation Loss: 53787.7730\n",
      "Model saved with Validation Loss: 50419.2086\n",
      "Model saved with Validation Loss: 48780.7258\n",
      "Model saved with Validation Loss: 47797.4145\n",
      "Model saved with Validation Loss: 47309.4852\n",
      "Model saved with Validation Loss: 44687.4891\n",
      "Model saved with Validation Loss: 43814.9754\n",
      "Model saved with Validation Loss: 42934.0316\n",
      "Model saved with Validation Loss: 42280.3875\n",
      "Model saved with Validation Loss: 41697.5074\n",
      "Epoch 1800/50000, Training Loss: 52541.8536\n",
      "Epoch 1800/50000, Validation Loss: 42031.6941\n",
      "Model saved with Validation Loss: 39375.3113\n",
      "Model saved with Validation Loss: 38916.9969\n",
      "Model saved with Validation Loss: 38004.5082\n",
      "Model saved with Validation Loss: 34770.4879\n",
      "Model saved with Validation Loss: 34416.8520\n",
      "Epoch 1850/50000, Training Loss: 44381.9982\n",
      "Epoch 1850/50000, Validation Loss: 40722.0805\n",
      "Model saved with Validation Loss: 34024.2367\n",
      "Model saved with Validation Loss: 32208.4645\n",
      "Model saved with Validation Loss: 30545.8814\n",
      "Model saved with Validation Loss: 29744.8732\n",
      "Model saved with Validation Loss: 28791.3074\n",
      "Epoch 1900/50000, Training Loss: 36970.5794\n",
      "Epoch 1900/50000, Validation Loss: 27179.2396\n",
      "Model saved with Validation Loss: 27179.2396\n",
      "Model saved with Validation Loss: 26023.9697\n",
      "Model saved with Validation Loss: 25396.6084\n",
      "Model saved with Validation Loss: 25125.9852\n",
      "Model saved with Validation Loss: 24820.6779\n",
      "Model saved with Validation Loss: 24100.7787\n",
      "Model saved with Validation Loss: 22789.7127\n",
      "Model saved with Validation Loss: 21045.9125\n",
      "Model saved with Validation Loss: 19836.9238\n",
      "Epoch 1950/50000, Training Loss: 30782.8579\n",
      "Epoch 1950/50000, Validation Loss: 24239.2412\n",
      "Model saved with Validation Loss: 19335.9803\n",
      "Model saved with Validation Loss: 17902.5064\n",
      "Model saved with Validation Loss: 16805.7373\n",
      "Model saved with Validation Loss: 16538.5636\n",
      "Epoch 2000/50000, Training Loss: 25849.8981\n",
      "Epoch 2000/50000, Validation Loss: 17589.6549\n",
      "Model saved with Validation Loss: 15920.3698\n",
      "Model saved with Validation Loss: 15408.0150\n",
      "Model saved with Validation Loss: 14192.0195\n",
      "Model saved with Validation Loss: 12979.0158\n",
      "Model saved with Validation Loss: 12279.7037\n",
      "Model saved with Validation Loss: 12021.8435\n",
      "Model saved with Validation Loss: 11717.4834\n",
      "Epoch 2050/50000, Training Loss: 21740.1771\n",
      "Epoch 2050/50000, Validation Loss: 13273.2081\n",
      "Model saved with Validation Loss: 11696.4563\n",
      "Model saved with Validation Loss: 9734.6967\n",
      "Model saved with Validation Loss: 8949.3706\n",
      "Model saved with Validation Loss: 8688.3590\n",
      "Model saved with Validation Loss: 7256.1492\n",
      "Epoch 2100/50000, Training Loss: 18355.3726\n",
      "Epoch 2100/50000, Validation Loss: 10923.7538\n",
      "Model saved with Validation Loss: 6947.7578\n",
      "Model saved with Validation Loss: 6889.4127\n",
      "Model saved with Validation Loss: 6149.7993\n",
      "Model saved with Validation Loss: 5184.2996\n",
      "Epoch 2150/50000, Training Loss: 16382.5085\n",
      "Epoch 2150/50000, Validation Loss: 6477.3393\n",
      "Model saved with Validation Loss: 4592.1253\n",
      "Model saved with Validation Loss: 4393.5096\n",
      "Model saved with Validation Loss: 3875.0855\n",
      "Epoch 2200/50000, Training Loss: 14560.3327\n",
      "Epoch 2200/50000, Validation Loss: 5055.6115\n",
      "Model saved with Validation Loss: 3615.4597\n",
      "Model saved with Validation Loss: 3609.9051\n",
      "Model saved with Validation Loss: 3317.5015\n",
      "Model saved with Validation Loss: 2725.5918\n",
      "Epoch 2250/50000, Training Loss: 13428.2830\n",
      "Epoch 2250/50000, Validation Loss: 4267.3656\n",
      "Model saved with Validation Loss: 2562.3919\n",
      "Model saved with Validation Loss: 2478.0772\n",
      "Model saved with Validation Loss: 2312.7174\n",
      "Epoch 2300/50000, Training Loss: 12642.9270\n",
      "Epoch 2300/50000, Validation Loss: 3152.5255\n",
      "Model saved with Validation Loss: 1901.9248\n",
      "Model saved with Validation Loss: 1466.3797\n",
      "Epoch 2350/50000, Training Loss: 12028.6640\n",
      "Epoch 2350/50000, Validation Loss: 1765.7093\n",
      "Model saved with Validation Loss: 1462.2399\n",
      "Epoch 2400/50000, Training Loss: 11823.0537\n",
      "Epoch 2400/50000, Validation Loss: 2285.0841\n",
      "Model saved with Validation Loss: 1341.1508\n",
      "Epoch 2450/50000, Training Loss: 11133.7789\n",
      "Epoch 2450/50000, Validation Loss: 2351.1776\n",
      "Epoch 2500/50000, Training Loss: 10514.7215\n",
      "Epoch 2500/50000, Validation Loss: 1575.9258\n",
      "Model saved with Validation Loss: 1175.8562\n",
      "Epoch 2550/50000, Training Loss: 10459.2961\n",
      "Epoch 2550/50000, Validation Loss: 2297.3041\n",
      "Epoch 2600/50000, Training Loss: 10363.7542\n",
      "Epoch 2600/50000, Validation Loss: 1940.4188\n",
      "Epoch 2650/50000, Training Loss: 10065.7499\n",
      "Epoch 2650/50000, Validation Loss: 2265.0562\n",
      "Model saved with Validation Loss: 1137.0961\n",
      "Epoch 2700/50000, Training Loss: 9891.2237\n",
      "Epoch 2700/50000, Validation Loss: 1926.0411\n",
      "Epoch 2750/50000, Training Loss: 9772.5576\n",
      "Epoch 2750/50000, Validation Loss: 1894.4336\n",
      "Epoch 2800/50000, Training Loss: 9491.0487\n",
      "Epoch 2800/50000, Validation Loss: 1880.4317\n",
      "Model saved with Validation Loss: 1107.9983\n",
      "Model saved with Validation Loss: 1077.9566\n",
      "Epoch 2850/50000, Training Loss: 9341.2304\n",
      "Epoch 2850/50000, Validation Loss: 1730.0382\n",
      "Epoch 2900/50000, Training Loss: 9110.2963\n",
      "Epoch 2900/50000, Validation Loss: 1594.2459\n",
      "Epoch 2950/50000, Training Loss: 8938.4132\n",
      "Epoch 2950/50000, Validation Loss: 1907.1418\n",
      "Epoch 3000/50000, Training Loss: 8820.9346\n",
      "Epoch 3000/50000, Validation Loss: 2062.2022\n",
      "Epoch 3050/50000, Training Loss: 8791.1611\n",
      "Epoch 3050/50000, Validation Loss: 1667.4865\n",
      "Epoch 3100/50000, Training Loss: 8412.2023\n",
      "Epoch 3100/50000, Validation Loss: 1520.8986\n",
      "Epoch 3150/50000, Training Loss: 8561.5845\n",
      "Epoch 3150/50000, Validation Loss: 2002.7229\n",
      "Epoch 3200/50000, Training Loss: 8324.4412\n",
      "Epoch 3200/50000, Validation Loss: 1803.3599\n",
      "Epoch 3250/50000, Training Loss: 8198.9199\n",
      "Epoch 3250/50000, Validation Loss: 1667.2590\n",
      "Model saved with Validation Loss: 1047.3096\n",
      "Epoch 3300/50000, Training Loss: 8095.3593\n",
      "Epoch 3300/50000, Validation Loss: 1804.0680\n",
      "Epoch 3350/50000, Training Loss: 8056.3293\n",
      "Epoch 3350/50000, Validation Loss: 1497.7641\n",
      "Epoch 3400/50000, Training Loss: 7714.7616\n",
      "Epoch 3400/50000, Validation Loss: 1756.8845\n",
      "Epoch 3450/50000, Training Loss: 7872.8722\n",
      "Epoch 3450/50000, Validation Loss: 2617.9250\n",
      "Epoch 3500/50000, Training Loss: 7680.3401\n",
      "Epoch 3500/50000, Validation Loss: 1056.9670\n",
      "Model saved with Validation Loss: 1021.1161\n",
      "Epoch 3550/50000, Training Loss: 7756.4875\n",
      "Epoch 3550/50000, Validation Loss: 2031.9890\n",
      "Epoch 3600/50000, Training Loss: 7305.0236\n",
      "Epoch 3600/50000, Validation Loss: 1338.4294\n",
      "Model saved with Validation Loss: 1003.6394\n",
      "Epoch 3650/50000, Training Loss: 7498.0456\n",
      "Epoch 3650/50000, Validation Loss: 1044.6008\n",
      "Model saved with Validation Loss: 975.8593\n",
      "Epoch 3700/50000, Training Loss: 7176.3679\n",
      "Epoch 3700/50000, Validation Loss: 1405.7411\n",
      "Epoch 3750/50000, Training Loss: 7312.8143\n",
      "Epoch 3750/50000, Validation Loss: 1401.4299\n",
      "Epoch 3800/50000, Training Loss: 6793.2556\n",
      "Epoch 3800/50000, Validation Loss: 1861.8159\n",
      "Epoch 3850/50000, Training Loss: 7033.4606\n",
      "Epoch 3850/50000, Validation Loss: 1496.0616\n",
      "Model saved with Validation Loss: 945.0205\n",
      "Epoch 3900/50000, Training Loss: 6878.2357\n",
      "Epoch 3900/50000, Validation Loss: 1194.0919\n",
      "Epoch 3950/50000, Training Loss: 6648.1909\n",
      "Epoch 3950/50000, Validation Loss: 1744.7328\n",
      "Model saved with Validation Loss: 909.7553\n",
      "Model saved with Validation Loss: 857.9075\n",
      "Epoch 4000/50000, Training Loss: 6666.4252\n",
      "Epoch 4000/50000, Validation Loss: 1694.4880\n",
      "Epoch 4050/50000, Training Loss: 6704.7055\n",
      "Epoch 4050/50000, Validation Loss: 1765.6645\n",
      "Epoch 4100/50000, Training Loss: 6665.7795\n",
      "Epoch 4100/50000, Validation Loss: 1944.5721\n",
      "Epoch 4150/50000, Training Loss: 6563.0144\n",
      "Epoch 4150/50000, Validation Loss: 1395.7206\n",
      "Epoch 4200/50000, Training Loss: 6598.2965\n",
      "Epoch 4200/50000, Validation Loss: 1826.0976\n",
      "Epoch 4250/50000, Training Loss: 6644.2126\n",
      "Epoch 4250/50000, Validation Loss: 1370.4835\n",
      "Epoch 4300/50000, Training Loss: 6735.5397\n",
      "Epoch 4300/50000, Validation Loss: 1624.1163\n",
      "Epoch 4350/50000, Training Loss: 6573.2424\n",
      "Epoch 4350/50000, Validation Loss: 1724.3379\n",
      "Model saved with Validation Loss: 717.7037\n",
      "Epoch 4400/50000, Training Loss: 6352.3749\n",
      "Epoch 4400/50000, Validation Loss: 1436.6516\n",
      "Epoch 4450/50000, Training Loss: 6343.0400\n",
      "Epoch 4450/50000, Validation Loss: 1364.1180\n",
      "Epoch 4500/50000, Training Loss: 6408.8831\n",
      "Epoch 4500/50000, Validation Loss: 1865.4769\n",
      "Epoch 4550/50000, Training Loss: 6276.3750\n",
      "Epoch 4550/50000, Validation Loss: 1489.8452\n",
      "Epoch 4600/50000, Training Loss: 6264.4440\n",
      "Epoch 4600/50000, Validation Loss: 1771.6878\n",
      "Epoch 4650/50000, Training Loss: 6248.6134\n",
      "Epoch 4650/50000, Validation Loss: 2299.8854\n",
      "Epoch 4700/50000, Training Loss: 6302.4405\n",
      "Epoch 4700/50000, Validation Loss: 1512.0681\n",
      "Epoch 4750/50000, Training Loss: 6241.1955\n",
      "Epoch 4750/50000, Validation Loss: 1790.4458\n",
      "Epoch 4800/50000, Training Loss: 6114.5419\n",
      "Epoch 4800/50000, Validation Loss: 1950.2184\n",
      "Epoch 4850/50000, Training Loss: 6028.0730\n",
      "Epoch 4850/50000, Validation Loss: 1704.8359\n",
      "Epoch 4900/50000, Training Loss: 6081.6593\n",
      "Epoch 4900/50000, Validation Loss: 1198.8888\n",
      "Epoch 4950/50000, Training Loss: 6178.6066\n",
      "Epoch 4950/50000, Validation Loss: 1719.5474\n",
      "Epoch 5000/50000, Training Loss: 5933.4392\n",
      "Epoch 5000/50000, Validation Loss: 2117.1006\n",
      "Epoch 5050/50000, Training Loss: 6010.2788\n",
      "Epoch 5050/50000, Validation Loss: 1057.5873\n",
      "Epoch 5100/50000, Training Loss: 6117.4170\n",
      "Epoch 5100/50000, Validation Loss: 1326.8247\n",
      "Epoch 5150/50000, Training Loss: 5957.0653\n",
      "Epoch 5150/50000, Validation Loss: 2214.3204\n",
      "Epoch 5200/50000, Training Loss: 6009.0283\n",
      "Epoch 5200/50000, Validation Loss: 1201.4038\n",
      "Epoch 5250/50000, Training Loss: 5968.0888\n",
      "Epoch 5250/50000, Validation Loss: 1662.5233\n",
      "Epoch 5300/50000, Training Loss: 5686.1503\n",
      "Epoch 5300/50000, Validation Loss: 1255.1622\n",
      "Epoch 5350/50000, Training Loss: 5655.2991\n",
      "Epoch 5350/50000, Validation Loss: 1072.5399\n",
      "Epoch 5400/50000, Training Loss: 5538.1399\n",
      "Epoch 5400/50000, Validation Loss: 1269.3119\n",
      "Epoch 5450/50000, Training Loss: 5617.7732\n",
      "Epoch 5450/50000, Validation Loss: 1312.5546\n",
      "Epoch 5500/50000, Training Loss: 5518.3039\n",
      "Epoch 5500/50000, Validation Loss: 2414.7085\n",
      "Epoch 5550/50000, Training Loss: 5494.9286\n",
      "Epoch 5550/50000, Validation Loss: 1385.0311\n",
      "Epoch 5600/50000, Training Loss: 5625.6742\n",
      "Epoch 5600/50000, Validation Loss: 1461.3836\n",
      "Epoch 5650/50000, Training Loss: 5369.4727\n",
      "Epoch 5650/50000, Validation Loss: 1434.4801\n",
      "Epoch 5700/50000, Training Loss: 5705.0289\n",
      "Epoch 5700/50000, Validation Loss: 1481.8007\n",
      "Epoch 5750/50000, Training Loss: 5508.2092\n",
      "Epoch 5750/50000, Validation Loss: 1578.4899\n",
      "Epoch 5800/50000, Training Loss: 5735.7843\n",
      "Epoch 5800/50000, Validation Loss: 1454.2419\n",
      "Epoch 5850/50000, Training Loss: 5442.2218\n",
      "Epoch 5850/50000, Validation Loss: 1571.8201\n",
      "Epoch 5900/50000, Training Loss: 5495.5687\n",
      "Epoch 5900/50000, Validation Loss: 1335.2856\n",
      "Epoch 5950/50000, Training Loss: 5494.0017\n",
      "Epoch 5950/50000, Validation Loss: 1351.0434\n",
      "Epoch 6000/50000, Training Loss: 5682.6096\n",
      "Epoch 6000/50000, Validation Loss: 1618.2821\n",
      "Epoch 6050/50000, Training Loss: 5506.9528\n",
      "Epoch 6050/50000, Validation Loss: 1623.6952\n",
      "Epoch 6100/50000, Training Loss: 5489.3570\n",
      "Epoch 6100/50000, Validation Loss: 1527.7010\n",
      "Epoch 6150/50000, Training Loss: 5458.1421\n",
      "Epoch 6150/50000, Validation Loss: 1369.5616\n",
      "Epoch 6200/50000, Training Loss: 5542.3541\n",
      "Epoch 6200/50000, Validation Loss: 1403.4105\n",
      "Epoch 6250/50000, Training Loss: 5407.7197\n",
      "Epoch 6250/50000, Validation Loss: 1433.0422\n",
      "Epoch 6300/50000, Training Loss: 5367.3409\n",
      "Epoch 6300/50000, Validation Loss: 1689.4911\n",
      "Epoch 6350/50000, Training Loss: 5302.8123\n",
      "Epoch 6350/50000, Validation Loss: 1570.9406\n",
      "Epoch 6400/50000, Training Loss: 5472.2920\n",
      "Epoch 6400/50000, Validation Loss: 1602.2863\n",
      "Epoch 6450/50000, Training Loss: 5452.9889\n",
      "Epoch 6450/50000, Validation Loss: 1767.1513\n",
      "Epoch 6500/50000, Training Loss: 5376.7698\n",
      "Epoch 6500/50000, Validation Loss: 1417.7830\n",
      "Epoch 6550/50000, Training Loss: 5280.5000\n",
      "Epoch 6550/50000, Validation Loss: 1491.8389\n",
      "Epoch 6600/50000, Training Loss: 5263.8177\n",
      "Epoch 6600/50000, Validation Loss: 2128.4562\n",
      "Epoch 6650/50000, Training Loss: 5337.3055\n",
      "Epoch 6650/50000, Validation Loss: 1318.4132\n",
      "Epoch 6700/50000, Training Loss: 5418.0838\n",
      "Epoch 6700/50000, Validation Loss: 1437.5180\n",
      "Epoch 6750/50000, Training Loss: 5321.7006\n",
      "Epoch 6750/50000, Validation Loss: 1352.4745\n",
      "Epoch 6800/50000, Training Loss: 5409.6120\n",
      "Epoch 6800/50000, Validation Loss: 1491.8157\n",
      "Epoch 6850/50000, Training Loss: 5316.7888\n",
      "Epoch 6850/50000, Validation Loss: 1576.3298\n",
      "Epoch 6900/50000, Training Loss: 5373.0379\n",
      "Epoch 6900/50000, Validation Loss: 1618.6138\n",
      "Epoch 6950/50000, Training Loss: 5230.1035\n",
      "Epoch 6950/50000, Validation Loss: 1579.4528\n",
      "Epoch 7000/50000, Training Loss: 5408.2440\n",
      "Epoch 7000/50000, Validation Loss: 1284.8257\n",
      "Epoch 7050/50000, Training Loss: 5456.3899\n",
      "Epoch 7050/50000, Validation Loss: 1552.1172\n",
      "Epoch 7100/50000, Training Loss: 5372.0143\n",
      "Epoch 7100/50000, Validation Loss: 1575.1867\n",
      "Epoch 7150/50000, Training Loss: 5373.8138\n",
      "Epoch 7150/50000, Validation Loss: 1430.1461\n",
      "Epoch 7200/50000, Training Loss: 5313.0043\n",
      "Epoch 7200/50000, Validation Loss: 1531.6600\n",
      "Epoch 7250/50000, Training Loss: 5211.2346\n",
      "Epoch 7250/50000, Validation Loss: 1769.8091\n",
      "Epoch 7300/50000, Training Loss: 5242.8484\n",
      "Epoch 7300/50000, Validation Loss: 1383.4745\n",
      "Epoch 7350/50000, Training Loss: 5399.2254\n",
      "Epoch 7350/50000, Validation Loss: 1423.8514\n",
      "Epoch 7400/50000, Training Loss: 5240.0926\n",
      "Epoch 7400/50000, Validation Loss: 1635.1340\n",
      "Epoch 7450/50000, Training Loss: 5220.7206\n",
      "Epoch 7450/50000, Validation Loss: 1337.7049\n",
      "Epoch 7500/50000, Training Loss: 5341.4229\n",
      "Epoch 7500/50000, Validation Loss: 1651.1525\n",
      "Epoch 7550/50000, Training Loss: 5351.6534\n",
      "Epoch 7550/50000, Validation Loss: 1822.5430\n",
      "Epoch 7600/50000, Training Loss: 5374.1718\n",
      "Epoch 7600/50000, Validation Loss: 1877.4485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#left_arm_idx = list(range(left_wrist_idx + 1, left_wrist_idx + num_left_arm_landmarks))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m left_arm_idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_seq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_left_arm_hand_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand/train_ann_no_intrinsics.py:89\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, num_epochs, save_path, early_stopping, scheduler, writer, log_seq, weight_idx, weight, train_left_arm_hand_only)\u001b[0m\n\u001b[1;32m     86\u001b[0m loss \u001b[38;5;241m=\u001b[39m elementwise_loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 89\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     92\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \n",
      "File \u001b[0;32m~/py_venv/mmpose/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py_venv/mmpose/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py_venv/mmpose/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "left_wrist_idx = 5\n",
    "num_left_arm_landmarks = 21\n",
    "#left_arm_idx = list(range(left_wrist_idx + 1, left_wrist_idx + num_left_arm_landmarks))\n",
    "left_arm_idx = [7, 8, 11, 12, 15, 16, 19, 20, 23, 24]\n",
    "\n",
    "train_losses, val_losses = train_model(model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    optimizer, \n",
    "    num_epochs=num_epochs, \n",
    "    save_path=save_path,\n",
    "    early_stopping=early_stopping,\n",
    "    scheduler=scheduler,\n",
    "    writer=writer,\n",
    "    log_seq=50,\n",
    "    train_left_arm_hand_only=False,\n",
    "    weight_idx=None,\n",
    "    weight=1.)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpose",
   "language": "python",
   "name": "mmpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
