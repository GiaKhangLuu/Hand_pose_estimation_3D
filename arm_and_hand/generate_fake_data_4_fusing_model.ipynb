{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"Hand_pose_estimation_3D/arm_and_hand\")\n",
    "sys.path.append(\"Hand_pose_estimation_3D\")\n",
    "\n",
    "from dataloader_ann import HandArmLandmarksDataset_ANN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utilities import fuse_landmarks_from_two_cameras\n",
    "from functools import partial\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusing_model = partial(fuse_landmarks_from_two_cameras,\n",
    "    tolerance=1e-5,\n",
    "    method_name=\"L-BFGS-B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"  \n",
    "SELECTED_DATE = \"*\"\n",
    "\n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"train\")))\n",
    "val_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"val\")))\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "body_distance_thres=550\n",
    "leftarm_distance_thres=550\n",
    "lefthand_distance_thres=200\n",
    "\n",
    "train_dataset = HandArmLandmarksDataset_ANN(train_paths, \n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    body_distance_thres, \n",
    "    leftarm_distance_thres, \n",
    "    lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = train_dataset._inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 322)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing data and performing for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 144)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get records which have depth (z != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "left_camera_lmks_z_values = left_camera_lmks[:, -1, :]\n",
    "left_camera_rows_contain_z_idx = np.where(np.sum(left_camera_lmks_z_values, axis=1) != 0)[0]\n",
    "left_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)\n",
    "right_camera_lmks_z_values = right_camera_lmks[:, -1, :]\n",
    "right_camera_rows_contain_z_idx = np.where(np.sum(right_camera_lmks_z_values, axis=1) != 0)[0]\n",
    "right_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_id_mask = left_camera_rows_contain_z_idx == right_camera_rows_contain_z_idx\n",
    "fake_rows_selected_id = left_camera_rows_contain_z_idx[common_id_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set depth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546, 3, 48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks = left_camera_lmks[fake_rows_selected_id]\n",
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114372"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, -1, :] = fake_left_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])\n",
    "#fake_left_camera_lmks[:, -1, :] = np.ones_like(fake_left_camera_lmks[:, -1, :]) \n",
    "#fake_left_camera_lmks[:, -1, :] = fake_left_camera_lmks[:, -1, :] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28274"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546, 3, 48)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks = right_camera_lmks[fake_rows_selected_id]\n",
    "fake_right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115613"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29087"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks[:, -1, :] = fake_right_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])\n",
    "#fake_right_camera_lmks[:, -1, :] = np.ones_like(fake_left_camera_lmks[:, -1, :])\n",
    "#fake_right_camera_lmks[:, -1, :] = fake_right_camera_lmks[:, -1, :] * mask\n",
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546, 3, 48)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_left_camera_intrinsic = left_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_camera_intrinsic = right_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_2_left_mat = right_2_left_mat[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 1920 \n",
    "img_h = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, 0, :] = fake_left_camera_lmks[:, 0, :]  * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_left_camera_lmks[:, 1, :] = fake_left_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 0, :] = fake_right_camera_lmks[:, 0, :] * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 1, :] = fake_right_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks = np.transpose(fake_left_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3), N* = #selected_rows\n",
    "fake_right_camera_lmks = np.transpose(fake_right_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = []\n",
    "for i in range(fake_left_camera_lmks.shape[0]):\n",
    "    left_xyZ = fake_left_camera_lmks[i]\n",
    "    right_xyZ = fake_right_camera_lmks[i]\n",
    "    left_intr = selected_left_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_intr = selected_right_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_2_left_mat = selected_right_2_left_mat[i].reshape(4, 4)\n",
    "    fused_XYZ = fusing_model(left_xyZ,\n",
    "        right_xyZ,\n",
    "        right_intr,\n",
    "        left_intr,\n",
    "        right_2_left_mat)\n",
    "    fake_fusing_data.append(fused_XYZ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = np.array(fake_fusing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_hand_fused_names = [\"left shoulder\", \"left elbow\", \"left hip\", \"right shoulder\", \"right hip\", \n",
    " \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\", \"INDEX_FINGER_MCP\", \n",
    " \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\", \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_MCP\", \n",
    " \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_TIP\", \"RING_FINGER_MCP\", \n",
    " \"RING_FINGER_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_TIP\", \"PINKY_MCP\", \"PINKY_PIP\", \n",
    " \"PINKY_DIP\", \"PINKY_TIP\", \"right elbow\"]\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lmks = train_dataset._outputs\n",
    "gt_lmks = gt_lmks.reshape(-1, 3, 48)\n",
    "gt_lmks = np.transpose(gt_lmks, (0, 2, 1))\n",
    "\n",
    "merged_fake_and_gt = np.concatenate([gt_lmks, fake_fusing_data.reshape(-1, 48, 3)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ground-truth and fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from utilities import convert_to_left_shoulder_coord\n",
    "import time\n",
    "\n",
    "time_sleep = 0.1\n",
    "x = np.array([[500, 0, 0],\n",
    "    [0, 0, 0]])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(x)\n",
    "lines = [[0, 0]]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(x),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "vis.add_geometry(line_set)\n",
    "\n",
    "for i in range(merged_fake_and_gt.shape[0]):\n",
    "    output = merged_fake_and_gt[i, ...]  # shape: (48, 3)\n",
    "\n",
    "    lines = body_lines.copy()\n",
    "    lines.extend(lefthand_lines)\n",
    "\n",
    "    points, _ = convert_to_left_shoulder_coord(output,\n",
    "        arm_hand_fused_names)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    if i < gt_lmks.shape[0]:\n",
    "        colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    else:\n",
    "        colors = [[0, 0, 1] for i in range(len(lines))]\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)  \n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines) \n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.update_geometry(line_set)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "        \n",
    "    time.sleep(time_sleep)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from utilities import convert_to_left_shoulder_coord\n",
    "import time\n",
    "\n",
    "time_sleep = 0.1\n",
    "x = np.array([[500, 0, 0],\n",
    "    [0, 0, 0]])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(x)\n",
    "lines = [[0, 0]]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(x),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "vis.add_geometry(line_set)\n",
    "\n",
    "for i in range(fake_fusing_data.shape[0]):\n",
    "    output = fake_fusing_data[i, ...]  # shape: (144)\n",
    "    output = output.reshape(48, 3)  # shape: (48, 3)\n",
    "\n",
    "    lines = body_lines.copy()\n",
    "    lines.extend(lefthand_lines)\n",
    "\n",
    "    points, _ = convert_to_left_shoulder_coord(output,\n",
    "        arm_hand_fused_names)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)  \n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines) \n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.update_geometry(line_set)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "        \n",
    "    time.sleep(time_sleep)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate abs-error between GT data and fake data (depth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 403.9329122 ,  415.46720667,  379.16550393, ..., 1419.42772941,\n",
       "        1415.19516004, 1415.31684475],\n",
       "       [ 326.01000858,  343.48034908,  300.78903567, ..., 1546.32257681,\n",
       "        1544.67232153, 1544.73116729],\n",
       "       [ 316.26863112,  337.91649653,  282.09465758, ..., 1547.76046339,\n",
       "        1546.84398216, 1545.51210793],\n",
       "       ...,\n",
       "       [ 230.62679044,  379.42922073,  220.95343313, ..., 2766.5307005 ,\n",
       "        2768.7075366 , 2762.95119337],\n",
       "       [ 311.68723018,  441.58801223,  278.17032416, ..., 2696.96603027,\n",
       "        2702.60665757, 2701.79548023],\n",
       "       [ 419.18539214,  515.68079145,  389.69519384, ..., 2595.4959104 ,\n",
       "        2605.77249544, 2605.59853492]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 403.9329168 , -162.53821442, 1452.78067729, ...,  149.07896002,\n",
       "         317.40656406, 1415.31684744],\n",
       "       [ 326.01003582, -178.32397917, 1582.61388768, ...,   76.92987689,\n",
       "         306.79857738, 1544.73116736],\n",
       "       [ 316.26863975, -183.05685874, 1542.64847715, ...,   60.09843453,\n",
       "         311.49169781, 1545.51209429],\n",
       "       ...,\n",
       "       [  44.49103033, -125.69358541, 1642.23505562, ...,   -0.        ,\n",
       "          -0.        ,    0.        ],\n",
       "       [  45.47561712, -124.03909647, 1642.05288773, ...,   -0.        ,\n",
       "          -0.        ,    0.        ],\n",
       "       [  43.72238874, -129.89987106, 1642.08141943, ...,   -0.        ,\n",
       "          -0.        ,    0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_fusing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10876,144) (4546,144) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m true_outputs \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39m_outputs\n\u001b[0;32m----> 2\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[43mtrue_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfake_fusing_data\u001b[49m\n\u001b[1;32m      3\u001b[0m abs_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabsolute(error)\n\u001b[1;32m      4\u001b[0m mean_abs_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(abs_error)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10876,144) (4546,144) "
     ]
    }
   ],
   "source": [
    "true_outputs = train_dataset._outputs\n",
    "error = true_outputs - fake_fusing_data\n",
    "abs_error = np.absolute(error)\n",
    "mean_abs_error = np.mean(abs_error)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546, 144)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_fusing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform for each .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv_writer import create_csv, append_to_csv, fusion_csv_columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAKE_DATA_DIR = \"data/fake_data\"\n",
    "FAKE_TRAIN_DIR = os.path.join(FAKE_DATA_DIR, \"train\")\n",
    "FAKE_VAL_DIR = os.path.join(FAKE_DATA_DIR, \"val\")\n",
    "\n",
    "if os.path.exists(FAKE_TRAIN_DIR):\n",
    "    shutil.rmtree(FAKE_TRAIN_DIR)\n",
    "os.makedirs(FAKE_TRAIN_DIR)\n",
    "\n",
    "if os.path.exists(FAKE_VAL_DIR):\n",
    "    shutil.rmtree(FAKE_VAL_DIR)\n",
    "os.makedirs(FAKE_VAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "body_distance_thres=550\n",
    "leftarm_distance_thres=550\n",
    "lefthand_distance_thres=200\n",
    "\n",
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "img_w = 1920 \n",
    "img_h = 1080\n",
    "\n",
    "for train_path in train_paths:\n",
    "    train_dataset = HandArmLandmarksDataset_ANN([train_path], \n",
    "        body_lines, \n",
    "        lefthand_lines, \n",
    "        body_distance_thres, \n",
    "        leftarm_distance_thres, \n",
    "        lefthand_distance_thres,\n",
    "        filter_outlier=True,\n",
    "        only_keep_frames_contain_lefthand=True)\n",
    "    \n",
    "    input_data = train_dataset._inputs\n",
    "    if input_data.shape[0] < seq_len:\n",
    "        continue\n",
    "    \n",
    "    # Slicing data\n",
    "    left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows\n",
    "\n",
    "    # Get left and right records which have depth (z != 0) \n",
    "    left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    left_camera_lmks_z_values = left_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    right_camera_lmks_z_values = right_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    left_camera_sum_z = np.sum(left_camera_lmks_z_values)\n",
    "    right_camera_sum_z = np.sum(right_camera_lmks_z_values)\n",
    "    if left_camera_sum_z == 0 or right_camera_sum_z == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly set z = 0\n",
    "    mask_left = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    mask_right = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    left_camera_lmks[:, -1, :] = mask_left * left_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, -1, :] = mask_right * right_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "\n",
    "    left_camera_lmks[:, 0, :] = left_camera_lmks[:, 0, :]  * img_w  # shape: (N, 3, 48)\n",
    "    left_camera_lmks[:, 1, :] = left_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 0, :] = right_camera_lmks[:, 0, :] * img_w  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 1, :] = right_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "\n",
    "\n",
    "    left_camera_lmks = np.transpose(left_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "    right_camera_lmks = np.transpose(right_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "\n",
    "    # Fuse data\n",
    "    fake_fusing_data = []\n",
    "    for i in range(left_camera_lmks.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]\n",
    "        right_xyZ = right_camera_lmks[i]\n",
    "        left_intr = left_camera_intrinsic[i].reshape(3, 3)\n",
    "        right_intr = right_camera_intrinsic[i].reshape(3, 3)\n",
    "        trans_mat = right_2_left_mat[i].reshape(4, 4)\n",
    "        fused_XYZ = fusing_model(opposite_xyZ=left_xyZ,\n",
    "            right_side_xyZ=right_xyZ,\n",
    "            right_side_cam_intrinsic=right_intr,\n",
    "            opposite_cam_intrinsic=left_intr,\n",
    "            right_to_opposite_correctmat=trans_mat)\n",
    "        fake_fusing_data.append(fused_XYZ.flatten())\n",
    "\n",
    "    fake_fusing_data = np.array(fake_fusing_data)\n",
    "\n",
    "    filename = os.path.basename(train_path)\n",
    "    fake_data_path = os.path.join(FAKE_TRAIN_DIR, \"fake_\" + filename)\n",
    "    create_csv(fake_data_path, fusion_csv_columns_name)\n",
    "\n",
    "    # Write to file\n",
    "    for i in range(fake_fusing_data.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]  # shape: (48, 3)\n",
    "        right_xyZ = right_camera_lmks[i]  # shape: (48, 3)\n",
    "        left_intr = left_camera_intrinsic[i]  # shape: (9)\n",
    "        right_intr = right_camera_intrinsic[i]  # shape: (9)\n",
    "        trans_mat = right_2_left_mat[i]  # shape: (16)\n",
    "\n",
    "        fused_lmks = fake_fusing_data[i, ...]  # shape: (144)\n",
    "\n",
    "        left_xyZ = left_xyZ.T  # shape: (3, 48)\n",
    "        left_xyZ[0, :] = left_xyZ[0, :] / img_w\n",
    "        left_xyZ[1, :] = left_xyZ[1, :] / img_h\n",
    "        right_xyZ = right_xyZ.T  # shape: (3, 48)\n",
    "        right_xyZ[0, :] = right_xyZ[0, :] / img_w\n",
    "        right_xyZ[1, :] = right_xyZ[1, :] / img_h\n",
    "        fused_lmks = fused_lmks.reshape(48, 3)  # shape: (48, 3)\n",
    "        fused_lmks = fused_lmks.T  # shape: (3, 48)\n",
    "        \n",
    "        input_row = np.concatenate([[i],\n",
    "            left_xyZ.flatten(),\n",
    "            left_intr.flatten(),\n",
    "            right_xyZ.flatten(),\n",
    "            right_intr.flatten(),\n",
    "            trans_mat.flatten(),\n",
    "            fused_lmks.flatten()])\n",
    "        append_to_csv(fake_data_path, input_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_distance_thres = 450\n",
    "leftarm_distance_thres = 450\n",
    "lefthand_distance_thres = 200\n",
    "\n",
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "img_w = 1920 \n",
    "img_h = 1080\n",
    "\n",
    "for val_path in val_paths:\n",
    "    val_dataset = HandArmLandmarksDataset_ANN([val_path], \n",
    "        body_lines, \n",
    "        lefthand_lines, \n",
    "        body_distance_thres, \n",
    "        leftarm_distance_thres, \n",
    "        lefthand_distance_thres,\n",
    "        filter_outlier=True,\n",
    "        only_keep_frames_contain_lefthand=True)\n",
    "    \n",
    "    input_data = val_dataset._inputs\n",
    "    if input_data.shape[0] < seq_len:\n",
    "        continue\n",
    "    \n",
    "    # Slicing data\n",
    "    left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows\n",
    "\n",
    "    # Get left and right records which have depth (z != 0) \n",
    "    left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    left_camera_lmks_z_values = left_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    right_camera_lmks_z_values = right_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    left_camera_sum_z = np.sum(left_camera_lmks_z_values)\n",
    "    right_camera_sum_z = np.sum(right_camera_lmks_z_values)\n",
    "    if left_camera_sum_z == 0 or right_camera_sum_z == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly set z = 0\n",
    "    mask_left = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    mask_right = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    left_camera_lmks[:, -1, :] = mask_left * left_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, -1, :] = mask_right * right_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "\n",
    "    left_camera_lmks[:, 0, :] = left_camera_lmks[:, 0, :]  * img_w  # shape: (N, 3, 48)\n",
    "    left_camera_lmks[:, 1, :] = left_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 0, :] = right_camera_lmks[:, 0, :] * img_w  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 1, :] = right_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "\n",
    "\n",
    "    left_camera_lmks = np.transpose(left_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "    right_camera_lmks = np.transpose(right_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "\n",
    "    # Fuse data\n",
    "    fake_fusing_data = []\n",
    "    for i in range(left_camera_lmks.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]\n",
    "        right_xyZ = right_camera_lmks[i]\n",
    "        left_intr = left_camera_intrinsic[i].reshape(3, 3)\n",
    "        right_intr = right_camera_intrinsic[i].reshape(3, 3)\n",
    "        trans_mat = right_2_left_mat[i].reshape(4, 4)\n",
    "        fused_XYZ = fusing_model(opposite_xyZ=left_xyZ,\n",
    "            right_side_xyZ=right_xyZ,\n",
    "            right_side_cam_intrinsic=right_intr,\n",
    "            opposite_cam_intrinsic=left_intr,\n",
    "            right_to_opposite_correctmat=trans_mat)\n",
    "        fake_fusing_data.append(fused_XYZ.flatten())\n",
    "\n",
    "    fake_fusing_data = np.array(fake_fusing_data)\n",
    "\n",
    "    filename = os.path.basename(val_path)\n",
    "    fake_data_path = os.path.join(FAKE_VAL_DIR, \"fake_\" + filename)\n",
    "    create_csv(fake_data_path, fusion_csv_columns_name)\n",
    "\n",
    "    # Write to file\n",
    "    for i in range(fake_fusing_data.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]  # shape: (48, 3)\n",
    "        right_xyZ = right_camera_lmks[i]  # shape: (48, 3)\n",
    "        left_intr = left_camera_intrinsic[i]  # shape: (9)\n",
    "        right_intr = right_camera_intrinsic[i]  # shape: (9)\n",
    "        trans_mat = right_2_left_mat[i]  # shape: (16)\n",
    "\n",
    "        fused_lmks = fake_fusing_data[i, ...]  # shape: (144)\n",
    "\n",
    "        left_xyZ = left_xyZ.T  # shape: (3, 48)\n",
    "        left_xyZ[0, :] = left_xyZ[0, :] / img_w\n",
    "        left_xyZ[1, :] = left_xyZ[1, :] / img_h\n",
    "        right_xyZ = right_xyZ.T  # shape: (3, 48)\n",
    "        right_xyZ[0, :] = right_xyZ[0, :] / img_w\n",
    "        right_xyZ[1, :] = right_xyZ[1, :] / img_h\n",
    "        fused_lmks = fused_lmks.reshape(48, 3)  # shape: (48, 3)\n",
    "        fused_lmks = fused_lmks.T  # shape: (3, 48)\n",
    "        \n",
    "        input_row = np.concatenate([[i],\n",
    "            left_xyZ.flatten(),\n",
    "            left_intr.flatten(),\n",
    "            right_xyZ.flatten(),\n",
    "            right_intr.flatten(),\n",
    "            trans_mat.flatten(),\n",
    "            fused_lmks.flatten()])\n",
    "        append_to_csv(fake_data_path, input_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
