{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand\")\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D\")\n",
    "\n",
    "from dataloader_ann import HandArmLandmarksDataset_ANN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utilities import fuse_landmarks_from_two_cameras\n",
    "from functools import partial\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusing_model = partial(fuse_landmarks_from_two_cameras,\n",
    "    tolerance=1e-10,\n",
    "    method_name=\"L-BFGS-B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/giakhang/dev/pose_sandbox/data\"  \n",
    "SELECTED_DATE = \"*\"\n",
    "\n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"train\")))\n",
    "val_paths = glob.glob(os.path.join(DATA_DIR, \"{}/{}/fine_landmarks_{}_*.csv\".format(SELECTED_DATE, SELECTED_DATE, \"val\")))\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "body_distance_thres=550\n",
    "leftarm_distance_thres=550\n",
    "lefthand_distance_thres=200\n",
    "\n",
    "train_dataset = HandArmLandmarksDataset_ANN(train_paths, \n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    body_distance_thres, \n",
    "    leftarm_distance_thres, \n",
    "    lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = train_dataset._inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3522, 322)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing data and performing for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2681, 144)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get records which have depth (z != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "left_camera_lmks_z_values = left_camera_lmks[:, -1, :]\n",
    "left_camera_rows_contain_z_idx = np.where(np.sum(left_camera_lmks_z_values, axis=1) != 0)[0]\n",
    "left_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)\n",
    "right_camera_lmks_z_values = right_camera_lmks[:, -1, :]\n",
    "right_camera_rows_contain_z_idx = np.where(np.sum(right_camera_lmks_z_values, axis=1) != 0)[0]\n",
    "right_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_id_mask = left_camera_rows_contain_z_idx == right_camera_rows_contain_z_idx\n",
    "fake_rows_selected_id = left_camera_rows_contain_z_idx[common_id_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set depth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 3, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks = left_camera_lmks[fake_rows_selected_id]\n",
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, -1, :] = fake_left_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])\n",
    "#fake_left_camera_lmks[:, -1, :] = np.ones_like(fake_left_camera_lmks[:, -1, :]) \n",
    "#fake_left_camera_lmks[:, -1, :] = fake_left_camera_lmks[:, -1, :] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8355"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 3, 48)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks = right_camera_lmks[fake_rows_selected_id]\n",
    "fake_right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36101"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9006"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks[:, -1, :] = fake_right_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])\n",
    "#fake_right_camera_lmks[:, -1, :] = np.ones_like(fake_left_camera_lmks[:, -1, :])\n",
    "#fake_right_camera_lmks[:, -1, :] = fake_right_camera_lmks[:, -1, :] * mask\n",
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 3, 48)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_left_camera_intrinsic = left_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_camera_intrinsic = right_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_2_left_mat = right_2_left_mat[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 1920 \n",
    "img_h = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, 0, :] = fake_left_camera_lmks[:, 0, :]  * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_left_camera_lmks[:, 1, :] = fake_left_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 0, :] = fake_right_camera_lmks[:, 0, :] * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 1, :] = fake_right_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks = np.transpose(fake_left_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3), N* = #selected_rows\n",
    "fake_right_camera_lmks = np.transpose(fake_right_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = []\n",
    "for i in range(fake_left_camera_lmks.shape[0]):\n",
    "    left_xyZ = fake_left_camera_lmks[i]\n",
    "    right_xyZ = fake_right_camera_lmks[i]\n",
    "    left_intr = selected_left_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_intr = selected_right_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_2_left_mat = selected_right_2_left_mat[i].reshape(4, 4)\n",
    "    fused_XYZ = fusing_model(left_xyZ,\n",
    "        right_xyZ,\n",
    "        right_intr,\n",
    "        left_intr,\n",
    "        right_2_left_mat)\n",
    "    fake_fusing_data.append(fused_XYZ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = np.array(fake_fusing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_hand_fused_names = [\"left shoulder\", \"left elbow\", \"left hip\", \"right shoulder\", \"right hip\", \n",
    " \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\", \"INDEX_FINGER_MCP\", \n",
    " \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\", \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_MCP\", \n",
    " \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_TIP\", \"RING_FINGER_MCP\", \n",
    " \"RING_FINGER_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_TIP\", \"PINKY_MCP\", \"PINKY_PIP\", \n",
    " \"PINKY_DIP\", \"PINKY_TIP\", \"right elbow\"]\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lmks = train_dataset._outputs\n",
    "gt_lmks = gt_lmks.reshape(-1, 3, 48)\n",
    "gt_lmks = np.transpose(gt_lmks, (0, 2, 1))\n",
    "\n",
    "merged_fake_and_gt = np.concatenate([gt_lmks, fake_fusing_data.reshape(-1, 48, 3)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ground-truth and fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from utilities import convert_to_shoulder_coord\n",
    "import time\n",
    "\n",
    "time_sleep = 0.1\n",
    "x = np.array([[500, 0, 0],\n",
    "    [0, 0, 0]])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(x)\n",
    "lines = [[0, 0]]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(x),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "vis.add_geometry(line_set)\n",
    "\n",
    "for i in range(merged_fake_and_gt.shape[0]):\n",
    "    output = merged_fake_and_gt[i, ...]  # shape: (48, 3)\n",
    "\n",
    "    lines = body_lines.copy()\n",
    "    lines.extend(lefthand_lines)\n",
    "\n",
    "    points, _ = convert_to_shoulder_coord(output,\n",
    "        arm_hand_fused_names)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    if i < gt_lmks.shape[0]:\n",
    "        colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    else:\n",
    "        colors = [[0, 0, 1] for i in range(len(lines))]\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)  \n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines) \n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.update_geometry(line_set)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "        \n",
    "    time.sleep(time_sleep)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from utilities import convert_to_shoulder_coord\n",
    "import time\n",
    "\n",
    "time_sleep = 0.1\n",
    "x = np.array([[500, 0, 0],\n",
    "    [0, 0, 0]])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(x)\n",
    "lines = [[0, 0]]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(x),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "vis.add_geometry(line_set)\n",
    "\n",
    "for i in range(fake_fusing_data.shape[0]):\n",
    "    output = fake_fusing_data[i, ...]  # shape: (144)\n",
    "    output = output.reshape(48, 3)  # shape: (48, 3)\n",
    "\n",
    "    lines = body_lines.copy()\n",
    "    lines.extend(lefthand_lines)\n",
    "\n",
    "    points, _ = convert_to_shoulder_coord(output,\n",
    "        arm_hand_fused_names)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)  \n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines) \n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.update_geometry(line_set)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "        \n",
    "    time.sleep(time_sleep)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate abs-error between GT data and fake data (depth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.25242941e+01, -2.10511963e+00, -1.05293310e+02, ...,\n",
       "         2.57038318e+03,  2.62442164e+03,  2.65511055e+03],\n",
       "       [ 3.83211296e+01,  7.68492058e+01, -9.61939719e+00, ...,\n",
       "         2.69328283e+03,  2.71155484e+03,  2.71490973e+03],\n",
       "       [ 1.80402893e+01,  5.28069755e+01, -3.68680789e+01, ...,\n",
       "         2.66025776e+03,  2.68894465e+03,  2.70117981e+03],\n",
       "       ...,\n",
       "       [-1.83994547e+01,  7.44376419e+01, -7.76488667e+01, ...,\n",
       "         2.64023472e+03,  2.67795683e+03,  2.70501859e+03],\n",
       "       [-2.21631086e+01,  7.99102842e+01, -7.78069431e+01, ...,\n",
       "         2.62882537e+03,  2.66246453e+03,  2.68566126e+03],\n",
       "       [-2.30118613e+01,  7.20885288e+01, -7.99117471e+01, ...,\n",
       "         2.63425038e+03,  2.66615231e+03,  2.68851256e+03]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -42.52442052, -185.2095743 , 2218.97938764, ..., -410.07379255,\n",
       "         309.3090836 , 2655.15800635],\n",
       "       [  38.32093922, -181.8097672 , 2263.43605478, ..., -291.02371353,\n",
       "         307.81803029, 2714.91374759],\n",
       "       [  18.0403482 , -181.87053466, 2258.31249428, ..., -328.01398007,\n",
       "         310.03188802, 2701.20714513],\n",
       "       ...,\n",
       "       [ -18.39979591, -171.56696273, 2233.55714804, ..., -419.02639827,\n",
       "         358.35669457, 2705.02530216],\n",
       "       [ -22.16242369, -170.45824039, 2234.11511476, ..., -412.10049938,\n",
       "         346.62717294, 2685.74548267],\n",
       "       [ -23.01153525, -172.24973317, 2232.76519487, ..., -412.93104161,\n",
       "         349.62096188, 2688.4842939 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_fusing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140.8771597441114\n"
     ]
    }
   ],
   "source": [
    "true_outputs = train_dataset._outputs\n",
    "error = true_outputs - fake_fusing_data\n",
    "abs_error = np.absolute(error)\n",
    "mean_abs_error = np.mean(abs_error)\n",
    "print(mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform for each .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv_writer import create_csv, append_to_csv, fusion_csv_columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAKE_DATA_DIR = \"/home/giakhang/dev/pose_sandbox/data/fake_data\"\n",
    "FAKE_TRAIN_DIR = os.path.join(FAKE_DATA_DIR, \"train\")\n",
    "FAKE_VAL_DIR = os.path.join(FAKE_DATA_DIR, \"val\")\n",
    "\n",
    "if os.path.exists(FAKE_TRAIN_DIR):\n",
    "    shutil.rmtree(FAKE_TRAIN_DIR)\n",
    "os.makedirs(FAKE_TRAIN_DIR)\n",
    "\n",
    "if os.path.exists(FAKE_VAL_DIR):\n",
    "    shutil.rmtree(FAKE_VAL_DIR)\n",
    "os.makedirs(FAKE_VAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "body_distance_thres=550\n",
    "leftarm_distance_thres=550\n",
    "lefthand_distance_thres=200\n",
    "\n",
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "img_w = 1920 \n",
    "img_h = 1080\n",
    "\n",
    "for train_path in train_paths:\n",
    "    train_dataset = HandArmLandmarksDataset_ANN([train_path], \n",
    "        body_lines, \n",
    "        lefthand_lines, \n",
    "        body_distance_thres, \n",
    "        leftarm_distance_thres, \n",
    "        lefthand_distance_thres,\n",
    "        filter_outlier=True,\n",
    "        only_keep_frames_contain_lefthand=True)\n",
    "    \n",
    "    input_data = train_dataset._inputs\n",
    "    if input_data.shape[0] < seq_len:\n",
    "        continue\n",
    "    \n",
    "    # Slicing data\n",
    "    left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows\n",
    "\n",
    "    # Get left and right records which have depth (z != 0) \n",
    "    left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    left_camera_lmks_z_values = left_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    right_camera_lmks_z_values = right_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    left_camera_sum_z = np.sum(left_camera_lmks_z_values)\n",
    "    right_camera_sum_z = np.sum(right_camera_lmks_z_values)\n",
    "    if left_camera_sum_z == 0 or right_camera_sum_z == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly set z = 0\n",
    "    mask_left = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    mask_right = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    left_camera_lmks[:, -1, :] = mask_left * left_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, -1, :] = mask_right * right_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "\n",
    "    left_camera_lmks[:, 0, :] = left_camera_lmks[:, 0, :]  * img_w  # shape: (N, 3, 48)\n",
    "    left_camera_lmks[:, 1, :] = left_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 0, :] = right_camera_lmks[:, 0, :] * img_w  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 1, :] = right_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "\n",
    "\n",
    "    left_camera_lmks = np.transpose(left_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "    right_camera_lmks = np.transpose(right_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "\n",
    "    # Fuse data\n",
    "    fake_fusing_data = []\n",
    "    for i in range(left_camera_lmks.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]\n",
    "        right_xyZ = right_camera_lmks[i]\n",
    "        left_intr = left_camera_intrinsic[i].reshape(3, 3)\n",
    "        right_intr = right_camera_intrinsic[i].reshape(3, 3)\n",
    "        trans_mat = right_2_left_mat[i].reshape(4, 4)\n",
    "        fused_XYZ = fusing_model(opposite_xyZ=left_xyZ,\n",
    "            right_side_xyZ=right_xyZ,\n",
    "            right_side_cam_intrinsic=right_intr,\n",
    "            opposite_cam_intrinsic=left_intr,\n",
    "            right_to_opposite_correctmat=trans_mat)\n",
    "        fake_fusing_data.append(fused_XYZ.flatten())\n",
    "\n",
    "    fake_fusing_data = np.array(fake_fusing_data)\n",
    "\n",
    "    filename = os.path.basename(train_path)\n",
    "    fake_data_path = os.path.join(FAKE_TRAIN_DIR, \"fake_\" + filename)\n",
    "    create_csv(fake_data_path, fusion_csv_columns_name)\n",
    "\n",
    "    # Write to file\n",
    "    for i in range(fake_fusing_data.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]  # shape: (48, 3)\n",
    "        right_xyZ = right_camera_lmks[i]  # shape: (48, 3)\n",
    "        left_intr = left_camera_intrinsic[i]  # shape: (9)\n",
    "        right_intr = right_camera_intrinsic[i]  # shape: (9)\n",
    "        trans_mat = right_2_left_mat[i]  # shape: (16)\n",
    "\n",
    "        fused_lmks = fake_fusing_data[i, ...]  # shape: (144)\n",
    "\n",
    "        left_xyZ = left_xyZ.T  # shape: (3, 48)\n",
    "        left_xyZ[0, :] = left_xyZ[0, :] / img_w\n",
    "        left_xyZ[1, :] = left_xyZ[1, :] / img_h\n",
    "        right_xyZ = right_xyZ.T  # shape: (3, 48)\n",
    "        right_xyZ[0, :] = right_xyZ[0, :] / img_w\n",
    "        right_xyZ[1, :] = right_xyZ[1, :] / img_h\n",
    "        fused_lmks = fused_lmks.reshape(48, 3)  # shape: (48, 3)\n",
    "        fused_lmks = fused_lmks.T  # shape: (3, 48)\n",
    "        \n",
    "        input_row = np.concatenate([[i],\n",
    "            left_xyZ.flatten(),\n",
    "            left_intr.flatten(),\n",
    "            right_xyZ.flatten(),\n",
    "            right_intr.flatten(),\n",
    "            trans_mat.flatten(),\n",
    "            fused_lmks.flatten()])\n",
    "        append_to_csv(fake_data_path, input_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_distance_thres = 450\n",
    "leftarm_distance_thres = 450\n",
    "lefthand_distance_thres = 200\n",
    "\n",
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "img_w = 1920 \n",
    "img_h = 1080\n",
    "\n",
    "for val_path in val_paths:\n",
    "    val_dataset = HandArmLandmarksDataset_ANN([val_path], \n",
    "        body_lines, \n",
    "        lefthand_lines, \n",
    "        body_distance_thres, \n",
    "        leftarm_distance_thres, \n",
    "        lefthand_distance_thres,\n",
    "        filter_outlier=True,\n",
    "        only_keep_frames_contain_lefthand=True)\n",
    "    \n",
    "    input_data = val_dataset._inputs\n",
    "    if input_data.shape[0] < seq_len:\n",
    "        continue\n",
    "    \n",
    "    # Slicing data\n",
    "    left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "    right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "    right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows\n",
    "\n",
    "    # Get left and right records which have depth (z != 0) \n",
    "    left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "    left_camera_lmks_z_values = left_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    right_camera_lmks_z_values = right_camera_lmks[:, -1, :]  # shape: (N, 48)\n",
    "    left_camera_sum_z = np.sum(left_camera_lmks_z_values)\n",
    "    right_camera_sum_z = np.sum(right_camera_lmks_z_values)\n",
    "    if left_camera_sum_z == 0 or right_camera_sum_z == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly set z = 0\n",
    "    mask_left = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    mask_right = np.random.choice([0, 1], size=(left_camera_lmks_z_values.shape), p=[0.75, 0.25])    \n",
    "    left_camera_lmks[:, -1, :] = mask_left * left_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, -1, :] = mask_right * right_camera_lmks_z_values  # shape: (N, 3, 48)\n",
    "\n",
    "    left_camera_lmks[:, 0, :] = left_camera_lmks[:, 0, :]  * img_w  # shape: (N, 3, 48)\n",
    "    left_camera_lmks[:, 1, :] = left_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 0, :] = right_camera_lmks[:, 0, :] * img_w  # shape: (N, 3, 48)\n",
    "    right_camera_lmks[:, 1, :] = right_camera_lmks[:, 1, :] * img_h  # shape: (N, 3, 48)\n",
    "\n",
    "\n",
    "    left_camera_lmks = np.transpose(left_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "    right_camera_lmks = np.transpose(right_camera_lmks, (0, 2, 1))  # shape: (N, 48, 3)\n",
    "\n",
    "    # Fuse data\n",
    "    fake_fusing_data = []\n",
    "    for i in range(left_camera_lmks.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]\n",
    "        right_xyZ = right_camera_lmks[i]\n",
    "        left_intr = left_camera_intrinsic[i].reshape(3, 3)\n",
    "        right_intr = right_camera_intrinsic[i].reshape(3, 3)\n",
    "        trans_mat = right_2_left_mat[i].reshape(4, 4)\n",
    "        fused_XYZ = fusing_model(opposite_xyZ=left_xyZ,\n",
    "            right_side_xyZ=right_xyZ,\n",
    "            right_side_cam_intrinsic=right_intr,\n",
    "            opposite_cam_intrinsic=left_intr,\n",
    "            right_to_opposite_correctmat=trans_mat)\n",
    "        fake_fusing_data.append(fused_XYZ.flatten())\n",
    "\n",
    "    fake_fusing_data = np.array(fake_fusing_data)\n",
    "\n",
    "    filename = os.path.basename(val_path)\n",
    "    fake_data_path = os.path.join(FAKE_VAL_DIR, \"fake_\" + filename)\n",
    "    create_csv(fake_data_path, fusion_csv_columns_name)\n",
    "\n",
    "    # Write to file\n",
    "    for i in range(fake_fusing_data.shape[0]):\n",
    "        left_xyZ = left_camera_lmks[i]  # shape: (48, 3)\n",
    "        right_xyZ = right_camera_lmks[i]  # shape: (48, 3)\n",
    "        left_intr = left_camera_intrinsic[i]  # shape: (9)\n",
    "        right_intr = right_camera_intrinsic[i]  # shape: (9)\n",
    "        trans_mat = right_2_left_mat[i]  # shape: (16)\n",
    "\n",
    "        fused_lmks = fake_fusing_data[i, ...]  # shape: (144)\n",
    "\n",
    "        left_xyZ = left_xyZ.T  # shape: (3, 48)\n",
    "        left_xyZ[0, :] = left_xyZ[0, :] / img_w\n",
    "        left_xyZ[1, :] = left_xyZ[1, :] / img_h\n",
    "        right_xyZ = right_xyZ.T  # shape: (3, 48)\n",
    "        right_xyZ[0, :] = right_xyZ[0, :] / img_w\n",
    "        right_xyZ[1, :] = right_xyZ[1, :] / img_h\n",
    "        fused_lmks = fused_lmks.reshape(48, 3)  # shape: (48, 3)\n",
    "        fused_lmks = fused_lmks.T  # shape: (3, 48)\n",
    "        \n",
    "        input_row = np.concatenate([[i],\n",
    "            left_xyZ.flatten(),\n",
    "            left_intr.flatten(),\n",
    "            right_xyZ.flatten(),\n",
    "            right_intr.flatten(),\n",
    "            trans_mat.flatten(),\n",
    "            fused_lmks.flatten()])\n",
    "        append_to_csv(fake_data_path, input_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
