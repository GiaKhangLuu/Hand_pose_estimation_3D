{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand\")\n",
    "sys.path.append(\"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D\")\n",
    "\n",
    "from dataloader_ann import HandArmLandmarksDataset_ANN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utilities import fuse_landmarks_from_two_cameras\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusing_model = partial(fuse_landmarks_from_two_cameras,\n",
    "    tolerance=1e-15,\n",
    "    method_name=\"L-BFGS-B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/giakhang/dev/pose_sandbox/data\"  \n",
    "train_paths = glob.glob(os.path.join(DATA_DIR, \"*/*/fine_landmarks_{}_*.csv\".format(\"train\")))\n",
    "val_paths = glob.glob(os.path.join(DATA_DIR, \"*/*/fine_landmarks_{}_*.csv\".format(\"val\")))\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]\n",
    "body_distance_thres=500\n",
    "leftarm_distance_thres=500\n",
    "lefthand_distance_thres=200\n",
    "\n",
    "train_dataset = HandArmLandmarksDataset_ANN(train_paths, \n",
    "    body_lines, \n",
    "    lefthand_lines, \n",
    "    body_distance_thres, \n",
    "    leftarm_distance_thres, \n",
    "    lefthand_distance_thres,\n",
    "    filter_outlier=True,\n",
    "    only_keep_frames_contain_lefthand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = train_dataset._inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 322)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_first_intrinsic_value_idx = 144\n",
    "right_camera_first_lmk_value_idx = left_camera_first_intrinsic_value_idx + 9\n",
    "right_camera_first_intrinsic_value_idx = right_camera_first_lmk_value_idx + 144\n",
    "first_right_2_left_matrix_value_idx = right_camera_first_intrinsic_value_idx + 9\n",
    "\n",
    "left_camera_lmks = input_data[:, :left_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "left_camera_intrinsic = input_data[:, left_camera_first_intrinsic_value_idx:right_camera_first_lmk_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_camera_lmks = input_data[:, right_camera_first_lmk_value_idx:right_camera_first_intrinsic_value_idx]  # shape: (N, 144), N = #rows\n",
    "right_camera_intrinsic = input_data[:, right_camera_first_intrinsic_value_idx:first_right_2_left_matrix_value_idx]  # shape: (N, 9), N = #rows\n",
    "right_2_left_mat = input_data[:, first_right_2_left_matrix_value_idx:]  # shape: (N, 16), N = #rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 144)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_lmks = left_camera_lmks.reshape(-1, 3, 48)  # shape: (N, 3, 48)\n",
    "left_camera_lmks_z_values = left_camera_lmks[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_camera_rows_contain_z_idx = np.where(np.sum(left_camera_lmks_z_values, axis=1) != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_camera_lmks = right_camera_lmks.reshape(-1, 3, 48)\n",
    "right_camera_lmks_z_values = right_camera_lmks[:, -1, :]\n",
    "right_camera_rows_contain_z_idx = np.where(np.sum(right_camera_lmks_z_values, axis=1) != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_camera_rows_contain_z_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_id_mask = left_camera_rows_contain_z_idx == right_camera_rows_contain_z_idx\n",
    "fake_rows_selected_id = left_camera_rows_contain_z_idx[common_id_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 3, 48)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks = left_camera_lmks[fake_rows_selected_id]\n",
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28419"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, -1, :] = fake_left_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7133"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_left_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 3, 48)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks = right_camera_lmks[fake_rows_selected_id]\n",
    "fake_right_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28970"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7209"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_right_camera_lmks[:, -1, :] = fake_right_camera_lmks[:, -1, :] * np.random.choice([0, 1], size=(fake_left_camera_lmks[:, -1, :].shape), p=[0.75, 0.25])\n",
    "np.count_nonzero(fake_right_camera_lmks[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 3, 48)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_left_camera_lmks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_left_camera_intrinsic = left_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_camera_intrinsic = right_camera_intrinsic[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows\n",
    "selected_right_2_left_mat = right_2_left_mat[fake_rows_selected_id]  # shape: (N*, 9), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 1920 \n",
    "img_h = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks[:, 0, :] = fake_left_camera_lmks[:, 0, :]  * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_left_camera_lmks[:, 1, :] = fake_left_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 0, :] = fake_right_camera_lmks[:, 0, :] * img_w  # shape: (N*, 3, 48), N* = #selected_rows\n",
    "fake_right_camera_lmks[:, 1, :] = fake_right_camera_lmks[:, 1, :] * img_h  # shape: (N*, 3, 48), N* = #selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_left_camera_lmks = np.transpose(fake_left_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3), N* = #selected_rows\n",
    "fake_right_camera_lmks = np.transpose(fake_right_camera_lmks, (0, 2, 1))  # shape: (N*, 48, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = []\n",
    "for i in range(fake_left_camera_lmks.shape[0]):\n",
    "    left_xyZ = fake_left_camera_lmks[i]\n",
    "    right_xyZ = fake_right_camera_lmks[i]\n",
    "    left_intr = selected_left_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_intr = selected_right_camera_intrinsic[i].reshape(3, 3)\n",
    "    right_2_left_mat = selected_right_2_left_mat[i].reshape(4, 4)\n",
    "    fused_XYZ = fusing_model(left_xyZ,\n",
    "        right_xyZ,\n",
    "        right_intr,\n",
    "        left_intr,\n",
    "        right_2_left_mat)\n",
    "    fake_fusing_data.append(fused_XYZ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fusing_data = np.array(fake_fusing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_hand_fused_names = [\"left shoulder\", \"left elbow\", \"left hip\", \"right shoulder\", \"right hip\", \n",
    " \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\", \"INDEX_FINGER_MCP\", \n",
    " \"INDEX_FINGER_PIP\", \"INDEX_FINGER_DIP\", \"INDEX_FINGER_TIP\", \"MIDDLE_FINGER_MCP\", \n",
    " \"MIDDLE_FINGER_PIP\", \"MIDDLE_FINGER_DIP\", \"MIDDLE_FINGER_TIP\", \"RING_FINGER_MCP\", \n",
    " \"RING_FINGER_PIP\", \"RING_FINGER_DIP\", \"RING_FINGER_TIP\", \"PINKY_MCP\", \"PINKY_PIP\", \n",
    " \"PINKY_DIP\", \"PINKY_TIP\", \"right elbow\"]\n",
    "\n",
    "body_lines = [[0,2], [0, 3], [2, 4], [3, 4]]\n",
    "lefthand_lines = [[0, 1], [1, 5], [5, 6], [5, 10], [5, 22], [10, 14], [14, 18], [18, 22], \n",
    "    [6, 7], [7, 8], [8, 9], \n",
    "    [10, 11], [11, 12], [12, 13], \n",
    "    [14, 15], [15, 16], [16, 17], \n",
    "    [18, 19], [19, 20], [20, 21], \n",
    "    [22, 23], [23, 24], [24, 25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from utilities import convert_to_shoulder_coord\n",
    "import time\n",
    "\n",
    "time_sleep = 0.1\n",
    "x = np.array([[500, 0, 0],\n",
    "    [0, 0, 0]])\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(x)\n",
    "lines = [[0, 0]]\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(x),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)\n",
    "vis.add_geometry(line_set)\n",
    "\n",
    "for i in range(fake_fusing_data.shape[0]):\n",
    "    output = fake_fusing_data[i, ...]  # shape: (144)\n",
    "    output = output.reshape(48, 3)  # shape: (48, 3)\n",
    "\n",
    "    lines = body_lines.copy()\n",
    "    lines.extend(lefthand_lines)\n",
    "\n",
    "    points, _ = convert_to_shoulder_coord(output,\n",
    "        arm_hand_fused_names)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)  \n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines) \n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    vis.update_geometry(pcd)\n",
    "    vis.update_geometry(line_set)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "        \n",
    "    time.sleep(time_sleep)\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 144)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_fusing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv_writer import create_csv, append_to_csv, fusion_csv_columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_date_path = \"/home/giakhang/dev/pose_sandbox/Hand_pose_estimation_3D/arm_and_hand/fake_data.csv\"\n",
    "create_csv(fake_date_path, fusion_csv_columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(fake_fusing_data.shape[0]):\n",
    "    left_xyZ = fake_left_camera_lmks[i]  # shape: (48, 3)\n",
    "    right_xyZ = fake_right_camera_lmks[i]  # shape: (48, 3)\n",
    "    left_intr = selected_left_camera_intrinsic[i]  # shape: (9)\n",
    "    right_intr = selected_right_camera_intrinsic[i]  # shape: (9)\n",
    "    right_2_left_mat = selected_right_2_left_mat[i]  # shape: (16)\n",
    "\n",
    "    fused_lmks = fake_fusing_data[i, ...]  # shape: (144)\n",
    "\n",
    "    left_xyZ = left_xyZ.T  # shape: (3, 48)\n",
    "    left_xyZ[0, :] = left_xyZ[0, :] / img_w\n",
    "    left_xyZ[1, :] = left_xyZ[1, :] / img_h\n",
    "    right_xyZ = right_xyZ.T  # shape: (3, 48)\n",
    "    right_xyZ[0, :] = right_xyZ[0, :] / img_w\n",
    "    right_xyZ[1, :] = right_xyZ[1, :] / img_h\n",
    "    fused_lmks = fused_lmks.reshape(48, 3)  # shape: (48, 3)\n",
    "    fused_lmks = fused_lmks.T  # shape: (3, 48)\n",
    "\n",
    "    input_row = np.concatenate([[i],\n",
    "        left_xyZ.flatten(),\n",
    "        left_intr.flatten(),\n",
    "        right_xyZ.flatten(),\n",
    "        right_intr.flatten(),\n",
    "        right_2_left_mat.flatten(),\n",
    "        fused_lmks.flatten()])\n",
    "    append_to_csv(fake_date_path, input_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
